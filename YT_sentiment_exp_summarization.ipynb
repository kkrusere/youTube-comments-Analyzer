{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "\n",
        "wget -N https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/118.0.5993.70/linux64/chromedriver-linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver-linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver-linux64/chromedriver\n",
        "mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver\n",
        "pip install selenium chromedriver_autoinstaller\n",
        "\n",
        "pip install bitsandbytes\n",
        "pip install accelerate\n",
        "pip install trl peft\n",
        "pip install datasets\n",
        "pip install rouge-score\n",
        "pip install evaluate\n",
        "pip install huggingface_hub\n",
        "pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBA4YErknYov",
        "outputId": "9cb136c5-6db4-451b-eddb-7029646b04cc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Ign:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,308 kB]\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,440 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,150 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,585 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 7,740 kB in 3s (2,296 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "68 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.81.0-1ubuntu1.18).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " google-chrome-stable : Depends: libvulkan1 but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n",
            "--2024-09-17 15:59:52--  http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
            "Resolving archive.ubuntu.com (archive.ubuntu.com)... 91.189.91.83, 91.189.91.81, 185.125.190.82, ...\n",
            "Connecting to archive.ubuntu.com (archive.ubuntu.com)|91.189.91.83|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3708 (3.6K) [application/vnd.debian.binary-package]\n",
            "Saving to: ‘libu2f-udev_1.1.4-1_all.deb.5’\n",
            "\n",
            "libu2f-udev_1.1.4-1 100%[===================>]   3.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-17 15:59:53 (469 MB/s) - ‘libu2f-udev_1.1.4-1_all.deb.5’ saved [3708/3708]\n",
            "\n",
            "(Reading database ... 123720 files and directories currently installed.)\n",
            "Preparing to unpack libu2f-udev_1.1.4-1_all.deb ...\n",
            "Unpacking libu2f-udev (1.1.4-1) over (1.1.4-1) ...\n",
            "Setting up libu2f-udev (1.1.4-1) ...\n",
            "--2024-09-17 15:59:54--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 74.125.200.93, 74.125.200.91, 74.125.200.136, ...\n",
            "Connecting to dl.google.com (dl.google.com)|74.125.200.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 110722184 (106M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb.5’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 105.59M  82.5MB/s    in 1.3s    \n",
            "\n",
            "2024-09-17 15:59:55 (82.5 MB/s) - ‘google-chrome-stable_current_amd64.deb.5’ saved [110722184/110722184]\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading google-chrome-stable from 128.0.6613.137-1 to 128.0.6613.119-1\n",
            "(Reading database ... 123720 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (128.0.6613.119-1) over (128.0.6613.137-1) ...\n",
            "\u001b[1mdpkg:\u001b[0m dependency problems prevent configuration of google-chrome-stable:\n",
            " google-chrome-stable depends on libvulkan1; however:\n",
            "  Package libvulkan1 is not installed.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m error processing package google-chrome-stable (--install):\n",
            " dependency problems - leaving unconfigured\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Errors were encountered while processing:\n",
            " google-chrome-stable\n",
            "--2024-09-17 16:00:09--  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/118.0.5993.70/linux64/chromedriver-linux64.zip\n",
            "Resolving edgedl.me.gvt1.com (edgedl.me.gvt1.com)... 34.104.35.123, 2600:1900:4110:86f::\n",
            "Connecting to edgedl.me.gvt1.com (edgedl.me.gvt1.com)|34.104.35.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/chrome-for-testing-public/118.0.5993.70/linux64/chromedriver-linux64.zip [following]\n",
            "--2024-09-17 16:00:09--  https://storage.googleapis.com/chrome-for-testing-public/118.0.5993.70/linux64/chromedriver-linux64.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.130.207, 74.125.68.207, 64.233.170.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.130.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‘/tmp/chromedriver-linux64.zip’ not modified on server. Omitting download.\n",
            "\n",
            "Archive:  /tmp/chromedriver-linux64.zip\n",
            "  inflating: /tmp/chromedriver-linux64/LICENSE.chromedriver  \n",
            "  inflating: /tmp/chromedriver-linux64/chromedriver  \n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.24.0)\n",
            "Requirement already satisfied: chromedriver_autoinstaller in /usr/local/lib/python3.10/dist-packages (0.6.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.26.2)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.8.30)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver_autoinstaller) (24.1)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.8)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.4.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.44.2)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.26.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.34.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (3.0.0)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.8.10)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.19.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.8.1)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2.1.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.10.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.5)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.24.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "import os\n",
        "import json\n",
        "#mounting google drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "########################################\n",
        "\n",
        "#changing the working directory\n",
        "os.chdir(\"/content/drive/MyDrive/NLP_Data\")\n",
        "\n",
        "!pwd\n",
        "\n",
        "huggingface_token = userdata.get('Hugging_Face_Hub_API_TOKEN')\n",
        "\n",
        "#logging into huggingface\n",
        "login(huggingface_token)"
      ],
      "metadata": {
        "id": "sTBJTSwEE6BI",
        "outputId": "a47a4484-cda2-42e8-f615-39d283d6373e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/NLP_Data\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qQnm3ng8ExaU"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "\n",
        "from selenium import webdriver\n",
        "import chromedriver_autoinstaller\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.common.exceptions import TimeoutException, ElementNotInteractableException\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "import json\n",
        "import random\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "import torch\n",
        "import evaluate\n",
        "from evaluate import load\n",
        "from rouge_score import rouge_scorer, scoring"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Below are functions for reading a writting json file for the current working directory\n",
        "\n",
        "def save_to_json(data, filename):\n",
        "    with open(filename, 'w') as json_file:\n",
        "        json.dump(data, json_file, indent=4)\n",
        "\n",
        "def load_from_json(filename):\n",
        "    with open(filename, 'r') as json_file:\n",
        "        comments = json.load(json_file)\n",
        "    return comments"
      ],
      "metadata": {
        "id": "NFk3DIPIIwR2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert string values containing suffixes 'K', 'M', or 'B' to integers and extract numeric values.\n",
        "def convert_to_int(value):\n",
        "  \"\"\"\n",
        "    - If the value is NaN or an empty string, return 0.\n",
        "    - If the value is a string:\n",
        "      - Extract numeric digits from the string.\n",
        "      - Convert the extracted digits to an integer.\n",
        "      - If the string contains 'K', multiply the number by 1,000.\n",
        "      - If the string contains 'M', multiply the number by 1,000,000.\n",
        "      - If the string contains 'B', multiply the number by 1,000,000,000.\n",
        "    - Return the converted integer value.\n",
        "\n",
        "  \"\"\"\n",
        "  if pd.isna(value) or value == '':\n",
        "      return 0\n",
        "  if isinstance(value, str):\n",
        "      # Extract numbers and convert them\n",
        "      num = re.findall(r'\\d+', value)\n",
        "      if not num:\n",
        "          return 0\n",
        "      num = ''.join(num)\n",
        "      if 'K' in value:\n",
        "          return int(float(num) * 1000)\n",
        "      if 'M' in value:\n",
        "          return int(float(num) * 1000000)\n",
        "      if 'B' in value:\n",
        "          return int(float(num) * 1000000000)\n",
        "      return int(num)\n",
        "  return int(value)"
      ],
      "metadata": {
        "id": "GE-zPp2ZIwN8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize YouTube API client\n",
        "def initialize_youtube_api(api_key):\n",
        "    return build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "\n",
        "def init_webdriver():\n",
        "    \"\"\"Initializes and returns a Chrome WebDriver instance with options.\"\"\"\n",
        "    try:\n",
        "        chrome_options = webdriver.ChromeOptions()\n",
        "        chrome_options.add_argument('--headless')\n",
        "        chrome_options.add_argument('--no-sandbox')\n",
        "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "        chromedriver_autoinstaller.install()\n",
        "        driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "        print(\"WebDriver initialized successfully\")  # Confirm initialization\n",
        "        return driver\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to initialize WebDriver: {e}\")\n",
        "        raise\n",
        "\n",
        "def close_webdriver(driver):\n",
        "    \"\"\"Closes the provided WebDriver instance.\"\"\"\n",
        "    print(\"WebDriver successfully closed\")\n",
        "    driver.quit()\n"
      ],
      "metadata": {
        "id": "z2goaB14IwJ1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_youtube_url(video_id):\n",
        "  \"\"\"\n",
        "  Constructs a YouTube URL from a given video ID.\n",
        "\n",
        "  Args:\n",
        "      video_id: The unique identifier for a YouTube video.\n",
        "\n",
        "  Returns:\n",
        "      The full URL of the YouTube video.\n",
        "  \"\"\"\n",
        "\n",
        "  video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "\n",
        "  return video_url\n",
        "\n",
        "\n",
        "def get_video_id_from_url(url):\n",
        "  \"\"\"\n",
        "  Extracts the video ID from a YouTube video URL.\n",
        "\n",
        "  Args:\n",
        "      url: The URL of the YouTube video.\n",
        "\n",
        "  Returns:\n",
        "      The video ID as a string, or None if the URL is invalid.\n",
        "  \"\"\"\n",
        "  try:\n",
        "    video_id = url.split(\"v=\")[1]\n",
        "    ampersand_position = video_id.find(\"&\")\n",
        "    if ampersand_position != -1:\n",
        "      video_id = video_id[:ampersand_position]\n",
        "    return video_id\n",
        "  except IndexError:\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "_P3jQlMmoQdt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_comments_html(video_url, driver):\n",
        "    \"\"\"\n",
        "    Fetches the HTML content of the comments section from a YouTube video.\n",
        "\n",
        "    This function initializes a WebDriver instance to open the provided YouTube video URL,\n",
        "    scrolls down to load the comments section, and retrieves the HTML content of the loaded\n",
        "    comments section.\n",
        "\n",
        "    Args:\n",
        "        video_url (str): The URL of the YouTube video from which to fetch comments.\n",
        "        driver: An initialized WebDriver instance (from Selenium).\n",
        "\n",
        "    Returns:\n",
        "        str: The HTML content of the comments section.\n",
        "\n",
        "    Raises:\n",
        "        TimeoutException: If the comments section does not load within the specified time.\n",
        "    \"\"\"\n",
        "\n",
        "    # Wait until the comments section is loaded\n",
        "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'ytd-comments')))\n",
        "\n",
        "    # Scroll to the comments section to load initial comments\n",
        "    driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
        "\n",
        "    # Set initial values for dynamic loading\n",
        "    last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
        "    scroll_pause_time = 2  # Time to wait between scrolls\n",
        "    max_scrolls = 100  # Increase the max number of scrolls to ensure all comments are loaded\n",
        "    scroll_count = 0\n",
        "\n",
        "    while scroll_count < max_scrolls:\n",
        "        # Scroll down to the bottom\n",
        "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
        "\n",
        "        # Wait for new comments to load dynamically\n",
        "        time.sleep(scroll_pause_time)  # Simple wait to allow comments to load\n",
        "\n",
        "        # Check the new scroll height and compare it with the last height\n",
        "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
        "        if new_height == last_height:\n",
        "            # If the height hasn't changed, try one more scroll to ensure all comments are loaded\n",
        "            time.sleep(scroll_pause_time)\n",
        "            new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
        "            if new_height == last_height:\n",
        "                # If the height still hasn't changed, we've reached the end\n",
        "                print(\"All comments have been loaded.\")\n",
        "                break\n",
        "\n",
        "        last_height = new_height\n",
        "        scroll_count += 1\n",
        "\n",
        "    # Get the HTML of the comments section\n",
        "    comments_html = driver.page_source\n",
        "\n",
        "    # Close the driver\n",
        "    driver.quit()\n",
        "\n",
        "    return comments_html\n",
        "\n",
        "\n",
        "def get_comment_thread_renderers(comments_html):\n",
        "    \"\"\"\n",
        "    Parses the provided HTML content to extract YouTube comment threads and their counts.\n",
        "\n",
        "    This function uses BeautifulSoup to parse the HTML content of a YouTube video's comments section.\n",
        "    It finds and prints the number of comments and the number of comment thread renderers (`ytd-comment-thread-renderer`).\n",
        "    It then returns a list of all the `ytd-comment-thread-renderer` elements found in the HTML.\n",
        "\n",
        "    Args:\n",
        "        comments_html (str): The HTML content of the comments section of a YouTube video.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of `ytd-comment-thread-renderer` elements found in the HTML.\n",
        "    \"\"\"\n",
        "\n",
        "    soup = BeautifulSoup(comments_html, 'html.parser')\n",
        "\n",
        "    # Find the span element with the specified class\n",
        "    comment_count_span = soup.find('span', class_='style-scope yt-formatted-string')\n",
        "\n",
        "    # Extract the text content of the span element\n",
        "    comment_count = comment_count_span.text.strip()\n",
        "\n",
        "    # # Print or use the comment count\n",
        "    # print(\"Comment Count:\", comment_count)\n",
        "\n",
        "    # Find all occurrences of the ytd-comment-thread-renderer element\n",
        "    comment_thread_renderers = soup.find_all('ytd-comment-thread-renderer', class_='style-scope ytd-item-section-renderer')\n",
        "\n",
        "    # Count the number of occurrences\n",
        "    comment_thread_count = len(comment_thread_renderers)\n",
        "\n",
        "    # # Print or use the comment thread count\n",
        "    # print(\"Number of ytd-comment-thread-renderer elements:\", comment_thread_count)\n",
        "\n",
        "    return comment_thread_renderers\n",
        "\n",
        "def get_comments(comment_thread_renderers):\n",
        "    comments = list()\n",
        "    comments_data = list()\n",
        "    # Iterate through each comment thread renderer\n",
        "    for comment_thread_renderer in comment_thread_renderers:\n",
        "\n",
        "        # Extracting the comment text\n",
        "        comment_text_element = comment_thread_renderer.find('yt-attributed-string', id='content-text')\n",
        "        comment_text = comment_text_element.get_text(strip=True) if comment_text_element else None\n",
        "\n",
        "        # Extracting the number of likes\n",
        "        like_count_element = comment_thread_renderer.find('span', class_='style-scope ytd-comment-engagement-bar')\n",
        "        like_count = like_count_element.get_text(strip=True) if like_count_element else None\n",
        "\n",
        "        # Extracting the number of replies\n",
        "        reply_count_element = comment_thread_renderer.find('ytd-button-renderer', id='more-replies')\n",
        "        reply_count = reply_count_element.get_text(strip=True) if reply_count_element else None\n",
        "\n",
        "        comments.append(comment_text)\n",
        "\n",
        "        comments_data.append(\n",
        "            {\n",
        "            \"comment_text\": comment_text,\n",
        "            \"like_count\": like_count,\n",
        "            \"reply_count\": reply_count\n",
        "\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return comments, comments_data\n",
        "\n",
        "\n",
        "\n",
        "def clean_description(description_data, model_path=\"./Desc-Sum-fine-tuned-lora-model\"):\n",
        "    \"\"\"\n",
        "    Cleans and summarizes YouTube video descriptions using a fine-tuned LoRA model.\n",
        "\n",
        "    Args:\n",
        "        description_data: A list of dictionaries containing video details (channel_name, video_title, video_description).\n",
        "        model_path: The path to the fine-tuned LoRA model.\n",
        "\n",
        "    Returns:\n",
        "        A list of cleaned and summarized video descriptions.\n",
        "    \"\"\"\n",
        "    # Configure LoRA\n",
        "    lora_config = LoraConfig(\n",
        "        r=16,  # Rank of the LoRA matrix\n",
        "        lora_alpha=32,  # Scaling factor for LoRA\n",
        "        target_modules=[\"q_proj\", \"v_proj\"],  # Target attention layers to apply LoRA\n",
        "        lora_dropout=0.05,  # Dropout rate for LoRA\n",
        "        bias=\"none\",  # No bias\n",
        "    )\n",
        "\n",
        "    # Preparing input for inference\n",
        "    formatted_inputs = [\n",
        "        f\"Channel: {item['channel_name']}, Title: {item['video_title']}, Description: {item['video_description']}\"\n",
        "        for item in description_data\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Loading the fine-tuned LoRA model and tokenizer\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_path)\n",
        "\n",
        "    # # Tokenize input\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_path)\n",
        "    inputs = tokenizer(formatted_inputs, max_length=512, return_tensors=\"pt\", truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Move inputs to the same device as the model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "\n",
        "    # LoRA configuration applied to the model\n",
        "    lora_model = get_peft_model(model, lora_config)\n",
        "    lora_model.to(device)\n",
        "\n",
        "    # Generate Cleaned Descriptions\n",
        "    with torch.no_grad():\n",
        "        outputs = lora_model.generate(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            max_length=128,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "    # Decode and print summaries\n",
        "    cleaned_descriptions = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    return cleaned_descriptions[0]\n",
        "\n",
        "\n",
        "def get_video_comments(video_url, driver):\n",
        "    \"\"\"\n",
        "    Retrieves comments from the provided YouTube video URL.\n",
        "\n",
        "    Args:\n",
        "        video_url (str): The URL of the YouTube video.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of comments and their data.\n",
        "    \"\"\"\n",
        "    #print(\"\\nwe are now in the get_video_comments function\\n\")\n",
        "    comments_html = get_comments_html(video_url, driver)  # Get HTML of comments section\n",
        "    comment_thread_renderers = get_comment_thread_renderers(comments_html)  # Extract comment renderers\n",
        "    _, comments_data = get_comments(comment_thread_renderers)  # Extract comment data\n",
        "\n",
        "    return comments_data\n",
        "\n",
        "\n",
        "def get_video_data(video_id):\n",
        "    \"\"\"Fetches video data from YouTube given a video ID.\n",
        "\n",
        "    Args:\n",
        "        video_id (str): The ID of the YouTube video to fetch data for.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the video data with the following keys:\n",
        "            - 'channel_name': The name of the channel that uploaded the video.\n",
        "            - 'video_title': The title of the video.\n",
        "            - 'video_description': The description of the video.\n",
        "\n",
        "    Raises:\n",
        "        Exception: If there is an error accessing or processing the video data.\n",
        "    \"\"\"\n",
        "    driver = init_webdriver()\n",
        "    video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "    video_data = {}\n",
        "\n",
        "    try:\n",
        "        driver.get(video_url)\n",
        "\n",
        "        # Handle YouTube consent dialog if it appears\n",
        "        try:\n",
        "            consent_button = WebDriverWait(driver, 10).until(\n",
        "                EC.element_to_be_clickable((By.XPATH, '//button[contains(., \"I agree\")]'))\n",
        "            )\n",
        "            consent_button.click()\n",
        "        except TimeoutException:\n",
        "            print(\"No consent dialog found or already handled.\")\n",
        "\n",
        "        # Handle any other potential modal dialogs that might pop up\n",
        "        try:\n",
        "            dialog_close_button = WebDriverWait(driver, 5).until(\n",
        "                EC.element_to_be_clickable((By.XPATH, '//button[@aria-label=\"Close\"]'))\n",
        "            )\n",
        "            dialog_close_button.click()\n",
        "        except TimeoutException:\n",
        "            print(\"No additional modal dialogs found.\")\n",
        "\n",
        "        try:\n",
        "            # Wait for the bottom-row element to be present\n",
        "            bottom_row = WebDriverWait(driver, 20).until(\n",
        "                EC.presence_of_element_located((By.XPATH, '//*[@id=\"bottom-row\"]'))\n",
        "            )\n",
        "\n",
        "            # Locate and click the expand button if it exists\n",
        "            try:\n",
        "                expand_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.presence_of_element_located((By.XPATH, '//tp-yt-paper-button[@id=\"expand\"]'))\n",
        "                )\n",
        "\n",
        "                # Use JavaScript to click the element to bypass any overlay issues\n",
        "                driver.execute_script(\"arguments[0].scrollIntoView();\", expand_button)\n",
        "                driver.execute_script(\"arguments[0].click();\", expand_button)\n",
        "            except TimeoutException:\n",
        "                pass  # Ignore if the expand button is not found\n",
        "\n",
        "            # Wait for elements to be visible and extract data\n",
        "            expanded_description = WebDriverWait(driver, 10).until(\n",
        "                EC.visibility_of_element_located((By.ID, 'description-inline-expander'))\n",
        "            )\n",
        "            title_element = WebDriverWait(driver, 10).until(\n",
        "                EC.presence_of_element_located((By.XPATH, '//h1[@class=\"style-scope ytd-watch-metadata\"]//yt-formatted-string'))\n",
        "            )\n",
        "            channel_name_element = WebDriverWait(driver, 10).until(\n",
        "                EC.presence_of_element_located((By.XPATH, '//ytd-channel-name[@id=\"channel-name\"]//yt-formatted-string//a'))\n",
        "            )\n",
        "\n",
        "            video_data = {\n",
        "                'channel_name': channel_name_element.text,\n",
        "                'video_title': title_element.text,\n",
        "                'video_description': expanded_description.text\n",
        "            }\n",
        "\n",
        "            # Clean the description\n",
        "            temp_list = [video_data]\n",
        "            cleaned_description = clean_description(temp_list)\n",
        "            video_data['video_description'] = cleaned_description\n",
        "\n",
        "            # Fetch comments\n",
        "            comments_data = get_video_comments(video_url, driver)\n",
        "            video_data['comments'] = comments_data\n",
        "\n",
        "        except TimeoutException:\n",
        "            print(f\"Error processing {video_url}: Elements not found within timeout.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {video_url}: {e}\")\n",
        "\n",
        "    finally:\n",
        "        # Close the browser when done\n",
        "        close_webdriver(driver)\n",
        "\n",
        "    return video_data\n"
      ],
      "metadata": {
        "id": "QOTZfo0UoQPo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_id = \"4u7QZkcoono\"  #@param {type:\"string\"}\n",
        "video_data = get_video_data(video_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_QDgpX7r-yJ",
        "outputId": "80e542ab-e85d-4844-dd96-87e2eb088b78"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WebDriver initialized successfully\n",
            "No consent dialog found or already handled.\n",
            "No additional modal dialogs found.\n",
            "All comments have been loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7891e724e740>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/8c096345f1e9780d2aaf1f3921833229\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7891c2e1fc40>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/8c096345f1e9780d2aaf1f3921833229\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7891e724e4d0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/8c096345f1e9780d2aaf1f3921833229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing https://www.youtube.com/watch?v=4u7QZkcoono: name 'BeautifulSoup' is not defined\n",
            "WebDriver successfully closed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlEIIFaltWKM",
        "outputId": "fc6f12b4-1b03-4edb-9235-79e14b2f2414"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'channel_name': 'Mayday: Air Disaster',\n",
              " 'video_title': 'How Did Scandinavian Flight 751 Survive This? | Mayday Air Disaster',\n",
              " 'video_description': 'Channel: Mayday: Air disaster, Title: How Did Scandinavian Flight 751 Survive This? | Mayday Air Disaster, Description: Chapters \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0View all \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0Introduction to flight 751 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa00:00 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0Preparations and Takeoff \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa04:50 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0Engine Trouble Begins \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa06:30 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0Dual Engine Failure \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa08:40 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0Desperate Attempts to Restart Engines \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa0 \\xa012:00\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0Show less'}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Om-KZ6Hvr-dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_TLdQcY3r-Z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_test_data_from_dict(data_dict):\n",
        "    \"\"\"\n",
        "    Prepares the test data for inference by formatting the input data from a list of dictionaries.\n",
        "\n",
        "    Args:\n",
        "        data_dict (list of dict): A list of dictionaries containing video details and comments.\n",
        "\n",
        "    Returns:\n",
        "        Dataset: A Hugging Face Dataset with formatted input data.\n",
        "    \"\"\"\n",
        "    # Convert the input data into a DataFrame\n",
        "    df = pd.DataFrame(data_dict)\n",
        "\n",
        "    # Format the input data\n",
        "    formatted_input_data = [\n",
        "        {\n",
        "            \"input\": f\"Channel: {row['channel_name']}, Title: {row['video_title']}, Description: {row['video_description']}, Comment Text: {row['comment_text']}\",\n",
        "            \"output\": \"\"  # Output is empty for test data\n",
        "        }\n",
        "        for _, row in df.iterrows()\n",
        "    ]\n",
        "\n",
        "    # Convert the formatted data into a Dataset\n",
        "    return Dataset.from_list(formatted_input_data)\n",
        "\n",
        "def tokenize_dataset(dataset, tokenizer):\n",
        "    \"\"\"\n",
        "    Tokenizes the dataset for model inference.\n",
        "\n",
        "    Args:\n",
        "        dataset (Dataset): A Hugging Face Dataset containing the input data.\n",
        "        tokenizer (PreTrainedTokenizer): A tokenizer for encoding the input data.\n",
        "\n",
        "    Returns:\n",
        "        Dataset: A tokenized dataset ready for model inference.\n",
        "    \"\"\"\n",
        "    # Tokenization function\n",
        "    def tokenize_data(example):\n",
        "        model_inputs = tokenizer(\n",
        "            example[\"input\"],\n",
        "            max_length=512,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True\n",
        "        )\n",
        "        return model_inputs\n",
        "\n",
        "    # Apply tokenization to the dataset\n",
        "    return dataset.map(tokenize_data, batched=True)\n",
        "\n",
        "def run_inference(model, tokenizer, tokenized_dataset):\n",
        "    \"\"\"\n",
        "    Runs inference on the tokenized dataset using the provided model and tokenizer.\n",
        "\n",
        "    Args:\n",
        "        model (PreTrainedModel): A pre-trained model for generating predictions.\n",
        "        tokenizer (PreTrainedTokenizer): A tokenizer for encoding and decoding inputs/outputs.\n",
        "        tokenized_dataset (Dataset): The tokenized dataset on which to perform inference.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of predictions generated by the model.\n",
        "    \"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    predictions = []\n",
        "\n",
        "    for example in tokenized_dataset:\n",
        "        # Prepare inputs for the model\n",
        "        inputs = tokenizer(example['input'], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "\n",
        "        # Generate outputs (predictions)\n",
        "        outputs = model.generate(**inputs)\n",
        "\n",
        "        # Decode the predictions\n",
        "        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "def get_predictions_from_data_dict(data_dict, model, tokenizer):\n",
        "    \"\"\"\n",
        "    Processes the data from `data_dict`, runs inference, and returns predictions.\n",
        "\n",
        "    Args:\n",
        "        data_dict (list of dict): A list of dictionaries containing video data and comments.\n",
        "        model (PreTrainedModel): A pre-trained model for generating predictions.\n",
        "        tokenizer (PreTrainedTokenizer): A tokenizer for encoding and decoding inputs/outputs.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of predictions for each entry in the data_dict.\n",
        "    \"\"\"\n",
        "    # Prepare and format the input data\n",
        "    formatted_dataset = prepare_test_data_from_dict(data_dict)\n",
        "\n",
        "    # Tokenize the dataset\n",
        "    tokenized_dataset = tokenize_dataset(formatted_dataset, tokenizer)\n",
        "\n",
        "    # Run inference to get predictions\n",
        "    predictions = run_inference(model, tokenizer, tokenized_dataset)\n",
        "\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "3y4DNdIlpIyc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q69MW4QarlUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: get data_dict\n",
        "\n",
        "def init_webdriver():\n",
        "    \"\"\"Initializes a Chrome WebDriver instance.\"\"\"\n",
        "    chromedriver_autoinstaller.install()\n",
        "    service = Service()\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')  # Run Chrome in headless mode\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome(service=service, options=options)\n",
        "    return driver\n",
        "\n",
        "def close_webdriver(driver):\n",
        "    \"\"\"Closes the WebDriver instance.\"\"\"\n",
        "    if driver:\n",
        "        driver.quit()\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Example usage:\n",
        "video_id = \"your_video_id\"  # Replace with the ID of the YouTube video\n",
        "data_dict = get_video_data(video_id)\n"
      ],
      "metadata": {
        "id": "3ME0tP_4rlRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = BartForConditionalGeneration.from_pretrained(\"./SA-bart-fine-tuned-lora-model\")\n",
        "# tokenizer = BartTokenizer.from_pretrained(\"./SA-bart-fine-tuned-lora-model\")"
      ],
      "metadata": {
        "id": "cecAvUNOpIvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = get_predictions_from_data_dict(data_dict, model, tokenizer)"
      ],
      "metadata": {
        "id": "dCSzutIRpIsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3AixYWiaoQMR"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkrusere/youTube-comments-Analyzer/blob/main/fine-tuned_LLM_text_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn3vHjrgdvbN"
      },
      "source": [
        "### <center>**Transformer-Based Summarization for Cleaning YouTube Video Descriptions**</center>\n",
        "\n",
        "<center><em>\n",
        "Leverage the power of transformer-based text summarization to automatically remove irrelevant information from YouTube video descriptions, ensuring they're concise and informative.\n",
        "</em></center>\n",
        "\n",
        "#### Intro:\n",
        "\n",
        "YouTube video descriptions are vital for attracting viewers, but often contain extraneous information that hinders understanding. This project utilizes transformer-based text summarization models (like BERT and GPT) to automatically clean these descriptions.\n",
        "\n",
        "By training a summarization model on a dataset of YouTube descriptions paired with their human-refined counterparts, the model learns to identify and remove irrelevant content while preserving key points. This leads to concise, informative descriptions.\n",
        "\n",
        "The project will explore the fine-tuning and evaluation of transformer models for this specific summarization task, focusing on their ability to remove extraneous information and produce distilled video descriptions.\n",
        "\n",
        "**Key Points:**\n",
        "- Problem: YouTube descriptions often contain excessive tags, promotions, and irrelevant details.\n",
        "- Solution: Transformer-based text summarization models trained to clean descriptions.\n",
        "- Approach: Fine-tune models on a dataset of original and human-cleaned descriptions.\n",
        "- Goal: Produce concise, informative descriptions that enhance user experience.\n",
        "- Evaluation: Focus on the models' ability to remove extraneous information effectively."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H8bQWUQEd73_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "\n",
        "wget -N https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/118.0.5993.70/linux64/chromedriver-linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver-linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver-linux64/chromedriver\n",
        "mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver\n",
        "pip install selenium chromedriver_autoinstaller"
      ],
      "metadata": {
        "id": "SL5_Z_Nxd7HS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft\n",
        "!pip install datasets\n",
        "!pip install rouge-score\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "RCv7HwWr68Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMKkbHhrdvbP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import Dataset\n",
        "from peft import LoraConfig, PeftConfig, PeftModel, get_peft_model\n",
        "\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "import transformers\n",
        "from transformers import (\n",
        "                            AutoModelForCausalLM,\n",
        "                            AutoTokenizer,\n",
        "                            BartForConditionalGeneration,\n",
        "                            BartTokenizer,\n",
        "                            BitsAndBytesConfig,\n",
        "                            EarlyStoppingCallback,\n",
        "                            logging,\n",
        "                            pipeline,\n",
        "                            Trainer,\n",
        "                            TrainingArguments,\n",
        ")\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "q7Nv9LM250Kt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hKoBXt59Qk9-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Collection - Overview**\n",
        "- The data collection process involves gathering YouTube video descriptions along with additional metadata, such as the channel name and video title. We are going to use the above functions for this. This data will be used to train and evaluate our transformer-based summarization model.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "- Fetch Video Data:\n",
        "Iterate through a predefined list of YouTube video IDs.\n",
        "> For each video ID, use a custom function to retrieve the video data.\n",
        "- The function fetches:\n",
        "> - Channel Name: The name of the channel where the video was uploaded.\n",
        "> - Video Title: The title of the video.\n",
        "> - Video Description: The description text provided by the video uploader.\n",
        "- Store Data:\n",
        "> - Append the retrieved data, formatted as a dictionary, to the list.\n",
        "> - Store the collected data in a file (e.g., JSON or CSV) to facilitate access and further processing.\n",
        "\n",
        "**Example Output**\n",
        "> - The collected data will be a list of dictionaries, each containing the following keys:\n",
        "\n",
        "> - ```yaml\n",
        "channel_name: The name of the YouTube channel.\n",
        "video_title: The title of the video.\n",
        "video_description: The description text of the video.\n"
      ],
      "metadata": {
        "id": "4Qmp57fTVwtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "import os\n",
        "import json\n",
        "#mounting google drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "########################################\n",
        "\n",
        "#changing the working directory\n",
        "os.chdir(\"/content/drive/MyDrive/NLP_Data\")\n",
        "\n",
        "!pwd\n",
        "\n",
        "huggingface_token = userdata.get('Hugging_Face_Hub_API_TOKEN')\n",
        "\n",
        "#logging into huggingface\n",
        "login(huggingface_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPKUgB2yW8Zv",
        "outputId": "56aad518-a086-471e-933c-7cf64d9dc264"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/NLP_Data\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# below are functions for reading a writting json file for the current working directory\n",
        "\n",
        "def save_to_json(data, filename):\n",
        "    with open(filename, 'w') as json_file:\n",
        "        json.dump(data, json_file, indent=4)\n",
        "\n",
        "def load_from_json(filename):\n",
        "    with open(filename, 'r') as json_file:\n",
        "        comments = json.load(json_file)\n",
        "    return comments"
      ],
      "metadata": {
        "id": "lobNB2YAXl2q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SHxdsKIBf5-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Data Preparation for Fine-Tuning**\n",
        "\n",
        "\n",
        "1. **Data Formatting:**\n",
        "- Each row is formatted to include a combined input of `channel_name`, `video_title`, and `video_description`.\n",
        "- The target output is `clean_video_descriptions`.\n",
        "2. **Converting to Dataset Object:**\n",
        "- `Dataset.from_list(formatted_data)` converts the list of formatted `input-output` pairs into a `Hugging Face Dataset` object.\n",
        "3. **Tokenization:**\n",
        "- The `tokenize_data` function tokenizes both the input text and the target text.\n",
        "- The tokenized target is added to the input dictionary under `\"labels\"`, as required for `seq2seq` training.\n",
        "4. **Tokenized Dataset:**\n",
        "- The tokenized dataset, `tokenized_datasets`, is now ready for `fine-tuning` the `BART` model using `LoRA`.\n"
      ],
      "metadata": {
        "id": "2AG1hd6B2o02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('video_data.csv')\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "aO-vzVm6C_Zi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "29ac38d7-89a5-43fe-b6ee-91477cb79669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      channel_name                                        video_title  \\\n",
              "0  LastWeekTonight  Miss America Pageant: Last Week Tonight with J...   \n",
              "1             ESPN  Smooth 🔥 (via @dariusgaddy2, @d.looo_/TT) #shorts   \n",
              "2      PowerfulJRE            Joe Rogan Experience #1227 - Mike Tyson   \n",
              "3      PowerfulJRE  Joe Rogan Experience #872 - Graham Hancock & R...   \n",
              "4    Mentour Pilot                   HOW was THIS Allowed to HAPPEN?!   \n",
              "\n",
              "                                   video_description  \\\n",
              "0  The Miss America Pageant…how is this still a t...   \n",
              "1  ✔️ Subscribe to ESPN+ http://espnplus.com/yout...   \n",
              "2  Mike Tyson is the former undisputed heavyweigh...   \n",
              "3  Graham Hancock is an English author and journa...   \n",
              "4  Go to https://curiositystream.thld.co/mento......   \n",
              "\n",
              "                             clean_video_description  \n",
              "0  John Oliver criticizes the Miss America Pagean...  \n",
              "1  This is a short video showcasing smooth moves ...  \n",
              "2  Mike Tyson, the former undisputed heavyweight ...  \n",
              "3  Graham Hancock and Randall Carlson discuss cro...  \n",
              "4  This video explores a close call between two A...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4466f8a-6c31-4dd2-9be0-e86186a547ac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel_name</th>\n",
              "      <th>video_title</th>\n",
              "      <th>video_description</th>\n",
              "      <th>clean_video_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LastWeekTonight</td>\n",
              "      <td>Miss America Pageant: Last Week Tonight with J...</td>\n",
              "      <td>The Miss America Pageant…how is this still a t...</td>\n",
              "      <td>John Oliver criticizes the Miss America Pagean...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ESPN</td>\n",
              "      <td>Smooth 🔥 (via @dariusgaddy2, @d.looo_/TT) #shorts</td>\n",
              "      <td>✔️ Subscribe to ESPN+ http://espnplus.com/yout...</td>\n",
              "      <td>This is a short video showcasing smooth moves ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PowerfulJRE</td>\n",
              "      <td>Joe Rogan Experience #1227 - Mike Tyson</td>\n",
              "      <td>Mike Tyson is the former undisputed heavyweigh...</td>\n",
              "      <td>Mike Tyson, the former undisputed heavyweight ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PowerfulJRE</td>\n",
              "      <td>Joe Rogan Experience #872 - Graham Hancock &amp; R...</td>\n",
              "      <td>Graham Hancock is an English author and journa...</td>\n",
              "      <td>Graham Hancock and Randall Carlson discuss cro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mentour Pilot</td>\n",
              "      <td>HOW was THIS Allowed to HAPPEN?!</td>\n",
              "      <td>Go to https://curiositystream.thld.co/mento......</td>\n",
              "      <td>This video explores a close call between two A...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4466f8a-6c31-4dd2-9be0-e86186a547ac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d4466f8a-6c31-4dd2-9be0-e86186a547ac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d4466f8a-6c31-4dd2-9be0-e86186a547ac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-82db8314-979a-4236-9150-69bfe566b3c3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82db8314-979a-4236-9150-69bfe566b3c3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-82db8314-979a-4236-9150-69bfe566b3c3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 233,\n  \"fields\": [\n    {\n      \"column\": \"channel_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"Shaun\",\n          \"HasanAbi\",\n          \"LastWeekTonight\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 231,\n        \"samples\": [\n          \"Face Swap Masters - Best of Just For Laughs Gags\",\n          \"Celebrating the life of Jessi Combs\",\n          \"World: The Inches That Matter | The New York Times\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 230,\n        \"samples\": [\n          \"If you make it through this video you get a prize.\\n\\nSmiling at the laziness of just stealing his thumbnail and writing 'response' on it. Leave me alone, I've got the flu.\\n\\nContact:\\n\\nTwitter -   / shaun_jen  \\nask.fm - http://ask.fm/shaun_jen\\n\\nSources:\\n\\nStefan's video -    \\u2022 Video  \\nThe Matriarchal Lineage of Corruption -    \\u2022 Video  \\nStefan's channel -     / channel  \\nWebsite: https://freedomainradio.com/\\nStefan's sources - http://www.fdrurl.com/fall-of-rome\\n\\nAnything else available on request.\\n\\nMost stuff by Shaun, additional research by Jen. That's right, she actually put a little work in for once. Shaun now dead from shock\\nKey moments\\nView all\\nSlavery\\n8:18\\nFall of Rome The Decline\\n15:50\\nFamily\\n29:38\\nFall of Rome The End\\n31:19\\nFall of Rome Size of Empire\\n35:34\\nTranscript\\nFollow along using the transcript.\\nShow transcript\\nShaun\\n713K subscribers\\nVideos\\nAbout\\nTwitter\\nPatreon\\nShow less\",\n          \"Explore the 2022 Nissan Pathfinder. View key interior and exterior features, including Intelligent 4x4, seamless connectivity, and advanced driver-assist and safety technologies. Learn more about the all-new 2022 Pathfinder here: \\nhttps://www.nissanusa.com/vehicles/cr...\\n\\n2022 Nissan Pathfinder \\n00:00 Intro\\n00:17 Performance and Capability \\n00:19 New 9-speed automatic transmission \\n00:29 3.5-liter V6 engine \\n00:31 259 lb-ft of torque \\n00:32 284 Horsepower\\n00:35 Up to 6,000-lb. maximum towing capacity \\n00:43 Underfloor storage \\n00:49 EZ FLEX\\u00ae seating on both sides \\n00:55 Cavernous cargo space \\n01:00 New Intelligent 4x4 \\n01:08 Seven Drive and Terrain Modes \\n01:18 Intelligent Around View\\u00ae Monitor \\n\\n01:40 Connectivity \\n01:46 Wireless Charging \\n01:52 Wireless Apple CarPlay\\u00ae integration \\n01:57 Larger Touch-Screen Display \\n02:05 Fully Customizable Digital Displays \\n02:14 Apple Maps \\n02:18 Google Maps\\u2122 Satellite View \\n02:20 Waze\\u2122 \\n02:22 Nissan Door to Door Navigation \\n02:27 Head-Up Display \\n02:30 2nd-row Captain's Chairs with removable center console \\n02:35 Wi-Fi Hotspot, 6 USB ports, 120-volt outlet \\n \\n02:51 Driver Assist and Safety Technologies\\n02:56 Standard Safety Shield\\u00ae 360 \\n02:58 Standard Rear Cross Traffic Alert \\n03:03 Standard Rear Automatic Braking \\n03:10 Standard Automatic Emergency Braking with Pedestrian Detection \\n03:25 Intelligent Blind Spot Intervention \\n03:35 Intelligent Lane Intervention\\n\\nConnect With Us Online: \\nWebsite \\u2013 https://www.NissanUSA.com\\nFacebook \\u2013   / nissanusa  \\nTwitter:   / nissanusa  \\nInstagram:   / nissanusa  \\nPinterest \\u2013   / nissanusa  \\n\\n#Nissan #Pathfinder #NissanPathfinder\\nChapters\\nView all\\nIntro\\n0:00\\nPerformance and Capability\\n0:17\\nNew 9-speed automatic transmission\\n0:19\\n3.5-liter V6 engine\\n0:29\\n284 Horsepower\\n0:32\\nTranscript\\nFollow along using the transcript.\\nShow transcript\\nNissan USA\\n458K subscribers\\nVideos\\nAbout\\nFacebook\\nTwitter\\nInstagram\\nPinterest\\n2022 Nissan Pathfinder\\nClick to discover more\\nShow less\",\n          \"C. J. Chivers reports from Marja, Afghanistan, where Marines face stiff resistance from Taliban fighters, including a rarity, a trained marksman.\\n\\nRelated Article: http://nyti.ms/9FPV24\\n\\nSubscribe to the Times Video newsletter for free and get a handpicked selection of the best videos from The New York Times every week: http://bit.ly/timesvideonewsletter\\n\\nSubscribe on YouTube: http://bit.ly/U8Ys7n\\n\\nWatch more videos at: http://nytimes.com/video\\n\\n---------------------------------------------------------------\\n\\nWant more from The New York Times?\\n\\nTwitter:   / nytvideo  \\n\\nFacebook:   / nytimes  \\n\\nGoogle+: https://plus.google.com/+nytimes/\\n\\nWhether it's reporting on conflicts abroad and political divisions at home, or covering the latest style trends and scientific developments, New York Times video journalists provide a revealing and unforgettable view of the world. It's all the news that's fit to watch. On YouTube.\\n\\nWorld: The Inches That Matter - nytimes.com/video\\n   / thenewyorktimes  \\nTranscript\\nFollow along using the transcript.\\nShow transcript\\nThe New York Times\\n4.53M subscribers\\nVideos\\nAbout\\nShow less\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_video_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 233,\n        \"samples\": [\n          \"MrBeast showcases various expensive cars and their unique door opening mechanisms.\",\n          \"This video showcases the evolution of Jeep brand vehicles throughout its 75 years, from the 1941 Willys MA to the modern Jeep Wrangler.\",\n          \"This video is a commercial for the 2022 Toyota GR86. It shows the Gazoo Racing team trying to get an enthusiast focus group excited about the new car.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv0lG0r115ZQ",
        "outputId": "ae8693d3-e28e-4e95-a801-28bcd31cfdab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 233 entries, 0 to 232\n",
            "Data columns (total 4 columns):\n",
            " #   Column                   Non-Null Count  Dtype \n",
            "---  ------                   --------------  ----- \n",
            " 0   channel_name             233 non-null    object\n",
            " 1   video_title              233 non-null    object\n",
            " 2   video_description        233 non-null    object\n",
            " 3   clean_video_description  233 non-null    object\n",
            "dtypes: object(4)\n",
            "memory usage: 7.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_xurw7y2NPKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lRGB4GreNPHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split the dataset into training and validation sets (80-20 split)\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "X6IS6hfS2oR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KVA0XjikNPEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizer and Model\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Tokenization Function (with dynamic padding)\n",
        "def tokenize_data(example):\n",
        "    model_inputs = tokenizer(\n",
        "        example[\"input\"],\n",
        "        max_length=512,\n",
        "        padding=\"longest\",  # Dynamic padding\n",
        "        truncation=True\n",
        "    )\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            example[\"output\"],\n",
        "            max_length=128,\n",
        "            padding=\"longest\",  # Dynamic padding for labels\n",
        "            truncation=True\n",
        "        )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Data preparation (assuming train_df and val_df exist)\n",
        "formatted_train_data = [\n",
        "    {\n",
        "        \"input\": f\"Channel: {row['channel_name']}, Title: {row['video_title']}, Description: {row['video_description']}\",\n",
        "        \"output\": row['clean_video_description']\n",
        "    }\n",
        "    for _, row in train_df.iterrows()\n",
        "]\n",
        "\n",
        "formatted_val_data = [\n",
        "    {\n",
        "        \"input\": f\"Channel: {row['channel_name']}, Title: {row['video_title']}, Description: {row['video_description']}\",\n",
        "        \"output\": row['clean_video_description']\n",
        "    }\n",
        "    for _, row in val_df.iterrows()\n",
        "]\n",
        "\n",
        "# Convert data to Hugging Face Dataset\n",
        "train_dataset = Dataset.from_list(formatted_train_data)\n",
        "val_dataset = Dataset.from_list(formatted_val_data)\n",
        "\n",
        "# Tokenize datasets\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_data, batched=True)\n",
        "tokenized_val_dataset = val_dataset.map(tokenize_data, batched=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "0QFxE73lGzWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jZGLR5p4NqIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Fine-Tuning the BART Model with LoRA**\n",
        "\n",
        "**Who is LoRA?**\n",
        "\n",
        "LoRA, which stands for Low-Rank Adaptation, is a technique used in fine-tuning large language models (LLMs) to make them more efficient and less computationally expensive.\n",
        "\n",
        "Key points about LoRA:\n",
        "\n",
        "- Reduced parameter updates: Instead of updating all the parameters of a pre-trained LLM during fine-tuning, LoRA focuses on updating a smaller set of parameters, specifically low-rank matrices that are added to the existing model weights.\n",
        "- Efficiency: This approach significantly reduces the number of trainable parameters, leading to faster training times and lower memory requirements compared to traditional fine-tuning methods.\n",
        "- Preserved performance: Despite the reduction in updated parameters, LoRA has been shown to achieve comparable or even better performance than full fine-tuning in many cases.\n",
        "- Adaptability: It can be easily integrated with various LLM architectures and fine-tuning tasks.\n",
        "\n",
        "LoRA offers a practical and effective solution to fine-tune large language models for specific tasks without incurring the high computational costs associated with full fine-tuning.\n",
        "\n",
        "\n",
        "\n",
        "**To fine-tune the BART model with LoRA, we will follow these steps:**\n",
        "\n",
        "\n",
        "1. **Set Up LoRA Configuration:** Defining the LoRA parameters such as rank `(r)`, scaling factor `(lora_alpha)`, target modules `(q_proj and v_proj)`, dropout rate `(lora_dropout)`, etc.\n",
        "2. **Wrap the BART Model with LoRA:** We use the peft library to apply LoRA to the original BART model, which allows for efficient fine-tuning with fewer trainable parameters.\n",
        "3. **Define Training Arguments:** Configuring the training parameters like `batch size`, `number of epochs`, `learning rate`, `logging steps`, `evaluation strategy`, and `saving intervals` using the `TrainingArguments` class from Hugging Face.\n",
        "4. **Define the Compute Metrics Function:** Setting up a function to compute evaluation metrics such as `ROUGE scores`, which measure the quality of the generated summaries against the reference summaries.\n",
        "5. **Train the Model:** We use the Hugging Face Trainer to fine-tune the LoRA-wrapped model on the training dataset while evaluating it on a validation dataset during training to monitor the model's performance.\n",
        "6. **Evaluate the Fine-Tuned Model:** After training,we evaluate the model's performance on the validation dataset using the `ROUGE metric` to understand how well the model generates summaries.\n",
        "7. **Save the Fine-Tuned Model:** Lastly we save the fine-tuned model and tokenizer for future use in generating summaries or further fine-tuning.\n"
      ],
      "metadata": {
        "id": "5TUlyLz1-ISN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gllD9MocN87k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **LoRA Configuration:**\n",
        "- The `LoraConfig` class is used to define the configuration for Low-Rank Adaptation.\n",
        "- Key parameters include:\n",
        "> - `r`: The rank of the LoRA matrix.\n",
        "> - `lora_alpha`: Scaling factor for LoRA.\n",
        "> - `target_modules`: Specifies which modules in the model should have LoRA applied (usually the attention layers).\n",
        "> - `lora_dropout`: Dropout rate to be applied to LoRA.\n",
        "> - `bias`: Specifies how to handle biases; in this case, no bias is applied (\"none\").\n",
        "2. **Wrap the BART Model with LoRA:**\n",
        "- The `get_peft_model` function from the peft library wraps the original BART model with LoRA, making it suitable for `parameter-efficient fine-tuning`.\n",
        "3. **Defining Training Arguments:**\n",
        "- TrainingArguments defines various parameters for the training process:\n",
        "> - `num_train_epochs`: Number of epochs for training.\n",
        "> - `per_device_train_batch_size` and `per_device_eval_batch_size`: Batch sizes for training and evaluation.\n",
        "> - `logging_steps`: Frequency of logging training metrics.\n",
        "> - `eval_steps`: Frequency of evaluation during training.\n",
        "> - `save_steps`: Frequency of saving model checkpoints.\n",
        "4. **Trainer Setup and Training:**\n",
        "- The Trainer class handles the training loop, evaluation, and checkpointing. It takes the LoRA model and training arguments as input.\n",
        "5. **Save the Fine-Tuned Model:**\n",
        "- After training, the fine-tuned model and tokenizer are saved using the save_pretrained method.\n"
      ],
      "metadata": {
        "id": "ePZOS3bbSY1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LoRA Configuration\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        ")\n",
        "\n",
        "# Apply LoRA\n",
        "lora_model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Post-processing function to clean generated summaries\n",
        "def post_process_summary(summary):\n",
        "    summary = re.sub(r\"http\\S+\", \"\", summary)  # Remove URLs\n",
        "    return summary.strip()\n",
        "\n",
        "\n",
        "# # Define Evaluation Metric and Compute Function\n",
        "rouge_metric = evaluate.load('rouge')  # Load the metric with evaluate\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Post-process summaries to remove unwanted tokens\n",
        "    decoded_preds = [post_process_summary(pred) for pred in decoded_preds]\n",
        "    decoded_labels = [post_process_summary(label) for label in decoded_labels]\n",
        "\n",
        "    # ROUGE expects newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(pred.strip().split(\". \")) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(label.strip().split(\". \")) for label in decoded_labels]\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    rouge_result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    rouge_result = {key: value.mid.fmeasure * 100 for key, value in rouge_result.items()}\n",
        "\n",
        "    return rouge_result\n"
      ],
      "metadata": {
        "id": "FWQysYqmGzQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ExbQCMrnGzNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Arguments (with enhancements)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=12,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_steps=1000,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    gradient_accumulation_steps=8,   # Simulate larger batch size (32)\n",
        "    fp16=True,                       # Mixed precision training\n",
        "    lr_scheduler_type=\"cosine_with_restarts\",  # Learning rate scheduler\n",
        ")\n",
        "\n",
        "# Trainer with Early Stopping\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]  # Early stopping after 3 non-improving evaluations\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "-2z1yus9HeNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ct3ac4rAGzKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation Results: {eval_results}\")\n",
        "\n",
        "# Save and Push to Hugging Face Hub\n",
        "lora_model.save_pretrained(\"./Bart-Desc-Sum-fine-tuned-lora-model\")\n",
        "tokenizer.save_pretrained(\"./Bart-Desc-Sum-fine-tuned-lora-model\")\n"
      ],
      "metadata": {
        "id": "wre0SRShHqaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Push to Hugging Face Hub\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n",
        "\n",
        "lora_model.push_to_hub(\"kkrusere/Bart-Desc-Sum-fine-tuned-lora-model\")\n",
        "tokenizer.push_to_hub(\"kkrusere/Bart-Desc-Sum-fine-tuned-lora-model\")"
      ],
      "metadata": {
        "id": "75I-qDMaHvA1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lxSfQmarHqV2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
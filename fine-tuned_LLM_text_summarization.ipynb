{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn3vHjrgdvbN"
      },
      "source": [
        "### **<center>Transformer-Based Summarization for Cleaning YouTube Video Descriptions</center>**\n",
        "\n",
        "<center><em>\n",
        "Leverage the power of transformer-based text summarization to automatically remove irrelevant information from YouTube video descriptions, ensuring they're concise and informative.\n",
        "</em></center>\n",
        "\n",
        "#### Intro:\n",
        "\n",
        "YouTube video descriptions are vital for attracting viewers, but often contain extraneous information that hinders understanding. This project utilizes transformer-based text summarization models (like BERT and GPT) to automatically clean these descriptions.\n",
        "\n",
        "By training a summarization model on a dataset of YouTube descriptions paired with their human-refined counterparts, the model learns to identify and remove irrelevant content while preserving key points. This leads to concise, informative descriptions.\n",
        "\n",
        "The project will explore the fine-tuning and evaluation of transformer models for this specific summarization task, focusing on their ability to remove extraneous information and produce distilled video descriptions.\n",
        "\n",
        "**Key Points:**\n",
        "- Problem: YouTube descriptions often contain excessive tags, promotions, and irrelevant details.\n",
        "- Solution: Transformer-based text summarization models trained to clean descriptions.\n",
        "- Approach: Fine-tune models on a dataset of original and human-cleaned descriptions.\n",
        "- Goal: Produce concise, informative descriptions that enhance user experience.\n",
        "- Evaluation: Focus on the models' ability to remove extraneous information effectively."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H8bQWUQEd73_"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "\n",
        "wget -N https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/118.0.5993.70/linux64/chromedriver-linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver-linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver-linux64/chromedriver\n",
        "mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver\n",
        "pip install selenium chromedriver_autoinstaller"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL5_Z_Nxd7HS",
        "outputId": "a62f11fc-2ad1-4e86-f0dc-627a10640e9d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Ign:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Fetched 257 kB in 2s (148 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "50 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.81.0-1ubuntu1.17).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "You might want to run 'apt --fix-broken install' to correct these.\n",
            "The following packages have unmet dependencies:\n",
            " google-chrome-stable : Depends: libvulkan1 but it is not going to be installed\n",
            "\u001b[1;31mE: \u001b[0mUnmet dependencies. Try 'apt --fix-broken install' with no packages (or specify a solution).\u001b[0m\n",
            "--2024-09-08 19:11:08--  http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
            "Resolving archive.ubuntu.com (archive.ubuntu.com)... 185.125.190.81, 91.189.91.82, 91.189.91.81, ...\n",
            "Connecting to archive.ubuntu.com (archive.ubuntu.com)|185.125.190.81|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3708 (3.6K) [application/vnd.debian.binary-package]\n",
            "Saving to: ‚Äòlibu2f-udev_1.1.4-1_all.deb.1‚Äô\n",
            "\n",
            "libu2f-udev_1.1.4-1 100%[===================>]   3.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-09-08 19:11:08 (500 MB/s) - ‚Äòlibu2f-udev_1.1.4-1_all.deb.1‚Äô saved [3708/3708]\n",
            "\n",
            "(Reading database ... 123718 files and directories currently installed.)\n",
            "Preparing to unpack libu2f-udev_1.1.4-1_all.deb ...\n",
            "Unpacking libu2f-udev (1.1.4-1) over (1.1.4-1) ...\n",
            "Setting up libu2f-udev (1.1.4-1) ...\n",
            "--2024-09-08 19:11:08--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 172.253.118.93, 172.253.118.190, 172.253.118.91, ...\n",
            "Connecting to dl.google.com (dl.google.com)|172.253.118.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 110842868 (106M) [application/x-debian-package]\n",
            "Saving to: ‚Äògoogle-chrome-stable_current_amd64.deb.1‚Äô\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 105.71M  89.3MB/s    in 1.2s    \n",
            "\n",
            "2024-09-08 19:11:10 (89.3 MB/s) - ‚Äògoogle-chrome-stable_current_amd64.deb.1‚Äô saved [110842868/110842868]\n",
            "\n",
            "(Reading database ... 123718 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (128.0.6613.119-1) over (128.0.6613.119-1) ...\n",
            "\u001b[1mdpkg:\u001b[0m dependency problems prevent configuration of google-chrome-stable:\n",
            " google-chrome-stable depends on libvulkan1; however:\n",
            "  Package libvulkan1 is not installed.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m error processing package google-chrome-stable (--install):\n",
            " dependency problems - leaving unconfigured\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Errors were encountered while processing:\n",
            " google-chrome-stable\n",
            "--2024-09-08 19:11:19--  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/118.0.5993.70/linux64/chromedriver-linux64.zip\n",
            "Resolving edgedl.me.gvt1.com (edgedl.me.gvt1.com)... 34.104.35.123, 2600:1900:4110:86f::\n",
            "Connecting to edgedl.me.gvt1.com (edgedl.me.gvt1.com)|34.104.35.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://storage.googleapis.com/chrome-for-testing-public/118.0.5993.70/linux64/chromedriver-linux64.zip [following]\n",
            "--2024-09-08 19:11:19--  https://storage.googleapis.com/chrome-for-testing-public/118.0.5993.70/linux64/chromedriver-linux64.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.118.207, 74.125.200.207, 74.125.130.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.118.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 304 Not Modified\n",
            "File ‚Äò/tmp/chromedriver-linux64.zip‚Äô not modified on server. Omitting download.\n",
            "\n",
            "Archive:  /tmp/chromedriver-linux64.zip\n",
            "  inflating: /tmp/chromedriver-linux64/LICENSE.chromedriver  \n",
            "  inflating: /tmp/chromedriver-linux64/chromedriver  \n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.24.0)\n",
            "Requirement already satisfied: chromedriver_autoinstaller in /usr/local/lib/python3.10/dist-packages (0.6.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.26.2)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.8.30)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver_autoinstaller) (24.1)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.8)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft\n",
        "!pip install datasets\n",
        "!pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCv7HwWr68Ss",
        "outputId": "1a75cca4-3c0b-4257-d486-7e8bc51bb518"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.33.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.24.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.5)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=088051753549d0f7b2ee09ea2585bbe98a0ece9ce5f9aa0c65177f4839e111c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "kMKkbHhrdvbP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "\n",
        "from selenium import webdriver\n",
        "import chromedriver_autoinstaller\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.common.exceptions import TimeoutException, ElementNotInteractableException\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import random\n",
        "import re\n",
        "import json\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_webdriver():\n",
        "    \"\"\"Initializes and returns a Chrome WebDriver instance with options.\n",
        "\n",
        "    Returns:\n",
        "        webdriver.Chrome: A configured Chrome WebDriver instance.\n",
        "\n",
        "    Raises:\n",
        "        Exception: If the WebDriver fails to initialize.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        chrome_options = webdriver.ChromeOptions()\n",
        "        chrome_options.add_argument('--headless')\n",
        "        chrome_options.add_argument('--no-sandbox')\n",
        "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "        chromedriver_autoinstaller.install()\n",
        "        driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "        print(\"WebDriver initialized successfully\")\n",
        "        return driver\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to initialize WebDriver: {e}\")\n",
        "        raise\n",
        "\n",
        "\n",
        "def close_webdriver(driver):\n",
        "    \"\"\"Closes the provided WebDriver instance.\n",
        "\n",
        "    Args:\n",
        "        driver (webdriver.Chrome): The WebDriver instance to close.\n",
        "\n",
        "    Prints:\n",
        "        str: Confirmation message that the WebDriver has been closed.\n",
        "    \"\"\"\n",
        "    print(\"WebDriver successfully closed\")\n",
        "    driver.quit()\n"
      ],
      "metadata": {
        "id": "uEqA5OxQeL3s"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q7Nv9LM250Kt"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_data(video_id):\n",
        "    \"\"\"Fetches video data from YouTube given a video ID.\n",
        "\n",
        "    Args:\n",
        "        video_id (str): The ID of the YouTube video to fetch data for.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the video data with the following keys:\n",
        "            - 'channel_name': The name of the channel that uploaded the video.\n",
        "            - 'video_title': The title of the video.\n",
        "            - 'video_description': The description of the video.\n",
        "\n",
        "    Raises:\n",
        "        Exception: If there is an error accessing or processing the video data.\n",
        "    \"\"\"\n",
        "    driver = init_webdriver()\n",
        "    video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "    video_data = {}\n",
        "\n",
        "    try:\n",
        "        driver.get(video_url)\n",
        "\n",
        "        try:\n",
        "            # Wait for the bottom-row element to be present\n",
        "            bottom_row = WebDriverWait(driver, 20).until(\n",
        "                EC.presence_of_element_located((By.XPATH, '//*[@id=\"bottom-row\"]'))\n",
        "            )\n",
        "\n",
        "            # Locate and click the expand button if it exists\n",
        "            try:\n",
        "                expand_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[4]/div[1]/div/ytd-text-inline-expander/tp-yt-paper-button[1]'))\n",
        "                )\n",
        "                expand_button.click()\n",
        "            except TimeoutException:\n",
        "                pass  # Ignore if the expand button is not found\n",
        "\n",
        "            # Wait for elements to be visible and extract data\n",
        "            expanded_description = WebDriverWait(driver, 10).until(\n",
        "                EC.visibility_of_element_located((By.ID, 'description-inline-expander'))\n",
        "            )\n",
        "            title_element = WebDriverWait(driver, 10).until(\n",
        "                EC.presence_of_element_located((By.XPATH, '//h1[@class=\"style-scope ytd-watch-metadata\"]//yt-formatted-string'))\n",
        "            )\n",
        "            channel_name_element = WebDriverWait(driver, 10).until(\n",
        "                EC.presence_of_element_located((By.XPATH, '//ytd-channel-name[@id=\"channel-name\"]//yt-formatted-string//a'))\n",
        "            )\n",
        "\n",
        "            video_data = {\n",
        "                'channel_name': channel_name_element.text,\n",
        "                'video_title': title_element.text,\n",
        "                'video_description': expanded_description.text\n",
        "            }\n",
        "\n",
        "        except TimeoutException:\n",
        "            print(f\"Error processing {video_url}: Elements not found within timeout.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {video_url}: {e}\")\n",
        "\n",
        "    finally:\n",
        "        # Close the browser when done\n",
        "        close_webdriver(driver)\n",
        "\n",
        "    return video_data\n"
      ],
      "metadata": {
        "id": "En6u1rRcLnaw"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test:\n",
        "video_id = \"CETSlLO_jio\"\n",
        "# Get video data\n",
        "video_data = get_video_data(video_id)\n",
        "\n",
        "# Print the data\n",
        "video_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn2O567VNzNL",
        "outputId": "16b15f46-dae4-4efe-a974-f00b26504a94"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WebDriver initialized successfully\n",
            "WebDriver successfully closed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'channel_name': 'truTV',\n",
              " 'video_title': 'Funniest If You Laugh You Lose Moments (Mashup) | Impractical Jokers | truTV',\n",
              " 'video_description': 'It\\'s impossible not to laugh at the way Murr rides away on his luggage. We can\\'t get enough of these \"If You Laugh, You Lose\" challenges. Watch Impractical Jokers on truTV.\\n\\n#ImpracticalJokers  #truTV #BrianQuinn #JamesMurray #SalVulcano\\n\\nSubscribe: http://bit.ly/truTVSubscribe\\nWatch More Impractical Jokers: http://bit.ly/2p59m19\\nWatch full episodes for Free: http://bit.ly/ImpracticalJokersTruTV\\n\\nAbout Impractical Jokers:\\nThree comedians and lifelong friends compete to embarrass each other amongst the general public with a series of hilarious and outrageous dares. When Sal, Q, and Murr challenge each other to say or do something, they have to do it‚Ä¶ if they refuse, they lose! At the end of every episode - with the help of a celebrity guest - the episode\\'s loser must endure a punishment of epic proportions.\\n\\nDownload the Jokers Wheel of Doom Mobile Game: trutv.com/jokersgame\\nSubscribe to The Official Impractical Jokers Podcast: http://bit.ly/ImpracticalJokersPodcast\\n\\nWatch Full Episodes On Demand and on the truTV App\\nSee more from truTV: http://bit.ly/FunnyBecauseItsTRU\\nLike truTV on Facebook: http://bit.ly/truTVFacebook\\nFollow truTV on Twitter: http://bit.ly/truTVTweets\\nFollow truTV on Instagram: http://bit.ly/truTVInsta\\n\\nAbout truTV:\\nThe home of Impractical Jokers, Tacoma FD, Adams Ruins Everything, movies and more.      \\n\\nFunniest If You Laugh You Lose Moments (Mashup) | Impractical Jokers | truTV\\n   ‚Ä¢ Funniest If You Laugh You Lose Moment...  \\n\\ntruTV\\n   / trutv  \\nTranscript\\nFollow along using the transcript.\\nShow transcript\\ntruTV\\n3.51M subscribers\\nVideos\\nAbout\\nFacebook\\nInstagram\\nTikTok\\n46\\nFunniest Moments: Impractical Jokers | truTV\\nby truTV\\nTru Home Page | truTV.com\\nVisit our website | truTV.com\\nShow less'}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hKoBXt59Qk9-"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Collection - Overview**\n",
        "- The data collection process involves gathering YouTube video descriptions along with additional metadata, such as the channel name and video title. We are going to use the above functions for this. This data will be used to train and evaluate our transformer-based summarization model.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "- Fetch Video Data:\n",
        "Iterate through a predefined list of YouTube video IDs.\n",
        "> For each video ID, use a custom function to retrieve the video data.\n",
        "- The function fetches:\n",
        "> - Channel Name: The name of the channel where the video was uploaded.\n",
        "> - Video Title: The title of the video.\n",
        "> - Video Description: The description text provided by the video uploader.\n",
        "- Store Data:\n",
        "> - Append the retrieved data, formatted as a dictionary, to the list.\n",
        "> - Store the collected data in a file (e.g., JSON or CSV) to facilitate access and further processing.\n",
        "\n",
        "**Example Output**\n",
        "> - The collected data will be a list of dictionaries, each containing the following keys:\n",
        "\n",
        "> - ```yaml\n",
        "channel_name: The name of the YouTube channel.\n",
        "video_title: The title of the video.\n",
        "video_description: The description text of the video.\n"
      ],
      "metadata": {
        "id": "4Qmp57fTVwtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "#mounting google drive\n",
        "drive.mount('/content/drive')\n",
        "########################################\n",
        "#changing the working directory\n",
        "os.chdir(\"/content/drive/MyDrive/NLP_Data\")\n",
        "\n",
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPKUgB2yW8Zv",
        "outputId": "4d8c2520-0921-4252-8dd2-5184a3bd0161"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/NLP_Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# below are functions for reading a writting json file for the current working directory\n",
        "\n",
        "def save_to_json(data, filename):\n",
        "    with open(filename, 'w') as json_file:\n",
        "        json.dump(data, json_file, indent=4)\n",
        "\n",
        "def load_from_json(filename):\n",
        "    with open(filename, 'r') as json_file:\n",
        "        comments = json.load(json_file)\n",
        "    return comments"
      ],
      "metadata": {
        "id": "lobNB2YAXl2q"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SHxdsKIBf5-T"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('video_data.csv')\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "aO-vzVm6C_Zi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "ce502d30-3ba3-470f-809c-0eb7e78d3757"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      channel_name                                        video_title  \\\n",
              "0  LastWeekTonight  Miss America Pageant: Last Week Tonight with J...   \n",
              "1             ESPN  Smooth üî• (via @dariusgaddy2, @d.looo_/TT) #shorts   \n",
              "2      PowerfulJRE            Joe Rogan Experience #1227 - Mike Tyson   \n",
              "3      PowerfulJRE  Joe Rogan Experience #872 - Graham Hancock & R...   \n",
              "4    Mentour Pilot                   HOW was THIS Allowed to HAPPEN?!   \n",
              "\n",
              "                                   video_description  \\\n",
              "0  The Miss America Pageant‚Ä¶how is this still a t...   \n",
              "1  ‚úîÔ∏è Subscribe to ESPN+ http://espnplus.com/yout...   \n",
              "2  Mike Tyson is the former undisputed heavyweigh...   \n",
              "3  Graham Hancock is an English author and journa...   \n",
              "4  Go to https://curiositystream.thld.co/mento......   \n",
              "\n",
              "                             clean_video_description  \n",
              "0  John Oliver criticizes the Miss America Pagean...  \n",
              "1  This is a short video showcasing smooth moves ...  \n",
              "2  Mike Tyson, the former undisputed heavyweight ...  \n",
              "3  Graham Hancock and Randall Carlson discuss cro...  \n",
              "4  This video explores a close call between two A...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b075ed29-2a65-4763-b548-2de588afd692\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel_name</th>\n",
              "      <th>video_title</th>\n",
              "      <th>video_description</th>\n",
              "      <th>clean_video_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LastWeekTonight</td>\n",
              "      <td>Miss America Pageant: Last Week Tonight with J...</td>\n",
              "      <td>The Miss America Pageant‚Ä¶how is this still a t...</td>\n",
              "      <td>John Oliver criticizes the Miss America Pagean...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ESPN</td>\n",
              "      <td>Smooth üî• (via @dariusgaddy2, @d.looo_/TT) #shorts</td>\n",
              "      <td>‚úîÔ∏è Subscribe to ESPN+ http://espnplus.com/yout...</td>\n",
              "      <td>This is a short video showcasing smooth moves ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PowerfulJRE</td>\n",
              "      <td>Joe Rogan Experience #1227 - Mike Tyson</td>\n",
              "      <td>Mike Tyson is the former undisputed heavyweigh...</td>\n",
              "      <td>Mike Tyson, the former undisputed heavyweight ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PowerfulJRE</td>\n",
              "      <td>Joe Rogan Experience #872 - Graham Hancock &amp; R...</td>\n",
              "      <td>Graham Hancock is an English author and journa...</td>\n",
              "      <td>Graham Hancock and Randall Carlson discuss cro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mentour Pilot</td>\n",
              "      <td>HOW was THIS Allowed to HAPPEN?!</td>\n",
              "      <td>Go to https://curiositystream.thld.co/mento......</td>\n",
              "      <td>This video explores a close call between two A...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b075ed29-2a65-4763-b548-2de588afd692')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b075ed29-2a65-4763-b548-2de588afd692 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b075ed29-2a65-4763-b548-2de588afd692');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 233,\n  \"fields\": [\n    {\n      \"column\": \"channel_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"Shaun\",\n          \"HasanAbi\",\n          \"LastWeekTonight\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 231,\n        \"samples\": [\n          \"Face Swap Masters - Best of Just For Laughs Gags\",\n          \"Celebrating the life of Jessi Combs\",\n          \"World: The Inches That Matter | The New York Times\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 230,\n        \"samples\": [\n          \"If you make it through this video you get a prize.\\n\\nSmiling at the laziness of just stealing his thumbnail and writing 'response' on it. Leave me alone, I've got the flu.\\n\\nContact:\\n\\nTwitter -   / shaun_jen  \\nask.fm - http://ask.fm/shaun_jen\\n\\nSources:\\n\\nStefan's video -    \\u2022 Video  \\nThe Matriarchal Lineage of Corruption -    \\u2022 Video  \\nStefan's channel -     / channel  \\nWebsite: https://freedomainradio.com/\\nStefan's sources - http://www.fdrurl.com/fall-of-rome\\n\\nAnything else available on request.\\n\\nMost stuff by Shaun, additional research by Jen. That's right, she actually put a little work in for once. Shaun now dead from shock\\nKey moments\\nView all\\nSlavery\\n8:18\\nFall of Rome The Decline\\n15:50\\nFamily\\n29:38\\nFall of Rome The End\\n31:19\\nFall of Rome Size of Empire\\n35:34\\nTranscript\\nFollow along using the transcript.\\nShow transcript\\nShaun\\n713K subscribers\\nVideos\\nAbout\\nTwitter\\nPatreon\\nShow less\",\n          \"Explore the 2022 Nissan Pathfinder. View key interior and exterior features, including Intelligent 4x4, seamless connectivity, and advanced driver-assist and safety technologies. Learn more about the all-new 2022 Pathfinder here: \\nhttps://www.nissanusa.com/vehicles/cr...\\n\\n2022 Nissan Pathfinder \\n00:00 Intro\\n00:17 Performance and Capability \\n00:19 New 9-speed automatic transmission \\n00:29 3.5-liter V6 engine \\n00:31 259 lb-ft of torque \\n00:32 284 Horsepower\\n00:35 Up to 6,000-lb. maximum towing capacity \\n00:43 Underfloor storage \\n00:49 EZ FLEX\\u00ae seating on both sides \\n00:55 Cavernous cargo space \\n01:00 New Intelligent 4x4 \\n01:08 Seven Drive and Terrain Modes \\n01:18 Intelligent Around View\\u00ae Monitor \\n\\n01:40 Connectivity \\n01:46 Wireless Charging \\n01:52 Wireless Apple CarPlay\\u00ae integration \\n01:57 Larger Touch-Screen Display \\n02:05 Fully Customizable Digital Displays \\n02:14 Apple Maps \\n02:18 Google Maps\\u2122 Satellite View \\n02:20 Waze\\u2122 \\n02:22 Nissan Door to Door Navigation \\n02:27 Head-Up Display \\n02:30 2nd-row Captain's Chairs with removable center console \\n02:35 Wi-Fi Hotspot, 6 USB ports, 120-volt outlet \\n \\n02:51 Driver Assist and Safety Technologies\\n02:56 Standard Safety Shield\\u00ae 360 \\n02:58 Standard Rear Cross Traffic Alert \\n03:03 Standard Rear Automatic Braking \\n03:10 Standard Automatic Emergency Braking with Pedestrian Detection \\n03:25 Intelligent Blind Spot Intervention \\n03:35 Intelligent Lane Intervention\\n\\nConnect With Us Online: \\nWebsite \\u2013 https://www.NissanUSA.com\\nFacebook \\u2013   / nissanusa  \\nTwitter:   / nissanusa  \\nInstagram:   / nissanusa  \\nPinterest \\u2013   / nissanusa  \\n\\n#Nissan #Pathfinder #NissanPathfinder\\nChapters\\nView all\\nIntro\\n0:00\\nPerformance and Capability\\n0:17\\nNew 9-speed automatic transmission\\n0:19\\n3.5-liter V6 engine\\n0:29\\n284 Horsepower\\n0:32\\nTranscript\\nFollow along using the transcript.\\nShow transcript\\nNissan USA\\n458K subscribers\\nVideos\\nAbout\\nFacebook\\nTwitter\\nInstagram\\nPinterest\\n2022 Nissan Pathfinder\\nClick to discover more\\nShow less\",\n          \"C. J. Chivers reports from Marja, Afghanistan, where Marines face stiff resistance from Taliban fighters, including a rarity, a trained marksman.\\n\\nRelated Article: http://nyti.ms/9FPV24\\n\\nSubscribe to the Times Video newsletter for free and get a handpicked selection of the best videos from The New York Times every week: http://bit.ly/timesvideonewsletter\\n\\nSubscribe on YouTube: http://bit.ly/U8Ys7n\\n\\nWatch more videos at: http://nytimes.com/video\\n\\n---------------------------------------------------------------\\n\\nWant more from The New York Times?\\n\\nTwitter:   / nytvideo  \\n\\nFacebook:   / nytimes  \\n\\nGoogle+: https://plus.google.com/+nytimes/\\n\\nWhether it's reporting on conflicts abroad and political divisions at home, or covering the latest style trends and scientific developments, New York Times video journalists provide a revealing and unforgettable view of the world. It's all the news that's fit to watch. On YouTube.\\n\\nWorld: The Inches That Matter - nytimes.com/video\\n   / thenewyorktimes  \\nTranscript\\nFollow along using the transcript.\\nShow transcript\\nThe New York Times\\n4.53M subscribers\\nVideos\\nAbout\\nShow less\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_video_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 233,\n        \"samples\": [\n          \"MrBeast showcases various expensive cars and their unique door opening mechanisms.\",\n          \"This video showcases the evolution of Jeep brand vehicles throughout its 75 years, from the 1941 Willys MA to the modern Jeep Wrangler.\",\n          \"This video is a commercial for the 2022 Toyota GR86. It shows the Gazoo Racing team trying to get an enthusiast focus group excited about the new car.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv0lG0r115ZQ",
        "outputId": "2669eeb2-c280-461d-c6f1-279a8bc5dcc5"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 233 entries, 0 to 232\n",
            "Data columns (total 4 columns):\n",
            " #   Column                   Non-Null Count  Dtype \n",
            "---  ------                   --------------  ----- \n",
            " 0   channel_name             233 non-null    object\n",
            " 1   video_title              233 non-null    object\n",
            " 2   video_description        233 non-null    object\n",
            " 3   clean_video_description  233 non-null    object\n",
            "dtypes: object(4)\n",
            "memory usage: 7.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split the dataset into training and validation sets (80-20 split)\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "X6IS6hfS2oR_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Data Preparation for Fine-Tuning**\n",
        "\n",
        "\n",
        "1. **Data Formatting:**\n",
        "- Each row is formatted to include a combined input of `channel_name`, `video_title`, and `video_description`.\n",
        "- The target output is `clean_video_descriptions`.\n",
        "2. **Converting to Dataset Object:**\n",
        "- `Dataset.from_list(formatted_data)` converts the list of formatted `input-output` pairs into a `Hugging Face Dataset` object.\n",
        "3. **Tokenization:**\n",
        "- The `tokenize_data` function tokenizes both the input text and the target text.\n",
        "- The tokenized target is added to the input dictionary under `\"labels\"`, as required for `seq2seq` training.\n",
        "4. **Tokenized Dataset:**\n",
        "- The tokenized dataset, `tokenized_datasets`, is now ready for `fine-tuning` the `BART` model using `LoRA`.\n"
      ],
      "metadata": {
        "id": "2AG1hd6B2o02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "from transformers import BartTokenizer"
      ],
      "metadata": {
        "id": "1la7nIQT2Kbh"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the tokenizer\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "# Data Preparation\n",
        "# Format the data for training\n",
        "formatted_train_data = [\n",
        "    {\n",
        "        \"input\": f\"Channel: {row['channel_name']}, Title: {row['video_title']}, Description: {row['video_description']}\",\n",
        "        \"output\": row['clean_video_description']\n",
        "    }\n",
        "    for _, row in train_df.iterrows()\n",
        "]\n",
        "\n",
        "# Format the data for validation\n",
        "formatted_val_data = [\n",
        "    {\n",
        "        \"input\": f\"Channel: {row['channel_name']}, Title: {row['video_title']}, Description: {row['video_description']}\",\n",
        "        \"output\": row['clean_video_description']\n",
        "    }\n",
        "    for _, row in val_df.iterrows()\n",
        "]\n",
        "\n",
        "# Convert formatted data to Dataset objects\n",
        "train_dataset = Dataset.from_list(formatted_train_data)\n",
        "val_dataset = Dataset.from_list(formatted_val_data)\n",
        "\n",
        "# Tokenization\n",
        "\n",
        "# Load the tokenizer\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenization function for training and validation datasets\n",
        "def tokenize_data(example):\n",
        "    model_inputs = tokenizer(\n",
        "        example[\"input\"],\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            example[\"output\"],\n",
        "            max_length=128,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True\n",
        "        )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Tokenize datasets\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_data, batched=True)\n",
        "tokenized_val_dataset = val_dataset.map(tokenize_data, batched=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169,
          "referenced_widgets": [
            "dae349e3f9a84cca87b9c127f84f8b95",
            "b15017fcc68c4e15a138078db54e8685",
            "03b35202fce54fd08f0f843e2f926156",
            "f21ebb3451a7424eb1c8717314b7660b",
            "4de014de163c418590df5d24388d962e",
            "6b28e86af5304d3ab5ace74885d4479e",
            "a9bee76a308f45b98e10dffce203136e",
            "42a5ae0d91514cd5b81ce03cc26c0ccf",
            "792ba025f6c842d9b4363ff190f43730",
            "1900bdcec0b548ae9a7527ff12eb8ee8",
            "f75bd9508f2a48789e5323e81f674d91",
            "ae5717fea63a49b2a3fc486901a35fed",
            "fd808f66005c405490fa63716f4f7f04",
            "84af0fd21a49474f96f29ef6be71b71a",
            "e6b75d77fb9749879b295d6419a0484e",
            "81bf8a077bef4df3a99a5c43cf7d2296",
            "4825e7119eb14f209c46868b763a01b6",
            "92a871e8a0ba4b5b8fff9b038bb2a8ac",
            "cb5b331420e44ee7b63584e9ea8c3852",
            "da69bf6692f24f9eb00479a3ec109454",
            "0c952e1276ba4eb0b263fb6bb5109f74",
            "024609d876f4403d85986ee77449ff91"
          ]
        },
        "id": "NSf-PVxc4_tN",
        "outputId": "67ee051e-2f17-4882-836a-eb48a726546d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/186 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dae349e3f9a84cca87b9c127f84f8b95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/47 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae5717fea63a49b2a3fc486901a35fed"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "niONcm4o6g1F"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Fine-Tuning the BART Model with LoRA**\n",
        "\n",
        "**Who is LoRA?**\n",
        "\n",
        "LoRA, which stands for Low-Rank Adaptation, is a technique used in fine-tuning large language models (LLMs) to make them more efficient and less computationally expensive.\n",
        "\n",
        "Key points about LoRA:\n",
        "\n",
        "- Reduced parameter updates: Instead of updating all the parameters of a pre-trained LLM during fine-tuning, LoRA focuses on updating a smaller set of parameters, specifically low-rank matrices that are added to the existing model weights.\n",
        "- Efficiency: This approach significantly reduces the number of trainable parameters, leading to faster training times and lower memory requirements compared to traditional fine-tuning methods.\n",
        "- Preserved performance: Despite the reduction in updated parameters, LoRA has been shown to achieve comparable or even better performance than full fine-tuning in many cases.\n",
        "- Adaptability: It can be easily integrated with various LLM architectures and fine-tuning tasks.\n",
        "\n",
        "LoRA offers a practical and effective solution to fine-tune large language models for specific tasks without incurring the high computational costs associated with full fine-tuning.\n",
        "\n",
        "\n",
        "\n",
        "**To fine-tune the BART model with LoRA, we will follow these steps:**\n",
        "\n",
        "\n",
        "1. **Set Up LoRA Configuration:** Defining the LoRA parameters such as rank `(r)`, scaling factor `(lora_alpha)`, target modules `(q_proj and v_proj)`, dropout rate `(lora_dropout)`, etc.\n",
        "2. **Wrap the BART Model with LoRA:** We use the peft library to apply LoRA to the original BART model, which allows for efficient fine-tuning with fewer trainable parameters.\n",
        "3. **Define Training Arguments:** Configuring the training parameters like `batch size`, `number of epochs`, `learning rate`, `logging steps`, `evaluation strategy`, and `saving intervals` using the `TrainingArguments` class from Hugging Face.\n",
        "4. **Define the Compute Metrics Function:** Setting up a function to compute evaluation metrics such as `ROUGE scores`, which measure the quality of the generated summaries against the reference summaries.\n",
        "5. **Train the Model:** We use the Hugging Face Trainer to fine-tune the LoRA-wrapped model on the training dataset while evaluating it on a validation dataset during training to monitor the model's performance.\n",
        "6. **Evaluate the Fine-Tuned Model:** After training,we evaluate the model's performance on the validation dataset using the `ROUGE metric` to understand how well the model generates summaries.\n",
        "7. **Save the Fine-Tuned Model:** Lastly we save the fine-tuned model and tokenizer for future use in generating summaries or further fine-tuning.\n"
      ],
      "metadata": {
        "id": "5TUlyLz1-ISN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, load_metric\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model  # PEFT LoRA utilities\n",
        "\n",
        "\n",
        "\n",
        "# Loading the base BART model\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Configure LoRA\n",
        "lora_config = LoraConfig(\n",
        "    r=16,  # Rank of the LoRA matrix\n",
        "    lora_alpha=32,  # Scaling factor for LoRA\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],  # Target attention layers to apply LoRA\n",
        "    lora_dropout=0.05,  # Dropout rate for LoRA\n",
        "    bias=\"none\",  # No bias\n",
        ")\n",
        "\n",
        "# Wrap the original model with LoRA\n",
        "lora_model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Defining the Training Arguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",          # Output directory for model and checkpoints\n",
        "    num_train_epochs=3,              # Number of training epochs\n",
        "    per_device_train_batch_size=4,   # Batch size per device during training\n",
        "    per_device_eval_batch_size=4,    # Batch size per device during evaluation\n",
        "    warmup_steps=500,                # Number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # Strength of weight decay\n",
        "    logging_dir=\"./logs\",            # Directory for storing logs\n",
        "    logging_steps=10,                # Frequency of logging\n",
        "    save_steps=1000,                 # Number of steps before saving model checkpoint\n",
        "    evaluation_strategy=\"steps\",     # Evaluation strategy\n",
        "    eval_steps=500,                  # Frequency of evaluation steps\n",
        ")\n",
        "\n",
        "# Defining Evaluation Metric and Compute Function\n",
        "\n",
        "# Loading the evaluation metric\n",
        "rouge_metric = load_metric(\"rouge\")\n",
        "\n",
        "# Defining the compute_metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # ROUGE expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(pred.strip().split(\". \")) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(label.strip().split(\". \")) for label in decoded_labels]\n",
        "\n",
        "    # Compute ROUGE scores\n",
        "    result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    return result\n",
        "\n",
        "# Initializing the Trainer and then we Train the Model\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=lora_model,                # The LoRA model to fine-tune\n",
        "    args=training_args,              # Training arguments\n",
        "    train_dataset=tokenized_train_dataset,  # The tokenized training dataset\n",
        "    eval_dataset=tokenized_val_dataset,  # The tokenized validation dataset\n",
        "    compute_metrics=compute_metrics  # Metrics computation function\n",
        ")\n",
        "\n",
        "# Training the model with LoRA\n",
        "trainer.train()\n",
        "\n",
        "# Evaluating the model on the validation dataset\n",
        "\n",
        "eval_results = trainer.evaluate()\n",
        "\n",
        "print(f\"Evaluation Results: {eval_results}\")\n",
        "\n",
        "# Lastly we save the Fine-Tuned Model\n",
        "\n",
        "lora_model.save_pretrained(\"./fine-tuned-lora-model\")\n",
        "tokenizer.save_pretrained(\"./fine-tuned-lora-model\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "qaZDIcix-H3s",
        "outputId": "7ba804d9-0195-4760-998f-d49f4ea9edb2"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [141/141 01:39, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [12/12 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Results: {'eval_runtime': 4.819, 'eval_samples_per_second': 9.753, 'eval_steps_per_second': 2.49, 'epoch': 3.0}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./fine-tuned-lora-model/tokenizer_config.json',\n",
              " './fine-tuned-lora-model/special_tokens_map.json',\n",
              " './fine-tuned-lora-model/vocab.json',\n",
              " './fine-tuned-lora-model/merges.txt',\n",
              " './fine-tuned-lora-model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TzZuVAQSRcGB"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **LoRA Configuration:**\n",
        "- The `LoraConfig` class is used to define the configuration for Low-Rank Adaptation.\n",
        "- Key parameters include:\n",
        "> - `r`: The rank of the LoRA matrix.\n",
        "> - `lora_alpha`: Scaling factor for LoRA.\n",
        "> - `target_modules`: Specifies which modules in the model should have LoRA applied (usually the attention layers).\n",
        "> - `lora_dropout`: Dropout rate to be applied to LoRA.\n",
        "> - `bias`: Specifies how to handle biases; in this case, no bias is applied (\"none\").\n",
        "2. **Wrap the BART Model with LoRA:**\n",
        "- The `get_peft_model` function from the peft library wraps the original BART model with LoRA, making it suitable for `parameter-efficient fine-tuning`.\n",
        "3. **Defining Training Arguments:**\n",
        "- TrainingArguments defines various parameters for the training process:\n",
        "> - `num_train_epochs`: Number of epochs for training.\n",
        "> - `per_device_train_batch_size` and `per_device_eval_batch_size`: Batch sizes for training and evaluation.\n",
        "> - `logging_steps`: Frequency of logging training metrics.\n",
        "> - `eval_steps`: Frequency of evaluation during training.\n",
        "> - `save_steps`: Frequency of saving model checkpoints.\n",
        "4. **Trainer Setup and Training:**\n",
        "- The Trainer class handles the training loop, evaluation, and checkpointing. It takes the LoRA model and training arguments as input.\n",
        "5. **Save the Fine-Tuned Model:**\n",
        "- After training, the fine-tuned model and tokenizer are saved using the save_pretrained method.\n"
      ],
      "metadata": {
        "id": "ePZOS3bbSY1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jyr18o0cSYek"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('test_video_data.csv')\n",
        "test_df.head()\n"
      ],
      "metadata": {
        "id": "VA759l0fTzGm",
        "outputId": "9fdfcf27-16ef-46ab-9b5a-3214580e579b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      channel_name                                        video_title  \\\n",
              "0          Cracked  4 Awful Ways Our Ancestors Got High (That We T...   \n",
              "1  Science Channel  Could This Be The Legendary \"Magic Bridge\" Con...   \n",
              "2    StevenCrowder  Biological Males Should Not Compete in Women's...   \n",
              "3          PragerU  Fund the Children, Not the Schools | 5 Minute ...   \n",
              "4  Dr. Todd Grande  Elliot Rodger (King of the INCELS) | Mental He...   \n",
              "\n",
              "                                   video_description  \n",
              "0  Chapters\\nView all\\nIntro\\n0:00\\nNose Pipe\\n0:...  \n",
              "1  What on Earth? | Tuesdays 9p\\nAncient Hindu lo...  \n",
              "2  In this edition of Change My Mind, Steven Crow...  \n",
              "3  Why is it that parents have so little control ...  \n",
              "4  This video answers the question: Can I analyze...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1243c180-2f3f-46ed-84df-e422e56f7bc5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel_name</th>\n",
              "      <th>video_title</th>\n",
              "      <th>video_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cracked</td>\n",
              "      <td>4 Awful Ways Our Ancestors Got High (That We T...</td>\n",
              "      <td>Chapters\\nView all\\nIntro\\n0:00\\nNose Pipe\\n0:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Science Channel</td>\n",
              "      <td>Could This Be The Legendary \"Magic Bridge\" Con...</td>\n",
              "      <td>What on Earth? | Tuesdays 9p\\nAncient Hindu lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>StevenCrowder</td>\n",
              "      <td>Biological Males Should Not Compete in Women's...</td>\n",
              "      <td>In this edition of Change My Mind, Steven Crow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PragerU</td>\n",
              "      <td>Fund the Children, Not the Schools | 5 Minute ...</td>\n",
              "      <td>Why is it that parents have so little control ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dr. Todd Grande</td>\n",
              "      <td>Elliot Rodger (King of the INCELS) | Mental He...</td>\n",
              "      <td>This video answers the question: Can I analyze...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1243c180-2f3f-46ed-84df-e422e56f7bc5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1243c180-2f3f-46ed-84df-e422e56f7bc5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1243c180-2f3f-46ed-84df-e422e56f7bc5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"channel_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 74,\n        \"samples\": [\n          \"Dr. Todd Grande\",\n          \"Stalekracker Official\",\n          \"adidas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"When Ordering Kobe Beef Off The Menu You Could Be Getting This Meat Instead\",\n          \"Jim Gaffigan - Beyond the Pale - Hot Pockets\",\n          \"Multi-Agent Hide and Seek\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"video_description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Japanese Kobe beef is considered the tastiest beef money can buy: a single steak can cost as much as $600. But an INSIDE EDITION investigation found that while some menus advertise Kobe beef, they are actually serving up meat of lesser value. Kobe beef, which has a marbled appearance, comes from pure-bred cattle raised on a special diet in Japan. The meat can cost $55 dollars an ounce, and only 400 pounds get shipped to in the U.S. each month, according to Kobe beef distributor Brent Nakama. #InsideEdition\\nChapters\\nView all\\nIntro\\n0:00\\nWhat sets this beef apart\\n0:40\\nCan you believe Kobe burgers and Kobe hotdogs\\n0:56\\nI like to order a Kobe hotdog\\n1:07\\nI just wanted to know\\n1:28\\nInside Edition\\n13.4M subscribers\\nVideos\\nAbout\\nFacebook\\nInstagram\\nTikTok\\nTwitter\\nShow less\",\n          \"Click Subscribe & turn on notifications and LET\\u2019S BECOME BEST FRIENDS!\\n\\nBEST of / FUNNIEST COMPILATION\\nAnimals https://bit.ly/AnimalsCompilation\\nFast Food https://bit.ly/FastFoodCompilation\\nJesus https://bit.ly/JesusComp\\nClothing http://bit.ly/JGClothingCompilation\\nDonuts https://bit.ly/JGDonuts\\nStores http://bit.ly/JGStores\\nCatholic http://bit.ly/JGCatholic\\nDrinking    \\u2022 Best DRINKING Jokes | Stand-Up Compil...  \\nDisney    \\u2022 Best Disney World Jokes | Stand-Up Co...  \\nJapan    \\u2022 Best Japan Jokes | Jim Gaffigan Stand...  \\nFish    \\u2022 The FUNNIEST Fish Jokes of 2020 | Sta...  \\nCheese    \\u2022 Best Cheese Jokes | Jim Gaffigan Stan...  \\nHeaven & Hell    \\u2022 Funniest Heaven and Hell Jokes | Jim ...  \\nTV    \\u2022 Best Watching TV Jokes | Jim Gaffigan...  \\nDesserts    \\u2022 Funniest Dessert Stand Up Jokes | Jim...  \\nHolidays    \\u2022 Best Holiday Jokes 2020 - Jim Gaffigan  \\nBirthdays    \\u2022 Funniest Stand-up Birthday Jokes | Ji...  \\nKorean    \\u2022 Funniest Stand-up Birthday Jokes | Ji...  \\nNordic    \\u2022 Best Nordic Jokes 2020 - Jim Gaffigan...  \\nDogs    \\u2022 Funniest Dog Stand up Jokes | Jim Gaf...  \\nHistory    \\u2022 Funniest History Jokes | Jim Gaffigan...  \\nOutdoor    \\u2022 Best Outdoor Jokes | Stand-Up Compila...  \\nChinese    \\u2022 Best Outdoor Jokes | Stand-Up Compila...  \\nEating    \\u2022 Funniest Eating Jokes | Jim Gaffigan  \\nHyiegene    \\u2022 Funniest Hygiene Stand-up Jokes | Jim...  \\nReading    \\u2022 Funniest Reading Jokes | Jim Gaffigan  \\nDoctors    \\u2022 Best Doctor Jokes | Stand-Up Compilation  \\nExcercise    \\u2022 Funniest Exercise Jokes - Jim Gaffiga...  \\n\\nOUR MASSIVE PLANET    \\u2022 Jim Gaffigan  \\\"OUR MASSIVE PLANET: WH...  \\n\\nHEALTHY & HAPPY Gardening \\nINTRO  https://bit.ly/HappyandHealthy1\\nCORN https://bit.ly/HappyandHealthyCorn\\n\\nTHE PALE TOURIST  \\nAsian American (Full Set) https://bit.ly/JGAsianAmerican\\nFlorida Man (Full Set) https://bit.ly/JGFloridaMan\\nOntario vs Quebec https://bit.ly/JGOntario\\nSuperstitions https://bit.ly/JGSuperstition\\nTourists https://bit.ly/JGTourist\\nHalifax Donair https://bit.ly/JGDonair\\nRodeo https://bit.ly/JGRodeo\\nDrake Story https://bit.ly/JGDrake\\n\\nQUALITY TIME \\nMarathons https://bit.ly/JGMarathons\\nHorses https://bit.ly/JGHorses\\nAppendix https://bit.ly/JGAppendix\\nMuseums https://bit.ly/JGMuseum\\nLying https://bit.ly/JGLying\\nCold Weather https://bit.ly/JGColdWeather\\n\\nNOBLE APE\\nMy Wife's Brain Tumor https://bit.ly/JGBrainTumor\\nMassages https://bit.ly/JGMassage\\nPope https://bit.ly/JGPope\\nUK vs US https://bit.ly/JGUSAvCanada\\n\\nCINCO\\nMorning Person https://bit.ly/JGMorning\\nSteak is Manly https://bit.ly/JGSteak\\nHiking https://bit.ly/JGHiking\\nIdiot Abroad https://bit.ly/JGIdiotAbroad\\nEasier to be a Guy https://bit.ly/JGBeaGuy\\nBig Family https://bit.ly/JGBigFamily\\n\\nOBSESSED\\nWeddings https://bit.ly/JGWeddingsyay\\nVictoria's Secret https://bit.ly/JGSecret\\nCan't Stop Eating https://bit.ly/JGstopeating\\n\\nMR. UNIVERSE\\nVitamins https://bit.ly/JGVitamins\\nWhales https://bit.ly/JGWhales\\nFitness Goals https://bit.ly/JGFitnessGoals\\nHome Birth https://bit.ly/JGHomebirth\\nBig Family https://bit.ly/3a6HW0L\\n\\nKING BABY\\nCamping https://bit.ly/JGCamping\\nBacon https://bit.ly/JGBacon\\n\\nBEYOND THE PALE\\nHot Pockets https://bit.ly/JGHotPocket\\nDoing Nothing https://bit.ly/JGDoingNothing\\nOut To Dinner https://bit.ly/JGOutToDinner\\nCake https://bit.ly/JGCakes\\nVegetarian https://bit.ly/JGVegetarian\\n\\nSUPER OLD\\nManatee https://bit.ly/JGManatee\\nGlasses https://bit.ly/JGGLasses\\n\\nMERCH Proceeds donated to ThelmagineSociety.org https://tinyurl.com/y5fwmpb2\\n\\nLETS GET COOKIN' World\\u2019s Favorite Quarantine Cooking Show \\nToast https://bit.ly/JGToast\\nBurger https://bit.ly/JGBurger\\nPork https://bit.ly/JGPork\\nHotdog & Eggs https://bit.ly/JGHotDogs\\nPizza https://bit.ly/JGPizzaLGC\\nHot Dog Fest https://bit.ly/JGHotDogFest\\nMeatball Parm https://bit.ly/JGMeatball\\nPeas & Corn https://bit.ly/JGPeasandCorn\\nMikey Takes Over https://bit.ly/JGMikey\\nOatmeal Soup https://bit.ly/JGOatmeal\\nChicken Fillet https://bit.ly/JGChickenFilet\\nBacon Wrapped Steaks https://bit.ly/JGBaconWrapped\\n\\nTHE MIKE & PAT SHOW: (next Pewdiepie or Roblox addicts challenge)\\nDaddy Dog https://bit.ly/JGDaddyDog\\nHot Pocket https://bit.ly/JGMPHotPocket\\nSpaghettios https://bit.ly/JGSPaghettios\\nLiverwurst https://bit.ly/JGLiverwust\\nTwinkies https://bit.ly/JGTwinkies\\nVegemite https://bit.ly/JGVegimite\\nGarden Veggies    \\u2022 Eating from Jim Gaffigan's Garden! | ...  \\n\\nMy Kids React my 1st Stand Up TV Spot    \\u2022 \\\"MY KIDS REACT: To My First TV Stand ...    \\nMy Kids React my 1st 1/2 hr Special    \\u2022 \\\"MY KIDS REACT: To My 1st Comedy Cent...    \\n\\nDINNER WITH THE GAFFIGANS nightly 6pm E. Watch past episodes click JOIN & become MEMBER. Fee (99 cents) donated to TheImagineSociety.org.\\n\\nJIM EATS THE WORLD (mukbang asmr local food)  \\nSt.Louis Pizza https://bit.ly/JimEatsTheWorld\\nKC BBQ https://bit.ly/JGKCBBQ\\nGarbage Plate https://bit.ly/JGGarbagePlate\\nPolish Boy https://bit.ly/JGPolishboy\\nColombia https://bit.ly/JGColombia\\nPaella https://bit.ly/JGPaella\\n\\nPALE FORCE \\nSeason 1 https://tinyurl.com/yxzyk5ws\\nSeason 2    \\u2022 Pale Force Season 2 (ALL EPISODES) wi...  \\n\\nCORONAVIRUS LIFE  (Try not to laugh+ CBS SUNDAY)\\nWelcome to Quarantine    \\u2022 \\u201cGreetings from Quarantine\\u201d - Jim Gaf...    \\nMy Kids Ask Covid-19    \\u2022 \\\"MY KIDS ASK: About COVID-19 & get an...    \\nPandemic CBS Sunday Morning Mega Compilation    \\u2022 Jim Gaffigan CBS Sunday Morning MEGA ...   \\n\\nJim Gaffigan is an American stand-up comedian, actor, writer and producer. He presently has 5 stand up specials on Netflix and 3 on Amazon Prime Video. He wrote 2 New York Times Best Sellers DAD IS FAT and FOOD: A Love Story \\nTEXT JIM 646-980-6600\\nShorts remixing this video\\n499 views\\n118 views\\n90 views\\n61 views\\nTranscript\\nFollow along using the transcript.\\nShow transcript\\njimgaffigan\\n939K subscribers\\nVideos\\nAbout\\nJim Gaffigan on Instagram\\nJim Gaffigan Facebook\\nTwitter\\nTiktok\\nShow less\",\n          \"We\\u2019ve observed agents discovering progressively more complex tool use while playing a simple game of hide-and-seek. Through training in our new simulated hide-and-seek environment, agents build a series of six distinct strategies and counterstrategies, some of which we did not know our environment supported. The self-supervised emergent complexity in this simple environment further suggests that multi-agent co-adaptation may one day produce extremely complex and intelligent behavior.\\n\\nLearn more: https://openai.com/blog/emergent-tool...\\nKey moments\\nView all\\nMultiple Door Blocking\\n0:41\\nRamp Use\\n0:53\\nRamp Defense\\n1:04\\nShelter Construction\\n1:24\\nBox Surfing\\n1:40\\nShorts remixing this video\\n285 views\\n90 views\\nTranscript\\nFollow along using the transcript.\\nShow transcript\\nOpenAI\\n1.24M subscribers\\nVideos\\nAbout\\nTwitter\\nLinkedIn\\nShow less\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select a subset of the test data\n",
        "new_data = test_df.sample(n=1)\n",
        "new_data = new_data.reset_index(drop=True)\n",
        "\n",
        "new_data['video_description'][0]"
      ],
      "metadata": {
        "id": "fsTe3hlTZgXB",
        "outputId": "523d2d1b-a7f2-4f46-f081-a1564edf84dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Bob Ross painted more than 1,000 landscapes for his television show ‚Äî so why are they so hard to find? Solving one of the internet‚Äôs favorite little mysteries. \\n\\nRead more about Bob Ross: https://nyti.ms/2xIsshb\\nWatched the video? Here are a few more details on The Times website. https://www.nytimes.com/2019/07/12/ar...\\n\\nSubscribe: http://bit.ly/U8Ys7n\\nMore from The New York Times Video:  http://nytimes.com/video\\n----------\\nWhether it's reporting on conflicts abroad and political divisions at home, or covering the latest style trends and scientific developments, New York Times video journalists provide a revealing and unforgettable view of the world. It's all the news that's fit to watch.\\nKey moments\\nView all\\nCHAPTER ONE\\n0:39\\nAnnette Kowalski\\n2:47\\nCHAPTER TWO\\n2:54\\nWalt Kowalski\\n3:10\\nCHAPTER THREE\\n4:44\\nTranscript\\nFollow along using the transcript.\\nShow transcript\\nThe New York Times\\n4.53M subscribers\\nVideos\\nAbout\\nSecrets of ‚ÄòSesame Street‚Äô Songwriting (Featuring Usher) | NYT\\nby The New York Times\\nHow Did New York's Trains Get so Bad? | NYT\\nby The New York Times\\nWe‚Äôre Losing the War Against Bacteria, Here‚Äôs Why | NYT\\nby The New York Times\\nShow less\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pXEd7_RFHPHt"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the DataFrame to a list of dictionaries\n",
        "new_data = new_data.to_dict(orient='records')\n"
      ],
      "metadata": {
        "id": "PxTtM1gQFOp6"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Inference with the Fine-Tuned Model**\n",
        "\n",
        "\n",
        "1. **Prepare Input for Inference:** The new input data is formatted similarly to the training data.\n",
        "2. **Tokenization:** The `formatted_inputs` are tokenized using the BART tokenizer.\n",
        "3. **Generate Summaries:** The `generate()` method is called on the `LoRA fine-tuned model` to generate summaries.\n",
        "4. **Output Summaries:** The generated summaries are decoded and printed."
      ],
      "metadata": {
        "id": "t9cRVJAhUXB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n"
      ],
      "metadata": {
        "id": "I80k8l1KGNtx"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing input for inference\n",
        "formatted_inputs = [\n",
        "    f\"Channel: {item['channel_name']}, Title: {item['video_title']}, Description: {item['video_description']}\"\n",
        "    for item in new_data\n",
        "]\n",
        "\n",
        "# # Tokenize input\n",
        "# tokenizer = BartTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
        "# inputs = tokenizer(formatted_inputs, max_length=512, return_tensors=\"pt\", truncation=True, padding=\"max_length\")\n",
        "\n",
        "# Move inputs to the same device as the model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "# Loading the fine-tuned LoRA model and tokenizer\n",
        "model_path = \"./fine-tuned-lora-model\"\n",
        "tokenizer = BartTokenizer.from_pretrained(model_path)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_path)\n",
        "\n",
        "# LoRA configuration applied to the model\n",
        "lora_model = get_peft_model(model, lora_config)\n",
        "lora_model.to(device)\n",
        "\n",
        "# Generate summaries\n",
        "with torch.no_grad():\n",
        "    outputs = lora_model.generate(\n",
        "        input_ids=inputs[\"input_ids\"],\n",
        "        attention_mask=inputs[\"attention_mask\"],\n",
        "        max_length=128,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "# Decode and print summaries\n",
        "generated_summaries = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "print(f\"Generated Summaries: {generated_summaries}\")"
      ],
      "metadata": {
        "id": "owRUreoKT0XD",
        "outputId": "e80e27d4-63f1-4f1c-d717-3b983d2392ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Summaries: ['The Fast Lane Car takes a look at the top 5 cars we think are great, but have low sales numbers compared to their competition. The Mazda 6, Chevy SS, Jaguar FType, Cadillac ELR, and Ford F-150 are among the cars we look at. The Top 5 Great Cars That Few Buy: Surprising Overlooked Automotive Gems.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4X_6uPhSUdcD"
      },
      "execution_count": 14,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dae349e3f9a84cca87b9c127f84f8b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b15017fcc68c4e15a138078db54e8685",
              "IPY_MODEL_03b35202fce54fd08f0f843e2f926156",
              "IPY_MODEL_f21ebb3451a7424eb1c8717314b7660b"
            ],
            "layout": "IPY_MODEL_4de014de163c418590df5d24388d962e"
          }
        },
        "b15017fcc68c4e15a138078db54e8685": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b28e86af5304d3ab5ace74885d4479e",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a9bee76a308f45b98e10dffce203136e",
            "value": "Map:‚Äá100%"
          }
        },
        "03b35202fce54fd08f0f843e2f926156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42a5ae0d91514cd5b81ce03cc26c0ccf",
            "max": 186,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_792ba025f6c842d9b4363ff190f43730",
            "value": 186
          }
        },
        "f21ebb3451a7424eb1c8717314b7660b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1900bdcec0b548ae9a7527ff12eb8ee8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f75bd9508f2a48789e5323e81f674d91",
            "value": "‚Äá186/186‚Äá[00:00&lt;00:00,‚Äá285.56‚Äáexamples/s]"
          }
        },
        "4de014de163c418590df5d24388d962e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b28e86af5304d3ab5ace74885d4479e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9bee76a308f45b98e10dffce203136e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42a5ae0d91514cd5b81ce03cc26c0ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "792ba025f6c842d9b4363ff190f43730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1900bdcec0b548ae9a7527ff12eb8ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f75bd9508f2a48789e5323e81f674d91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae5717fea63a49b2a3fc486901a35fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fd808f66005c405490fa63716f4f7f04",
              "IPY_MODEL_84af0fd21a49474f96f29ef6be71b71a",
              "IPY_MODEL_e6b75d77fb9749879b295d6419a0484e"
            ],
            "layout": "IPY_MODEL_81bf8a077bef4df3a99a5c43cf7d2296"
          }
        },
        "fd808f66005c405490fa63716f4f7f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4825e7119eb14f209c46868b763a01b6",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_92a871e8a0ba4b5b8fff9b038bb2a8ac",
            "value": "Map:‚Äá100%"
          }
        },
        "84af0fd21a49474f96f29ef6be71b71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb5b331420e44ee7b63584e9ea8c3852",
            "max": 47,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_da69bf6692f24f9eb00479a3ec109454",
            "value": 47
          }
        },
        "e6b75d77fb9749879b295d6419a0484e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c952e1276ba4eb0b263fb6bb5109f74",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_024609d876f4403d85986ee77449ff91",
            "value": "‚Äá47/47‚Äá[00:00&lt;00:00,‚Äá222.28‚Äáexamples/s]"
          }
        },
        "81bf8a077bef4df3a99a5c43cf7d2296": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4825e7119eb14f209c46868b763a01b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a871e8a0ba4b5b8fff9b038bb2a8ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb5b331420e44ee7b63584e9ea8c3852": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da69bf6692f24f9eb00479a3ec109454": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0c952e1276ba4eb0b263fb6bb5109f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "024609d876f4403d85986ee77449ff91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOrSk4Yp9PU0uKJYWOU+/Z/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a00c0f17ef6d4e4a9242c36ca4342f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58ba4777288c4090b937b93aaa1a2d9a",
              "IPY_MODEL_e9f5b1bf11b346cdb8decc51ad3d273a",
              "IPY_MODEL_e0b6f28cc8c54feea0db56ef0713cbc4"
            ],
            "layout": "IPY_MODEL_579ba9e19c9b43b6b59f2b19b67628ba"
          }
        },
        "58ba4777288c4090b937b93aaa1a2d9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fd2a0eedea94603ad9d15bc374f1d04",
            "placeholder": "​",
            "style": "IPY_MODEL_57dd0e3d821d41cf9ef14d156a853747",
            "value": "Map: 100%"
          }
        },
        "e9f5b1bf11b346cdb8decc51ad3d273a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25d20d5f514c47b3be0781bcad46b3f9",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fdfe3a7255b4f3e947d652041f5f8b4",
            "value": 100
          }
        },
        "e0b6f28cc8c54feea0db56ef0713cbc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b99019fec8824d869a26f5aa65c0c373",
            "placeholder": "​",
            "style": "IPY_MODEL_0c4c2a3a4c734c72a8a3764068989985",
            "value": " 100/100 [00:00&lt;00:00, 618.12 examples/s]"
          }
        },
        "579ba9e19c9b43b6b59f2b19b67628ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fd2a0eedea94603ad9d15bc374f1d04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57dd0e3d821d41cf9ef14d156a853747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25d20d5f514c47b3be0781bcad46b3f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fdfe3a7255b4f3e947d652041f5f8b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b99019fec8824d869a26f5aa65c0c373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c4c2a3a4c734c72a8a3764068989985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkrusere/youTube-comments-Analyzer/blob/main/SAnalysis_on_YT_comments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "pip install bitsandbytes\n",
        "pip install accelerate\n",
        "pip install trl peft\n",
        "pip install datasets\n",
        "pip install rouge-score\n",
        "pip install evaluate\n",
        "pip install huggingface_hub\n"
      ],
      "metadata": {
        "id": "slYfYmt_p59Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import random\n",
        "import time\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from datasets import Dataset\n",
        "from peft import LoraConfig, PeftConfig, PeftModel, get_peft_model\n",
        "\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "import transformers\n",
        "from transformers import (\n",
        "                            AutoModelForCausalLM,\n",
        "                            AutoTokenizer,\n",
        "                            BartForConditionalGeneration,\n",
        "                            BartTokenizer,\n",
        "                            BitsAndBytesConfig,\n",
        "                            EarlyStoppingCallback,\n",
        "                            logging,\n",
        "                            pipeline,\n",
        "                            Trainer,\n",
        "                            TrainingArguments,\n",
        ")\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "UDGOEFoOp55W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nG3-wREPp518"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, userdata\n",
        "from huggingface_hub import login\n",
        "\n",
        "import os\n",
        "import json\n",
        "#mounting google drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "########################################\n",
        "\n",
        "#changing the working directory\n",
        "os.chdir(\"/content/drive/MyDrive/NLP_Data\")\n",
        "\n",
        "!pwd\n",
        "\n",
        "huggingface_token = userdata.get('Hugging_Face_Hub_API_TOKEN')\n",
        "\n",
        "#logging into huggingface\n",
        "login(huggingface_token, add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "DKnCtc2KqiSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oaGCQylMp5y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/NLP_Data/train_valid_data.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "T47MKtfDqkOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    f\"\"\"\n",
        "        Channel Name: {df['channel_name'][0]}\n",
        "        Video Title: {df['video_title'][0]}\n",
        "        Description: {df['video_description'][0]}\n",
        "        Comment Text: {df['comment_text'][0]}\n",
        "        \\n\n",
        "        Sentiment: {df['Sentiment'][0]}\n",
        "        Explanaition: {df['Explanation'][0]}\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "#returns\n",
        "        # Channel Name: BBC\n",
        "        # Video Title: Can Cuttlefish camouflage in a living room? | Richard Hammond's Miracles of Nature - BBC\n",
        "        # Description: The final episode of Richard Hammond’s Miracles Of Nature. Richard is once again investigating the extraordinary super-powers of the animal kingdom. Cuttlefish survive by being able to blend into their surroundings through camouflage. Richard Hammond puts this to the test and experiments if the fish are able to camouflage in a tank set up like a living room.\n",
        "        # Comment Text: The big white square on his back was impressive af even tho it wasn't fooling our human perception.\n",
        "\n",
        "\n",
        "        # Sentiment: Positive\n",
        "        # Explanaition: The comment expresses admiration for the cuttlefish's camouflage abilities, despite it not being completely convincing to humans.\n"
      ],
      "metadata": {
        "id": "JRDu339yqkBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gJ4v20TQq2zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/NLP_Data/test_data.csv')\n",
        "train_valid_data = pd.read_csv('/content/drive/MyDrive/NLP_Data/train_valid_data.csv')\n",
        "\n",
        "# Split the dataset into training and validation sets (80-20 split)\n",
        "train_df, val_df = train_test_split(train_valid_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "model_name = \"facebook/bart-large-cnn\"  # BART model name\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# Data Preparation\n",
        "def format_data(df, for_test=False):\n",
        "    return [\n",
        "        {\n",
        "            \"input\": f\"Channel: {row['channel_name']}, Title: {row['video_title']}, Description: {row['video_description']}, Comment Text: {row['comment_text']}\",\n",
        "            \"output\": f\"Sentiment: {row['Sentiment']}, Explanation: {row['Explanation']}\" if not for_test else \"Sentiment: , Explanation: \"\n",
        "        }\n",
        "        for _, row in df.iterrows()\n",
        "    ]\n",
        "\n",
        "# Format the data\n",
        "formatted_train_data = format_data(train_df)\n",
        "formatted_val_data = format_data(val_df)\n",
        "formatted_test_data = format_data(test_df, for_test=True)\n",
        "\n",
        "# Convert to Dataset objects\n",
        "train_dataset = Dataset.from_list(formatted_train_data)\n",
        "val_dataset = Dataset.from_list(formatted_val_data)\n",
        "test_dataset = Dataset.from_list(formatted_test_data)\n",
        "\n",
        "# Tokenization\n",
        "def tokenize_data(example):\n",
        "    model_inputs = tokenizer(\n",
        "        example[\"input\"],\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            example[\"output\"],\n",
        "            max_length=128,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True\n",
        "        )\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Tokenize datasets\n",
        "tokenized_train_dataset = train_dataset.map(tokenize_data, batched=True)\n",
        "tokenized_val_dataset = val_dataset.map(tokenize_data, batched=True)\n",
        "\n",
        "# Configure LoRA\n",
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        ")\n",
        "lora_model = get_peft_model(model, lora_config)"
      ],
      "metadata": {
        "id": "OFsRduAZq2wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NYma0ErVq2tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Arguments with Optimizations\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=24,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    warmup_steps=1000,                 # Increased warmup steps\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_steps=1000,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps=500,\n",
        "    gradient_accumulation_steps=8,     # Simulate larger batch size\n",
        "    fp16=True,                         # Mixed precision training\n",
        "    learning_rate=1e-5,                # Optimized learning rate\n",
        "    lr_scheduler_type=\"linear\",        # Linear decay\n",
        "    load_best_model_at_end=True,       # Save best model\n",
        "    metric_for_best_model=\"eval_loss\", # Track best model by validation loss\n",
        ")\n",
        "\n",
        "# Add Early Stopping\n",
        "early_stopping = EarlyStoppingCallback(early_stopping_patience=3)\n",
        "\n",
        "# Trainer with Early Stopping\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "_PVwOR0Qq2qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation Results: {eval_results}\")"
      ],
      "metadata": {
        "id": "Zmr2N0T9q2k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eNe0mJv3rWWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Fine-Tuned Model\n",
        "lora_model.save_pretrained(\"./SA-bart-fine-tuned-lora-model\")\n",
        "tokenizer.save_pretrained(\"./SA-bart-fine-tuned-lora-model\")"
      ],
      "metadata": {
        "id": "AZOh0pUdq2iE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Push to Hugging Face Hub\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n",
        "\n",
        "lora_model.push_to_hub(\"kkrusere/SA-bart-fine-tuned-lora-model\")\n",
        "tokenizer.push_to_hub(\"kkrusere/SA-bart-fine-tuned-lora-model\")"
      ],
      "metadata": {
        "id": "_2w71UNLq2e-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wi7WX8G5rTGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JzB0T1WqrTDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned model and tokenizer\n",
        "model = BartForConditionalGeneration.from_pretrained(\"./SA-bart-fine-tuned-lora-model\")\n",
        "tokenizer = BartTokenizer.from_pretrained(\"./SA-bart-fine-tuned-lora-model\")\n",
        "\n",
        "# Load the test data\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/NLP_Data/test_data.csv')\n",
        "\n",
        "# Prepare the test data for inference\n",
        "def format_test_data(df):\n",
        "    return [\n",
        "        {\n",
        "            \"input\": f\"Channel: {row['channel_name']}, Title: {row['video_title']}, Description: {row['video_description']}, Comment Text: {row['comment_text']}\",\n",
        "            \"output\": \"\"  # For test data, the output is not needed\n",
        "        }\n",
        "        for _, row in df.iterrows()\n",
        "    ]\n",
        "\n",
        "# Format and convert test data to Dataset\n",
        "formatted_test_data = format_test_data(test_df)\n",
        "test_dataset = Dataset.from_list(formatted_test_data)\n",
        "\n",
        "# Tokenize the test data\n",
        "def tokenize_data(example):\n",
        "    model_inputs = tokenizer(\n",
        "        example[\"input\"],\n",
        "        max_length=512,\n",
        "        padding=\"max_length\",\n",
        "        truncation=True\n",
        "    )\n",
        "    return model_inputs\n",
        "\n",
        "# Tokenize the test dataset\n",
        "tokenized_test_dataset = test_dataset.map(tokenize_data, batched=True)\n",
        "\n",
        "# Inference\n",
        "def infer(model, tokenizer, dataset):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    for example in dataset:\n",
        "        inputs = tokenizer(example['input'], return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "        outputs = model.generate(**inputs)\n",
        "        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        predictions.append(prediction)\n",
        "    return predictions\n",
        "\n",
        "# Get predictions\n",
        "predictions = infer(model, tokenizer, tokenized_test_dataset)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "a00c0f17ef6d4e4a9242c36ca4342f07",
            "58ba4777288c4090b937b93aaa1a2d9a",
            "e9f5b1bf11b346cdb8decc51ad3d273a",
            "e0b6f28cc8c54feea0db56ef0713cbc4",
            "579ba9e19c9b43b6b59f2b19b67628ba",
            "4fd2a0eedea94603ad9d15bc374f1d04",
            "57dd0e3d821d41cf9ef14d156a853747",
            "25d20d5f514c47b3be0781bcad46b3f9",
            "8fdfe3a7255b4f3e947d652041f5f8b4",
            "b99019fec8824d869a26f5aa65c0c373",
            "0c4c2a3a4c734c72a8a3764068989985"
          ]
        },
        "id": "qSZi7GINLjDM",
        "outputId": "b70879c9-0148-4971-b1da-0b5cf06eeb1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a00c0f17ef6d4e4a9242c36ca4342f07"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "ur9vKDw8Bc8h",
        "outputId": "51e28f23-8118-4140-ad10-6ceca9b97d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Sentiment: Negative, Explanation: The comment expresses negative feelings about Tom Hanks, suggesting a negative reaction to the film, suggesting that the actor's dislike of Hanks is the biggest crime of all. The comment has a negative tone, suggesting negative feelings toward Hanks and the film.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A5d68zcpbIyc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkrusere/youTube-comments-Analyzer/blob/main/YT_comments_collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU0xXXoBQzor",
        "outputId": "cba3e7f4-b56c-4cc4-f957-c7e1efce48c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [929 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,556 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,922 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,393 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,189 kB]\n",
            "Fetched 9,252 kB in 3s (2,829 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "46 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.21.2-2ubuntu1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.16).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n",
            "--2024-06-25 12:45:55--  http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
            "Resolving archive.ubuntu.com (archive.ubuntu.com)... 91.189.91.82, 91.189.91.83, 185.125.190.81, ...\n",
            "Connecting to archive.ubuntu.com (archive.ubuntu.com)|91.189.91.82|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3708 (3.6K) [application/vnd.debian.binary-package]\n",
            "Saving to: ‘libu2f-udev_1.1.4-1_all.deb’\n",
            "\n",
            "libu2f-udev_1.1.4-1 100%[===================>]   3.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-25 12:45:56 (648 MB/s) - ‘libu2f-udev_1.1.4-1_all.deb’ saved [3708/3708]\n",
            "\n",
            "Selecting previously unselected package libu2f-udev.\n",
            "(Reading database ... 121925 files and directories currently installed.)\n",
            "Preparing to unpack libu2f-udev_1.1.4-1_all.deb ...\n",
            "Unpacking libu2f-udev (1.1.4-1) ...\n",
            "Setting up libu2f-udev (1.1.4-1) ...\n",
            "--2024-06-25 12:45:56--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 64.233.188.93, 64.233.188.190, 64.233.188.91, ...\n",
            "Connecting to dl.google.com (dl.google.com)|64.233.188.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 108773084 (104M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 103.73M   345MB/s    in 0.3s    \n",
            "\n",
            "2024-06-25 12:45:57 (345 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [108773084/108773084]\n",
            "\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "(Reading database ... 121929 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (126.0.6478.126-1) ...\n",
            "\u001b[1mdpkg:\u001b[0m dependency problems prevent configuration of google-chrome-stable:\n",
            " google-chrome-stable depends on libvulkan1; however:\n",
            "  Package libvulkan1 is not installed.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m error processing package google-chrome-stable (--install):\n",
            " dependency problems - leaving unconfigured\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Errors were encountered while processing:\n",
            " google-chrome-stable\n",
            "--2024-06-25 12:46:05--  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/118.0.5993.70/linux64/chromedriver-linux64.zip\n",
            "Resolving edgedl.me.gvt1.com (edgedl.me.gvt1.com)... 34.104.35.123, 2600:1900:4110:86f::\n",
            "Connecting to edgedl.me.gvt1.com (edgedl.me.gvt1.com)|34.104.35.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8269742 (7.9M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/chromedriver-linux64.zip’\n",
            "\n",
            "chromedriver-linux6 100%[===================>]   7.89M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-06-25 12:46:05 (54.7 MB/s) - ‘/tmp/chromedriver-linux64.zip’ saved [8269742/8269742]\n",
            "\n",
            "Archive:  /tmp/chromedriver-linux64.zip\n",
            "  inflating: /tmp/chromedriver-linux64/LICENSE.chromedriver  \n",
            "  inflating: /tmp/chromedriver-linux64/chromedriver  \n",
            "Collecting selenium\n",
            "  Downloading selenium-4.22.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromedriver_autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.25.1-py3-none-any.whl (467 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.7/467.7 kB\u001b[0m \u001b[31m47.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.6.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver_autoinstaller) (24.1)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, chromedriver_autoinstaller, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed chromedriver_autoinstaller-0.6.4 h11-0.14.0 outcome-1.3.0.post0 selenium-4.22.0 trio-0.25.1 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "\n",
        "wget -N https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/118.0.5993.70/linux64/chromedriver-linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver-linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver-linux64/chromedriver\n",
        "mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver\n",
        "pip install selenium chromedriver_autoinstaller"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "lo_Rt1YYX9U5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting google drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "########################################\n",
        "\n",
        "#changing the working directory\n",
        "os.chdir(\"/content/drive/MyDrive/EV NLP Data\")\n",
        "\n",
        "!pwd\n"
      ],
      "metadata": {
        "id": "TqMUbwZnX_vZ",
        "outputId": "5bc5886a-e18f-4d3b-eeb8-93fbe08887f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/EV NLP Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ql3oOw_zRdDb"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "\n",
        "from selenium import webdriver\n",
        "import chromedriver_autoinstaller\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "import time\n",
        "\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chromedriver_autoinstaller.install()\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YFxDFWLy2EeX"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('YouTubeAPI_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JHJ2Uf54UY-J"
      },
      "outputs": [],
      "source": [
        "import googleapiclient.discovery\n",
        "from googleapiclient.discovery import build\n",
        "import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J32M7G962vOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Jupyter Notebook is designed to collect YouTube video comments from various videos. These comments will be used for creating, training, and validating a Sentiment Analysis model. The videos from which the comments were collected were chosen with no particular criteria other than being from my favorite channels and videos.\n",
        "\n",
        "The process of collecting comments makes use of the YouTube API, Selenium, BeautifulSoup, and other custom functions.\n",
        "\n",
        "The process:\n",
        "\n",
        "1. Create a list of favorite channels.\n",
        "2. Use the YouTube API to select the top 10 most-watched videos from each channel and store them in a master list of videos from which we will collect comments.\n",
        "3. For each video in the master video list, use Selenium and BeautifulSoup to collect the comments and store them in a pandas DataFrame.\n",
        "4. Clean and sanitize the comments in the DataFrame and prepare the data for Sentiment Analysis."
      ],
      "metadata": {
        "id": "yMLm81KQ27EV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nNpaCEhz2vCm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # We are going to save this of channels to a json file. There was no particular proceedure in creating the below list of channels other than trying to capture cannels that would create a balance on positive, negative and neutral comments.\n",
        "\n",
        "# # List of YouTube channel URLs\n",
        "# channels = [\n",
        "#     \"https://www.youtube.com/@BestEverFoodReviewShow\",\n",
        "#     \"https://www.youtube.com/@TheRamseyShow\",\n",
        "#     \"https://www.youtube.com/@MrBallen\",\n",
        "#     \"https://www.youtube.com/@MattWalsh\",\n",
        "#     \"https://www.youtube.com/@VICE\",\n",
        "#     \"https://www.youtube.com/@CNN\",\n",
        "#     \"https://www.youtube.com/@Jeep\",\n",
        "#     \"https://www.youtube.com/@MrBeast\",\n",
        "#     \"https://www.youtube.com/@obamawhitehouse\",\n",
        "#     \"https://www.youtube.com/@DonaldJTrumpforPresident\",\n",
        "#     \"https://www.youtube.com/@TheDailyShow\",\n",
        "#     \"https://www.youtube.com/@gordonramsay\",\n",
        "#     \"https://www.youtube.com/@frontline\",\n",
        "#     \"https://www.youtube.com/@JoeBiden\",\n",
        "#     \"https://www.youtube.com/@LastWeekTonight\",\n",
        "#     \"https://www.youtube.com/@edmundscars\",\n",
        "#     \"https://www.youtube.com/@BillBurrOfficial\",\n",
        "#     \"https://www.youtube.com/@netflixisajoke\",\n",
        "#     \"https://www.youtube.com/@TheLaughFactory\",\n",
        "#     \"https://www.youtube.com/@VICENews\",\n",
        "#     \"https://www.youtube.com/@SargonofAkkad\",\n",
        "#     \"https://www.youtube.com/@gags\",\n",
        "#     \"https://www.youtube.com/@LaurenSouthernOfficial\",\n",
        "#     \"https://www.youtube.com/@FunnyOrDie\",\n",
        "#     \"https://www.youtube.com/@dropout\",\n",
        "#     \"https://www.youtube.com/@thedavidpakmanshow\",\n",
        "#     \"https://www.youtube.com/@Vaush\",\n",
        "#     \"https://www.youtube.com/@ComedyCentral\",\n",
        "#     \"https://www.youtube.com/@SortedFood\",\n",
        "#     \"https://www.youtube.com/@gmc\",\n",
        "#     \"https://www.youtube.com/@mytruecrimenews\",\n",
        "#     \"https://www.youtube.com/@amazon\",\n",
        "#     \"https://www.youtube.com/@RealCandaceO\",\n",
        "#     \"https://www.youtube.com/@JCS\",\n",
        "#     \"https://www.youtube.com/@Google\",\n",
        "#     \"https://www.youtube.com/@ChrisHansen\",\n",
        "#     \"https://www.youtube.com/@PragerU\",\n",
        "#     \"https://www.youtube.com/@NBCSports\",\n",
        "#     \"https://www.youtube.com/@Apple\",\n",
        "#     \"https://www.youtube.com/@ExploreWithUs\",\n",
        "#     \"https://www.youtube.com/@TODAY\",\n",
        "#     \"https://www.youtube.com/@Microsoft\",\n",
        "#     \"https://www.youtube.com/@DatelineNBC\",\n",
        "#     \"https://www.youtube.com/@Timcast\",\n",
        "#     \"https://www.youtube.com/@AssociatedPress\",\n",
        "#     \"https://www.youtube.com/@JordanBPeterson\",\n",
        "#     \"https://www.youtube.com/@NBCNews\",\n",
        "#     \"https://www.youtube.com/@StevenCrowder\",\n",
        "#     \"https://www.youtube.com/@NFL\",\n",
        "#     \"https://www.youtube.com/@SabineHossenfelder\",\n",
        "#     \"https://www.youtube.com/@RubinReport\",\n",
        "#     \"https://www.youtube.com/@CNBC\",\n",
        "#     \"https://www.youtube.com/@DailyWirePlus\",\n",
        "#     \"https://www.youtube.com/@joerogan\",\n",
        "#     \"https://www.youtube.com/@60minutes\",\n",
        "#     \"https://www.youtube.com/@ElectricVehicleSpace\",\n",
        "#     \"https://www.youtube.com/@DougDeMuro\",\n",
        "#     \"https://www.youtube.com/@markets\",\n",
        "#     \"https://www.youtube.com/@nypost\",\n",
        "#     \"https://www.youtube.com/@neoexplains\",\n",
        "#     \"https://www.youtube.com/@unboxtherapy\",\n",
        "#     \"https://www.youtube.com/@KitchenNightmares\",\n",
        "#     \"https://www.youtube.com/@SamEckholm\",\n",
        "#     \"https://www.youtube.com/@RealStories\",\n",
        "#     \"https://www.youtube.com/@FreeDocumentary\",\n",
        "#     \"https://www.youtube.com/@TechQuarks\",\n",
        "#     \"https://www.youtube.com/@WonderDocs\",\n",
        "#     \"https://www.youtube.com/@sciencechannel\",\n",
        "#     \"https://www.youtube.com/@FluctusOfficial\",\n",
        "#     \"https://www.youtube.com/@Munchies\",\n",
        "#     \"https://www.youtube.com/@dcofficial\",\n",
        "#     \"https://www.youtube.com/@48hours\",\n",
        "#     \"https://www.youtube.com/@therealautoblog\",\n",
        "#     \"https://www.youtube.com/@BusinessInsider\",\n",
        "#     \"https://www.youtube.com/@NickDiGiovanni\",\n",
        "#     \"https://www.youtube.com/@RamTrucks\",\n",
        "#     \"https://www.youtube.com/@stalekrackerofficial4240\",\n",
        "#     \"https://www.youtube.com/@nytimes\",\n",
        "#     \"https://www.youtube.com/@DailyCallerVideo\",\n",
        "#     \"https://www.youtube.com/@babishculinaryuniverse\",\n",
        "#     \"https://www.youtube.com/@marvel\",\n",
        "#     \"https://www.youtube.com/@adidas\",\n",
        "#     \"https://www.youtube.com/@nissanusa\",\n",
        "#     \"https://www.youtube.com/@TED\",\n",
        "#     \"https://www.youtube.com/@CBSNews\",\n",
        "#     \"https://www.youtube.com/@ProHomeCooks\",\n",
        "#     \"https://www.youtube.com/@buzzfeedtasty\",\n",
        "#     \"https://www.youtube.com/@Honda\",\n",
        "#     \"https://www.youtube.com/@TFLEV\",\n",
        "#     \"https://www.youtube.com/@jimgaffigan\",\n",
        "#     \"https://www.youtube.com/@breakingpoints\",\n",
        "#     \"https://www.youtube.com/@Honest_Ads\",\n",
        "#     \"https://www.youtube.com/@Shaun_vids\",\n",
        "#     \"https://www.youtube.com/@JKenjiLopezAlt\",\n",
        "#     \"https://www.youtube.com/@epicurious\",\n",
        "#     \"https://www.youtube.com/@JoshuaWeissman\",\n",
        "#     \"https://www.youtube.com/@TheOnion\",\n",
        "#     \"https://www.youtube.com/@Chevrolet\",\n",
        "#     \"https://www.youtube.com/@HowItShouldHaveEnded\",\n",
        "#     \"https://www.youtube.com/@wsj\",\n",
        "#     \"https://www.youtube.com/@cracked\",\n",
        "#     \"https://www.youtube.com/@TheTRYChannel\",\n",
        "#     \"https://www.youtube.com/@TeamCoco\",\n",
        "#     \"https://www.youtube.com/@LOLNetwork\",\n",
        "#     \"https://www.youtube.com/@KeyAndPeele\",\n",
        "#     \"https://www.youtube.com/@bonappetit\",\n",
        "#     \"https://www.youtube.com/@MentourNow\",\n",
        "#     \"https://www.youtube.com/@HasanAbi\",\n",
        "#     \"https://www.youtube.com/@TheLateLateShow\",\n",
        "#     \"https://www.youtube.com/@ThatChapter\",\n",
        "#     \"https://www.youtube.com/@Coffeezilla\",\n",
        "#     \"https://www.youtube.com/@JimmyKimmelLive\",\n",
        "#     \"https://www.youtube.com/@ClubRandomPodcast\",\n",
        "#     \"https://www.youtube.com/@MentourPilot\",\n",
        "#     \"https://www.youtube.com/@OpenAI\",\n",
        "#     \"https://www.youtube.com/@TheFBIFiles\",\n",
        "#     \"https://www.youtube.com/@CoffeehouseCrime\",\n",
        "#     \"https://www.youtube.com/@TechLead\",\n",
        "#     \"https://www.youtube.com/@gustoonz\",\n",
        "#     \"https://www.youtube.com/@TFLcar\",\n",
        "#     \"https://www.youtube.com/@BreakfastClubPower1051FM\",\n",
        "#     \"https://www.youtube.com/@nike\",\n",
        "#     \"https://www.youtube.com/@MaydayAirDisaster\",\n",
        "#     \"https://www.youtube.com/@GingerBilly\",\n",
        "#     \"https://www.youtube.com/@TheBabylonBee\",\n",
        "#     \"https://www.youtube.com/@Donut\",\n",
        "#     \"https://www.youtube.com/@CSPAN\",\n",
        "#     \"https://www.youtube.com/@PhilosophyTube\",\n",
        "#     \"https://www.youtube.com/@RealTime\",\n",
        "#     \"https://www.youtube.com/@kbb\",\n",
        "#     \"https://www.youtube.com/@tesla\",\n",
        "#     \"https://www.youtube.com/@TheYoungTurks\",\n",
        "#     \"https://www.youtube.com/@bigthink\",\n",
        "#     \"https://www.youtube.com/@LindsayEllisVids\",\n",
        "#     \"https://www.youtube.com/@latimes\",\n",
        "#     \"https://www.youtube.com/@SecularTalk\",\n",
        "#     \"https://www.youtube.com/@hbomberguy\",\n",
        "#     \"https://www.youtube.com/@NewsNation\",\n",
        "#     \"https://www.youtube.com/@aljazeeraenglish\",\n",
        "#     \"https://www.youtube.com/@BenShapiro\",\n",
        "#     \"https://www.youtube.com/@BadFaithPodcast\",\n",
        "#     \"https://www.youtube.com/@fifa\",\n",
        "#     \"https://www.youtube.com/@espn\",\n",
        "#     \"https://www.youtube.com/@ActualJusticeWarrior\",\n",
        "#     \"https://www.youtube.com/@ContraPoints\",\n",
        "#     \"https://www.youtube.com/@fallontonight\",\n",
        "#     \"https://www.youtube.com/@MarkWiens\",\n",
        "#     \"https://www.youtube.com/@BBC\",\n",
        "#     \"https://www.youtube.com/@pbsspacetime\",\n",
        "#     \"https://www.youtube.com/@Dodge\",\n",
        "#     \"https://www.youtube.com/@InsideEdition\",\n",
        "#     \"https://www.youtube.com/@ford\",\n",
        "#     \"https://www.youtube.com/@FoxNews\",\n",
        "#     \"https://www.youtube.com/@Beardmeatsfood\",\n",
        "#     \"https://www.youtube.com/@CodeBlueCam\",\n",
        "#     \"https://www.youtube.com/@SamChui\",\n",
        "#     \"https://www.youtube.com/@toyotausa\",\n",
        "#     \"https://www.youtube.com/@GugaFoods\",\n",
        "#     \"https://www.youtube.com/@BBCNews\",\n",
        "#     \"https://www.youtube.com/@ColbertLateShow\",\n",
        "#     \"https://www.youtube.com/@thehill\",\n",
        "#     \"https://www.youtube.com/@NatGeo\",\n",
        "#     \"https://www.youtube.com/@Cadillac\",\n",
        "#     \"https://www.youtube.com/@TheDodo\",\n",
        "#     \"https://www.youtube.com/@discovery\",\n",
        "#     \"https://www.youtube.com/@SimplilearnOfficial\",\n",
        "#     \"https://www.youtube.com/@NBCNews\"\n",
        "# ]\n",
        "\n",
        "# # Data to be written to JSON file\n",
        "# data = {\"channels\": channels}\n",
        "\n",
        "# # Writing to json file\n",
        "# with open(\"channels.json\", \"w\") as outfile:\n",
        "#     json.dump(data, outfile, indent=4)"
      ],
      "metadata": {
        "id": "hf3_-dFZdFb3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3GlBdDqdFJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aB1ExA1XYQzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_channel_videos(channel_url):\n",
        "    # Extract channel ID from URL\n",
        "    if 'channel/' in channel_url:\n",
        "        channel_id = channel_url.split('channel/')[-1]\n",
        "    else:\n",
        "        # Handle other URL formats if necessary\n",
        "        raise ValueError('Unsupported URL format. Please provide a valid channel URL.')\n",
        "\n",
        "\n",
        "    # Get channel uploads playlist ID\n",
        "    response = youtube.channels().list(\n",
        "        part='contentDetails',\n",
        "        id=channel_id\n",
        "    ).execute()\n",
        "\n",
        "    uploads_playlist_id = response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
        "\n",
        "    # Get all videos in the uploads playlist\n",
        "    videos = []\n",
        "    next_page_token = None\n",
        "    while True:\n",
        "        response = youtube.playlistItems().list(\n",
        "            part='contentDetails',\n",
        "            playlistId=uploads_playlist_id,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token\n",
        "        ).execute()\n",
        "\n",
        "        videos += response['items']\n",
        "        next_page_token = response.get('nextPageToken')\n",
        "\n",
        "        if next_page_token is None:\n",
        "            break\n",
        "\n",
        "    return [video['contentDetails']['videoId'] for video in videos]"
      ],
      "metadata": {
        "id": "nJj-_JqrYgOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TlKdUizoYgLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_comments_count(video_id, youtube):\n",
        "    response = youtube.videos().list(\n",
        "        part='statistics',\n",
        "        id=video_id\n",
        "    ).execute()\n",
        "\n",
        "    return int(response['items'][0]['statistics'].get('commentCount', 0))"
      ],
      "metadata": {
        "id": "xeeArd_JYgH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w_DFqP5-Yi-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_5_videos(channel_url):\n",
        "    video_ids = get_channel_videos(channel_url)\n",
        "\n",
        "    youtube = build('youtube', 'v3', developerKey=API_KEY)\n",
        "\n",
        "    video_comments = []\n",
        "    for video_id in video_ids:\n",
        "        comment_count = get_video_comments_count(video_id, youtube)\n",
        "        video_comments.append((video_id, comment_count))\n",
        "\n",
        "    # Sort videos by comment count in descending order and get top 5\n",
        "    top_5_videos = sorted(video_comments, key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "    return top_5_videos\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NfDNZ6wrYQxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EM8eVh6yYQu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "channel_url = 'https://www.youtube.com/channel/CHANNEL_ID'\n",
        "top_videos = get_top_5_videos(channel_url)\n",
        "print(top_videos)"
      ],
      "metadata": {
        "id": "RMN965j6YQrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KWBsUPKyYQmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YLTEFPM0yVZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "channel_id = 'UCfuEu0ff9Yy_oA5U21C5Stw'\n",
        "\n",
        "request = youtube.search().list(\n",
        "    part='snippet',\n",
        "    channelId=channel_id,\n",
        "    type='video',\n",
        "    order='viewCount',\n",
        "    maxResults=10\n",
        ")\n",
        "video_url_list = []\n",
        "\n",
        "response = request.execute()\n",
        "\n",
        "for item in response['items']:\n",
        "    video_title = item['snippet']['title']\n",
        "    video_id = item['id']['videoId']\n",
        "    video_url = f'https://www.youtube.com/watch?v={video_id}'\n",
        "\n",
        "    print(f'Title: {video_title} | URL: {video_url}')\n"
      ],
      "metadata": {
        "id": "vVKMIQMLyVWU",
        "outputId": "1f576d91-2fe4-4b66-c04e-6530776737fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: I killed the QUEEN to save the hive. | URL: https://www.youtube.com/watch?v=DXuzQkXVKXI\n",
            "Title: What comes out of an egg this BIG? The 50 day hatching adventure. | URL: https://www.youtube.com/watch?v=Cp19XhbqJ_c\n",
            "Title: The Round Beehive Explained... | URL: https://www.youtube.com/watch?v=qcjj9PjhBdU\n",
            "Title: We tricked our hens into hatching out the RAREST baby peacocks! | URL: https://www.youtube.com/watch?v=8rwC8FQugrw\n",
            "Title: What’s INSIDE of our Emu Eggs? | URL: https://www.youtube.com/watch?v=vIqhcG1oy2w\n",
            "Title: A New Bee Emerges | URL: https://www.youtube.com/watch?v=3JsX0OC58d4\n",
            "Title: These are NOT your normal big, green eggs. | URL: https://www.youtube.com/watch?v=jjEAZrZbHnU\n",
            "Title: How many Emu Eggs are there? | URL: https://www.youtube.com/watch?v=m9a2LYfgjkA\n",
            "Title: Meet the Guicken. How did this happen? | URL: https://www.youtube.com/watch?v=LY5lxc2lMjE\n",
            "Title: Our Emus Finally Laid Eggs *after 4 years* | URL: https://www.youtube.com/watch?v=J8fTVQpWsCQ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_channel_id_from_handle_url(handle_url):\n",
        "    \"\"\"Fetches the YouTube channel ID from a URL containing only the handle.\n",
        "\n",
        "    This function uses the YouTube Data API's 'search' endpoint to look for\n",
        "    channels matching the given handle. It extracts the channel ID from the\n",
        "    first matching result.\n",
        "\n",
        "    Args:\n",
        "        handle_url: The YouTube channel URL containing only the handle (e.g.,\n",
        "            'https://www.youtube.com/@Google').\n",
        "\n",
        "    Returns:\n",
        "        The channel ID (string) if found, otherwise None.\n",
        "\n",
        "    Raises:\n",
        "        googleapiclient.errors.HttpError: If there's an issue with the API request.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        request = youtube.search().list(\n",
        "            part='snippet',\n",
        "            q=handle_url,   # Search for the handle\n",
        "            type='channel',\n",
        "            maxResults=1    # We only need one result\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        if response['items']:\n",
        "            channel_id = response['items'][0]['snippet']['channelId']\n",
        "            return channel_id\n",
        "\n",
        "    except googleapiclient.errors.HttpError as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "    return None  # Return None if no channel is found\n"
      ],
      "metadata": {
        "id": "i7sQ-0Xy7NwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fZIaYKvv9jc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XZ_rr_tt9jaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from urllib.parse import urlparse, parse_qs\n",
        "\n",
        "def get_channel_id_from_handle(handle_url):\n",
        "    \"\"\"Extracts the YouTube channel ID from a URL containing only the handle.\n",
        "\n",
        "    This function takes a YouTube channel URL that might be in various formats\n",
        "    (shortened, custom, etc.) and extracts the unique channel ID. It works even\n",
        "    if the URL only contains the handle, utilizing the YouTube Data API for the lookup.\n",
        "\n",
        "    Args:\n",
        "        handle_url: The YouTube channel URL (string) containing the handle.\n",
        "\n",
        "    Returns:\n",
        "        The channel ID (string) if found, or None if not found or on API error.\n",
        "\n",
        "    Raises:\n",
        "        googleapiclient.errors.HttpError: If there's an issue with the API request.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Try direct extraction from URL if it's a standard format\n",
        "        parsed_url = urlparse(handle_url)\n",
        "        if parsed_url.netloc == 'www.youtube.com' and parsed_url.path.startswith('/c/'):\n",
        "            return parsed_url.path.split('/')[2]  # Handle after /c/\n",
        "        elif parsed_url.netloc == 'www.youtube.com' and parsed_url.path.startswith('/channel/'):\n",
        "            return parsed_url.path.split('/')[2]\n",
        "        else:\n",
        "            query_params = parse_qs(parsed_url.query)\n",
        "            if 'ab_channel' in query_params:\n",
        "                return query_params['ab_channel'][0]  # from query parameter\n",
        "    except ValueError:\n",
        "        # Parsing failed, continue with API lookup\n",
        "        pass\n",
        "\n",
        "    # If direct extraction fails, use the YouTube Data API for lookup\n",
        "    request = youtube.search().list(\n",
        "        part='snippet',\n",
        "        q=handle_url,  # Search by the handle\n",
        "        type='channel',\n",
        "        maxResults=1\n",
        "    )\n",
        "\n",
        "    response = request.execute()\n",
        "\n",
        "    if response['items']:\n",
        "        return response['items'][0]['snippet']['channelId']  # Extract ID from result\n",
        "\n",
        "    return None  # Channel not found or error occurred\n"
      ],
      "metadata": {
        "id": "vICZgUxk9jXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zFHHfIdw74dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_channel_id_from_handle_url('https://www.youtube.com/@thehill')"
      ],
      "metadata": {
        "id": "JYpHtEGU77Fw",
        "outputId": "48c33e79-cff3-462c-f78a-d8fcc6667f2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'UCfuEu0ff9Yy_oA5U21C5Stw'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_channel_id_from_handle('https://www.youtube.com/@thehill')\n"
      ],
      "metadata": {
        "id": "QIbvxXe49m1F",
        "outputId": "1d3f19c3-51f9-4563-dc42-d007710377ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'UCfuEu0ff9Yy_oA5U21C5Stw'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UCPWXiRWZ29zrxPFIQT7eHSA"
      ],
      "metadata": {
        "id": "1bJEanRn75cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_list(channel_id):\n",
        "  \"\"\"Fetches a list of top-viewed video URLs from a YouTube channel.\n",
        "\n",
        "  This function uses the YouTube Data API to retrieve the details (title, ID)\n",
        "  of the most viewed videos on a specified channel. It constructs full URLs for\n",
        "  each video and returns them in a list.\n",
        "\n",
        "  Args:\n",
        "      channel_id: The YouTube channel ID (string) from which to retrieve videos.\n",
        "\n",
        "  Returns:\n",
        "      A list of strings representing the URLs of the top-viewed videos.\n",
        "  \"\"\"\n",
        "\n",
        "  request = youtube.search().list(\n",
        "    part='snippet',\n",
        "    channelId=channel_id,\n",
        "    type='video',\n",
        "    order='viewCount',\n",
        "    maxResults=10\n",
        "  )\n",
        "  video_url_list = []\n",
        "\n",
        "  response = request.execute()\n",
        "\n",
        "  for item in response['items']:\n",
        "      video_title = item['snippet']['title']\n",
        "      video_id = item['id']['videoId']\n",
        "      video_url = f'https://www.youtube.com/watch?v={video_id}'\n",
        "\n",
        "      video_url_list.append(video_url)\n",
        "\n",
        "\n",
        "  return video_url_list"
      ],
      "metadata": {
        "id": "XOLBj-qwyU7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y4ppDByqyU4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QgMT_bXTycOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tUsrsmnAycL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHMs7BUE6ern"
      },
      "outputs": [],
      "source": [
        "# YouTube video URL\n",
        "video_url = \"https://www.youtube.com/watch?v=-cJ1fSX3Nec\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH7DXhiBwmO4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLcVyvxJwmMS"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    wait = WebDriverWait(driver, 5)\n",
        "\n",
        "    # Open the YouTube video\n",
        "    driver.get(video_url)\n",
        "\n",
        "    wait.until(EC.visibility_of_element_located((By.TAG_NAME, 'body')))\n",
        "\n",
        "    # Scroll down to load comments\n",
        "    last_height = 0\n",
        "    while True:\n",
        "        # Scroll to the end of the page\n",
        "        #driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
        "        # Scroll using page-manager element's scroll height\n",
        "        driver.execute_script(\"window.scrollTo(0, document.getElementById('page-manager').scrollHeight);\")\n",
        "        time.sleep(5)  # Adjust sleep time as needed\n",
        "\n",
        "        # Get the current page height\n",
        "        new_height = driver.execute_script(\"return document.getElementById('page-manager').scrollHeight\")\n",
        "\n",
        "        # Break the loop if no more content is loaded\n",
        "        if new_height == last_height:\n",
        "            break\n",
        "\n",
        "        last_height = new_height\n",
        "\n",
        "    # Wait for the comments section to be visible\n",
        "    comments_section = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"ytd-comments#comments.style-scope.ytd-watch-flexy\")))\n",
        "\n",
        "    # Get the HTML content of the comments section\n",
        "    comments_html = comments_section.get_attribute('outerHTML')\n",
        "\n",
        "finally:\n",
        "    # Close the WebDriver session\n",
        "    driver.quit()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnHBdhQQwmJZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ieZY8eEqJ9D",
        "outputId": "6214d0fe-8c81-49a4-ab92-06a742161991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comment Count: 9,327\n"
          ]
        }
      ],
      "source": [
        "soup = BeautifulSoup(comments_html, 'html.parser')\n",
        "\n",
        "# Find the span element with the specified class\n",
        "comment_count_span = soup.find('span', class_='style-scope yt-formatted-string')\n",
        "\n",
        "# Extract the text content of the span element\n",
        "comment_count = comment_count_span.text.strip()\n",
        "\n",
        "# Print or use the comment count\n",
        "print(\"Comment Count:\", comment_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN0V7PReqJy5",
        "outputId": "322f3c05-9837-405c-b707-061e9afe9651"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of ytd-comment-thread-renderer elements: 957\n"
          ]
        }
      ],
      "source": [
        "# Find all occurrences of the ytd-comment-thread-renderer element\n",
        "comment_thread_renderers = soup.find_all('ytd-comment-thread-renderer', class_='style-scope ytd-item-section-renderer')\n",
        "\n",
        "# Count the number of occurrences\n",
        "comment_thread_count = len(comment_thread_renderers)\n",
        "\n",
        "# Print or use the comment thread count\n",
        "print(\"Number of ytd-comment-thread-renderer elements:\", comment_thread_count)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pODm38fYW-oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save comments data to a JSON file\n",
        "def save_comments_to_json(comments, filename = 'youtube_comments.json'):\n",
        "    with open(filename, 'w') as json_file:\n",
        "        json.dump(comments, json_file, indent=4)\n",
        "\n",
        "def load_comments_from_json(filename = 'youtube_comments.json'):\n",
        "    with open(filename, 'r') as json_file:\n",
        "        comments = json.load(json_file)\n",
        "    return comments"
      ],
      "metadata": {
        "id": "c01OJ8kGXAEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lfcjiy0EXABQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVh7Bi4zs17k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxuNM3-v6iyv"
      },
      "outputs": [],
      "source": [
        "comments = []\n",
        "comments_data = load_comments_from_json()\n",
        "# Iterate through each comment thread renderer\n",
        "for comment_thread_renderer in comment_thread_renderers:\n",
        "\n",
        "    # Extracting the comment text\n",
        "    comment_text_element = comment_thread_renderer.find('yt-attributed-string', id='content-text')\n",
        "    comment_text = comment_text_element.get_text(strip=True) if comment_text_element else None\n",
        "\n",
        "    # Extracting the number of likes\n",
        "    like_count_element = comment_thread_renderer.find('span', class_='style-scope ytd-comment-engagement-bar')\n",
        "    like_count = like_count_element.get_text(strip=True) if like_count_element else None\n",
        "\n",
        "    # Extracting the number of replies\n",
        "    reply_count_element = comment_thread_renderer.find('ytd-button-renderer', id='more-replies')\n",
        "    reply_count = reply_count_element.get_text(strip=True) if reply_count_element else None\n",
        "\n",
        "    comments.append(comment_text)\n",
        "\n",
        "    print(\"Comment Text:\", comment_text)\n",
        "    print(\"Like Count:\", like_count)\n",
        "    print(\"Reply Count:\", reply_count)\n",
        "\n",
        "    print(\"\\n\\n\\n\")\n",
        "\n",
        "\n",
        "    comments_data.append(\n",
        "        {\n",
        "        \"comment_text\": comment_text,\n",
        "        \"like_count\": like_count,\n",
        "        \"reply_count\": reply_count\n",
        "\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "save_comments_to_json(comments = comments_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0xnxn5_VBwR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(load_comments_from_json())"
      ],
      "metadata": {
        "id": "HqxB4_8hWgqK",
        "outputId": "2752b835-caa2-4103-e169-9ceef67853f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16477"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qTTKlLrKWgnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2PDPb4YUWgkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MU5jFfivUasf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_id(video_url):\n",
        "  video_id = video_url.split('=')[1]\n",
        "\n",
        "  return video_id"
      ],
      "metadata": {
        "id": "9TPnHzmttD-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsai3V1XfUL9",
        "outputId": "f0150c4c-c992-4b64-817a-302e0aac323d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Why EVs Are Piling Up At Dealerships In The U.S.\n",
            "Thumbnail URL: <img src=\"https://i.ytimg.com/vi/cZlsZwcIgpc/maxresdefault.jpg\" alt=\"Thumbnail\">\n",
            "View count: 4492458\n",
            "Like count: 36502\n",
            "Number of Comments: 23211\n",
            "Date posted: 2023-10-16 16:26:47\n",
            "Description: In August 2023, it took about twice as long to sell an EV in the U.S. as it did the previous January. Prices of EVs are down 22% year-over-year and that's mainly driven by Tesla. About two thirds of EVs sold are Elon Musk's brand. Companies like Ford have ramped up hybrid production as demand has leveled off. While slightly more than half of consumers say EVs are the future and will eventually replace Internal Combustion Engines, less than a third of dealers say so. This all comes at a time when investments in EVs are more than ever. So what's really going on? Watch the video to learn more.\n"
          ]
        }
      ],
      "source": [
        "# Request video details\n",
        "response = youtube.videos().list(\n",
        "    part=\"snippet,statistics\",\n",
        "    id=get_video_id(video_url)\n",
        ").execute()\n",
        "\n",
        "# Extract required information\n",
        "video = response[\"items\"][0]\n",
        "title = video[\"snippet\"][\"title\"]\n",
        "thumbnail_url = video[\"snippet\"][\"thumbnails\"][\"maxres\"][\"url\"]\n",
        "view_count = video[\"statistics\"][\"viewCount\"]\n",
        "like_count = video[\"statistics\"][\"likeCount\"]\n",
        "commentCount = video[\"statistics\"][\"commentCount\"]\n",
        "date_posted = video[\"snippet\"][\"publishedAt\"]\n",
        "description = video[\"snippet\"][\"description\"]\n",
        "\n",
        "\n",
        "date_str = date_posted\n",
        "date_object = datetime.datetime.strptime(date_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "\n",
        "# Format the date object\n",
        "date_posted = date_object.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "\n",
        "# Split the description by newlines\n",
        "paragraphs = description.split(\"\\n\")\n",
        "\n",
        "# Get the first paragraph\n",
        "first_paragraph = paragraphs[0]\n",
        "\n",
        "# Generate HTML to display the thumbnail\n",
        "thumbnail_html = f'<img src=\"{thumbnail_url}\" alt=\"Thumbnail\">'\n",
        "\n",
        "# Print the information\n",
        "print(\"Title:\", title)\n",
        "print(\"Thumbnail URL:\", thumbnail_html)\n",
        "print(\"View count:\", view_count)\n",
        "print(\"Like count:\", like_count)\n",
        "print(\"Number of Comments:\", commentCount)\n",
        "print(\"Date posted:\", date_posted)\n",
        "print(\"Description:\", first_paragraph)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paihhshgdgc_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for videos using the YouTube API\n",
        "def search_videos(query, youtube = youtube):\n",
        "\n",
        "  # Request video search\n",
        "  response = youtube.search().list(\n",
        "      q=query,\n",
        "      type=\"video\",\n",
        "      part=\"id,snippet\",\n",
        "      maxResults=10\n",
        "  ).execute()\n",
        "\n",
        "  # Extract video IDs from search results\n",
        "  video_ids = []\n",
        "  for item in response[\"items\"]:\n",
        "    video_ids.append(item[\"id\"][\"videoId\"])\n",
        "\n",
        "  return video_ids"
      ],
      "metadata": {
        "id": "yELZ0SdqswL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fpCKbrnPOvN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_info(video_id):\n",
        "  # Request video details\n",
        "  response = youtube.videos().list(\n",
        "      part=\"snippet,statistics\",\n",
        "      id=video_id\n",
        "  ).execute()\n",
        "\n",
        "  # Extract required information\n",
        "  video = response[\"items\"][0]\n",
        "  title = video[\"snippet\"][\"title\"]\n",
        "  view_count = video[\"statistics\"][\"viewCount\"]\n",
        "  like_count = video[\"statistics\"][\"likeCount\"]\n",
        "  commentCount = video[\"statistics\"][\"commentCount\"]\n",
        "  date_posted = video[\"snippet\"][\"publishedAt\"]\n",
        "  description = video[\"snippet\"][\"description\"]\n",
        "\n",
        "\n",
        "  date_str = date_posted\n",
        "  date_object = datetime.datetime.strptime(date_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "\n",
        "  # Format the date object\n",
        "  date_posted = date_object.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "\n",
        "  # Split the description by newlines\n",
        "  paragraphs = description.split(\"\\n\")\n",
        "\n",
        "  # Get the first paragraph\n",
        "  first_paragraph = paragraphs[0]\n",
        "\n",
        "  extracted_video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "\n",
        "\n",
        "  # Print the information\n",
        "  print(\"Title:\", title)\n",
        "  print(\"Video URL:\", extracted_video_url)\n",
        "  print(\"View count:\", view_count)\n",
        "  print(\"Like count:\", like_count)\n",
        "  print(\"Number of Comments:\", commentCount)\n",
        "  print(\"Date posted:\", date_posted)\n",
        "  print(\"Description:\", first_paragraph)\n",
        "  print(\"\\n\\n\\n\")\n"
      ],
      "metadata": {
        "id": "ZYi3Cag9OvE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Zswn5xbOrKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_query = \"Electric Vehicles\"\n",
        "video_ids = search_videos(search_query)\n",
        "\n",
        "\n",
        "for video_id in video_ids:\n",
        "  get_video_info(video_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pw36E4SFswGo",
        "outputId": "6b0c9f02-4067-45a4-db93-2889af7be05c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: Should I Get An Electric Car?\n",
            "Video URL: https://www.youtube.com/watch?v=vXjs17ydRgI\n",
            "View count: 40707\n",
            "Like count: 2661\n",
            "Number of Comments: 574\n",
            "Date posted: 2024-04-10 15:31:46\n",
            "Description: Check out Insectarium on PBS Terra: https://www.youtube.com/watch?v=jowk_A71-EU\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Title: Used electric cars. The FIVE golden buying rules | Electrifying\n",
            "Video URL: https://www.youtube.com/watch?v=aIYyycWQc34\n",
            "View count: 13639\n",
            "Like count: 682\n",
            "Number of Comments: 96\n",
            "Date posted: 2024-04-09 15:30:00\n",
            "Description: #usedelectric #buyingcars #electriccars\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Title: Are used EVs a rip-off?!\n",
            "Video URL: https://www.youtube.com/watch?v=Ur47okU3eUk\n",
            "View count: 350718\n",
            "Like count: 13192\n",
            "Number of Comments: 1927\n",
            "Date posted: 2024-04-10 10:05:09\n",
            "Description: Sell your car for free with Carwow: https://bit.ly/Sell-Your-Car-For-Free-1004\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Title: Why Hybrids Are Beating EVs In The U.S.\n",
            "Video URL: https://www.youtube.com/watch?v=R_J_T7TWbXY\n",
            "View count: 633530\n",
            "Like count: 9340\n",
            "Number of Comments: 2979\n",
            "Date posted: 2024-04-02 16:00:20\n",
            "Description: When Japanese automaker Toyota first brought hybrids to the U.S. in the early 2000s, they were at the cutting edge of green transportation. But soon after, EVs stole the spotlight. Elon Musk-led Tesla disrupted the auto industry and nearly every major legacy automaker scrambled to take part in the coming EV revolution. With almost no fully electric vehicles, the once vanguard Toyota looked behind the times. However, as of early 2024, EV sales are leveling off and hybrids are making a comeback. Automakers such as Ford, BMW, Mercedes, Hyundai and General Motors are all either pulling back on EV production or boosting the manufacture of the humble hybrid. The vast majority of hybrids are standard ones - with an engine and backup battery. But plug-in hybrids are a growing category. Automakers such as GM are reintroducing them to North America.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Title: Honest Government Ad | Electric Vehicles\n",
            "Video URL: https://www.youtube.com/watch?v=fLflYkgnNBY\n",
            "View count: 3140140\n",
            "Like count: 141825\n",
            "Number of Comments: 13341\n",
            "Date posted: 2021-04-24 04:05:53\n",
            "Description: The Australien Government has made an ad about its Electric Vehicle policy, and it's surprisingly honest and informative.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Title: Electric Cars: Inconvenient Facts, Part One\n",
            "Video URL: https://www.youtube.com/watch?v=z2HneqfZGsM\n",
            "View count: 1944778\n",
            "Like count: 96314\n",
            "Number of Comments: 14415\n",
            "Date posted: 2022-11-01 12:30:24\n",
            "Description: Politicians and activists who want all cars to go electric are guilty of magical thinking.  \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Title: Save money on tyres & my perfect Electric Car ! | MW180\n",
            "Video URL: https://www.youtube.com/watch?v=o17jzHL_Wto\n",
            "View count: 3838\n",
            "Like count: 518\n",
            "Number of Comments: 203\n",
            "Date posted: 2024-04-10 17:00:28\n",
            "Description: This week I help you save money on tyres and I've found my perfect electric car !\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Title: The Cheapest EVs You Can Buy Today | Most Affordable Electric Cars & SUVs for 2024\n",
            "Video URL: https://www.youtube.com/watch?v=06Q-BbvA48Q\n",
            "View count: 80327\n",
            "Like count: 568\n",
            "Number of Comments: 50\n",
            "Date posted: 2024-02-08 17:00:01\n",
            "Description: While electric vehicles, in general, remain pricier than their internal combustion-engine counterparts, there are still a decent number of affordable models to choose from — some of which may surprise you. In this video, Edmunds’ Nick Yekikian goes through the cheapest EVs currently available!\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Title: How an Electric Car Works? Its Parts & Functions [Explained]\n",
            "Video URL: https://www.youtube.com/watch?v=tJfERzrG-D8\n",
            "View count: 2260407\n",
            "Like count: 28614\n",
            "Number of Comments: 673\n",
            "Date posted: 2021-10-25 03:30:07\n",
            "Description: How does an Electric Car Work? Its Parts & Functions Explained\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Title: Why EV Sales Are Falling | CNBC Marathon\n",
            "Video URL: https://www.youtube.com/watch?v=oDFS6gfDV7k\n",
            "View count: 562412\n",
            "Like count: 6200\n",
            "Number of Comments: 2244\n",
            "Date posted: 2024-03-02 17:00:37\n",
            "Description: CNBC Marathon explores the decline of electric vehicle sales and its implications.\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJT4gLq0PU1z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7RSC_pdtQ99W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
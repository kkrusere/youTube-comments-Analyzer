{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kkrusere/youTube-comments-Analyzer/blob/main/YT_comments_collection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU0xXXoBQzor",
        "outputId": "efeed00e-99d2-45e9-cb7b-6461c36dcb27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [1 InRelease 5,484 B/129\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [1 InRelease 22.9 kB/129\u001b[0m\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [1 InRelease 43.1 kB/129\u001b[0m\r                                                                               \rGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [968 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,978 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,116 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,400 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,253 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,654 kB]\n",
            "Fetched 10.8 MB in 2s (5,097 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "48 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "curl is already the newest version (7.81.0-1ubuntu1.16).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 48 not upgraded.\n",
            "--2024-07-01 18:40:45--  http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
            "Resolving archive.ubuntu.com (archive.ubuntu.com)... 185.125.190.82, 185.125.190.83, 91.189.91.81, ...\n",
            "Connecting to archive.ubuntu.com (archive.ubuntu.com)|185.125.190.82|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3708 (3.6K) [application/vnd.debian.binary-package]\n",
            "Saving to: ‘libu2f-udev_1.1.4-1_all.deb’\n",
            "\n",
            "libu2f-udev_1.1.4-1 100%[===================>]   3.62K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-07-01 18:40:45 (535 MB/s) - ‘libu2f-udev_1.1.4-1_all.deb’ saved [3708/3708]\n",
            "\n",
            "Selecting previously unselected package libu2f-udev.\n",
            "(Reading database ... 121925 files and directories currently installed.)\n",
            "Preparing to unpack libu2f-udev_1.1.4-1_all.deb ...\n",
            "Unpacking libu2f-udev (1.1.4-1) ...\n",
            "Setting up libu2f-udev (1.1.4-1) ...\n",
            "--2024-07-01 18:40:46--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 142.250.98.93, 142.250.98.136, 142.250.98.91, ...\n",
            "Connecting to dl.google.com (dl.google.com)|142.250.98.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 108773084 (104M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 103.73M   378MB/s    in 0.3s    \n",
            "\n",
            "2024-07-01 18:40:47 (378 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [108773084/108773084]\n",
            "\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "(Reading database ... 121929 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (126.0.6478.126-1) ...\n",
            "\u001b[1mdpkg:\u001b[0m dependency problems prevent configuration of google-chrome-stable:\n",
            " google-chrome-stable depends on libvulkan1; however:\n",
            "  Package libvulkan1 is not installed.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m error processing package google-chrome-stable (--install):\n",
            " dependency problems - leaving unconfigured\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Errors were encountered while processing:\n",
            " google-chrome-stable\n",
            "--2024-07-01 18:40:57--  https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/118.0.5993.70/linux64/chromedriver-linux64.zip\n",
            "Resolving edgedl.me.gvt1.com (edgedl.me.gvt1.com)... 34.104.35.123, 2600:1900:4110:86f::\n",
            "Connecting to edgedl.me.gvt1.com (edgedl.me.gvt1.com)|34.104.35.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8269742 (7.9M) [application/octet-stream]\n",
            "Saving to: ‘/tmp/chromedriver-linux64.zip’\n",
            "\n",
            "chromedriver-linux6 100%[===================>]   7.89M  11.0MB/s    in 0.7s    \n",
            "\n",
            "2024-07-01 18:40:58 (11.0 MB/s) - ‘/tmp/chromedriver-linux64.zip’ saved [8269742/8269742]\n",
            "\n",
            "Archive:  /tmp/chromedriver-linux64.zip\n",
            "  inflating: /tmp/chromedriver-linux64/LICENSE.chromedriver  \n",
            "  inflating: /tmp/chromedriver-linux64/chromedriver  \n",
            "Collecting selenium\n",
            "  Downloading selenium-4.22.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chromedriver_autoinstaller\n",
            "  Downloading chromedriver_autoinstaller-0.6.4-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.25.1-py3-none-any.whl (467 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.7/467.7 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.6.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from chromedriver_autoinstaller) (24.1)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, chromedriver_autoinstaller, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed chromedriver_autoinstaller-0.6.4 h11-0.14.0 outcome-1.3.0.post0 selenium-4.22.0 trio-0.25.1 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "\n",
        "wget -N https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/118.0.5993.70/linux64/chromedriver-linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver-linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver-linux64/chromedriver\n",
        "mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver\n",
        "pip install selenium chromedriver_autoinstaller"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "lo_Rt1YYX9U5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting google drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "########################################\n",
        "\n",
        "#changing the working directory\n",
        "os.chdir(\"/content/drive/MyDrive/EV NLP Data\")\n",
        "\n",
        "!pwd\n"
      ],
      "metadata": {
        "id": "TqMUbwZnX_vZ",
        "outputId": "5593d460-7684-4a8e-aae7-443991c005cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/EV NLP Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ql3oOw_zRdDb"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "\n",
        "from selenium import webdriver\n",
        "import chromedriver_autoinstaller\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chromedriver_autoinstaller.install()\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "KVMWOrY9stbw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YFxDFWLy2EeX"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('YouTubeAPI_key')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JHJ2Uf54UY-J"
      },
      "outputs": [],
      "source": [
        "import googleapiclient.discovery\n",
        "from googleapiclient.discovery import build\n",
        "import datetime\n",
        "\n",
        "\n",
        "\n",
        "youtube = googleapiclient.discovery.build(\"youtube\", \"v3\", developerKey=api_key)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J32M7G962vOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Jupyter Notebook is designed to collect YouTube video comments from various videos. These comments will be used for creating, training, and validating a Sentiment Analysis model. The videos from which the comments were collected were chosen with no particular criteria other than being from my favorite channels and videos.\n",
        "\n",
        "The process of collecting comments makes use of the YouTube API, Selenium, BeautifulSoup, and other custom functions.\n",
        "\n",
        "The process:\n",
        "\n",
        "1. Create a list of favorite channels.\n",
        "2. Use the YouTube API to select the top 10 most-watched videos from each channel and store them in a master list of videos from which we will collect comments.\n",
        "3. For each video in the master video list, use Selenium and BeautifulSoup to collect the comments and store them in a pandas DataFrame.\n",
        "4. Clean and sanitize the comments in the DataFrame and prepare the data for Sentiment Analysis."
      ],
      "metadata": {
        "id": "yMLm81KQ27EV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nNpaCEhz2vCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# below are functions for reading a writting json file for the current working directory\n",
        "\n",
        "def save_to_json(data, filename):\n",
        "    with open(filename, 'w') as json_file:\n",
        "        json.dump(data, json_file, indent=4)\n",
        "\n",
        "def load_from_json(filename):\n",
        "    with open(filename, 'r') as json_file:\n",
        "        comments = json.load(json_file)\n",
        "    return comments"
      ],
      "metadata": {
        "id": "sQISFC8_errB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XE90kVwSerj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # We are going to save this of channels to a json file. There was no particular proceedure in creating the below list of channels other than trying to capture cannels that would create a balance on positive, negative and neutral comments.\n",
        "\n",
        "# # List of YouTube channel URLs\n",
        "# channels = [\n",
        "#     \"https://www.youtube.com/@BestEverFoodReviewShow\",\n",
        "#     \"https://www.youtube.com/@TheRamseyShow\",\n",
        "#     \"https://www.youtube.com/@MrBallen\",\n",
        "#     \"https://www.youtube.com/@MattWalsh\",\n",
        "#     \"https://www.youtube.com/@TheBehaviorPanel\",\n",
        "#     \"https://www.youtube.com/@VICE\",\n",
        "#     \"https://www.youtube.com/@CNN\",\n",
        "#     \"https://www.youtube.com/@Jeep\",\n",
        "#     \"https://www.youtube.com/@MrBeast\",\n",
        "#     \"https://www.youtube.com/@obamawhitehouse\",\n",
        "#     \"https://www.youtube.com/@DonaldJTrumpforPresident\",\n",
        "#     \"https://www.youtube.com/@TheDailyShow\",\n",
        "#     \"https://www.youtube.com/@gordonramsay\",\n",
        "#     \"https://www.youtube.com/@frontline\",\n",
        "#     \"https://www.youtube.com/@DrGrande\",\n",
        "#     \"https://www.youtube.com/@JoeBiden\",\n",
        "#     \"https://www.youtube.com/@LastWeekTonight\",\n",
        "#     \"https://www.youtube.com/@edmundscars\",\n",
        "#     \"https://www.youtube.com/@BillBurrOfficial\",\n",
        "#     \"https://www.youtube.com/@netflixisajoke\",\n",
        "#     \"https://www.youtube.com/@TheLaughFactory\",\n",
        "#     \"https://www.youtube.com/@VICENews\",\n",
        "#     \"https://www.youtube.com/@SargonofAkkad\",\n",
        "#     \"https://www.youtube.com/@gags\",\n",
        "#     \"https://www.youtube.com/@LaurenSouthernOfficial\",\n",
        "#     \"https://www.youtube.com/@FunnyOrDie\",\n",
        "#     \"https://www.youtube.com/@dropout\",\n",
        "#     \"https://www.youtube.com/@thedavidpakmanshow\",\n",
        "#     \"https://www.youtube.com/@Vaush\",\n",
        "#     \"https://www.youtube.com/@ComedyCentral\",\n",
        "#     \"https://www.youtube.com/@SortedFood\",\n",
        "#     \"https://www.youtube.com/@gmc\",\n",
        "#     \"https://www.youtube.com/@mytruecrimenews\",\n",
        "#     \"https://www.youtube.com/@amazon\",\n",
        "#     \"https://www.youtube.com/@RealCandaceO\",\n",
        "#     \"https://www.youtube.com/@JCS\",\n",
        "#     \"https://www.youtube.com/@Google\",\n",
        "#     \"https://www.youtube.com/@ChrisHansen\",\n",
        "#     \"https://www.youtube.com/@PragerU\",\n",
        "#     \"https://www.youtube.com/@NBCSports\",\n",
        "#     \"https://www.youtube.com/@Apple\",\n",
        "#     \"https://www.youtube.com/@ExploreWithUs\",\n",
        "#     \"https://www.youtube.com/@TODAY\",\n",
        "#     \"https://www.youtube.com/@Microsoft\",\n",
        "#     \"https://www.youtube.com/@DatelineNBC\",\n",
        "#     \"https://www.youtube.com/@Timcast\",\n",
        "#     \"https://www.youtube.com/@AssociatedPress\",\n",
        "#     \"https://www.youtube.com/@JordanBPeterson\",\n",
        "#     \"https://www.youtube.com/@NBCNews\",\n",
        "#     \"https://www.youtube.com/@StevenCrowder\",\n",
        "#     \"https://www.youtube.com/@NFL\",\n",
        "#     \"https://www.youtube.com/@SabineHossenfelder\",\n",
        "#     \"https://www.youtube.com/@RubinReport\",\n",
        "#     \"https://www.youtube.com/@CNBC\",\n",
        "#     \"https://www.youtube.com/@DailyWirePlus\",\n",
        "#     \"https://www.youtube.com/@joerogan\",\n",
        "#     \"https://www.youtube.com/@60minutes\",\n",
        "#     \"https://www.youtube.com/@ElectricVehicleSpace\",\n",
        "#     \"https://www.youtube.com/@DougDeMuro\",\n",
        "#     \"https://www.youtube.com/@markets\",\n",
        "#     \"https://www.youtube.com/@nypost\",\n",
        "#     \"https://www.youtube.com/@neoexplains\",\n",
        "#     \"https://www.youtube.com/@unboxtherapy\",\n",
        "#     \"https://www.youtube.com/@KitchenNightmares\",\n",
        "#     \"https://www.youtube.com/@SamEckholm\",\n",
        "#     \"https://www.youtube.com/@RealStories\",\n",
        "#     \"https://www.youtube.com/@FreeDocumentary\",\n",
        "#     \"https://www.youtube.com/@TechQuarks\",\n",
        "#     \"https://www.youtube.com/@WonderDocs\",\n",
        "#     \"https://www.youtube.com/@sciencechannel\",\n",
        "#     \"https://www.youtube.com/@FluctusOfficial\",\n",
        "#     \"https://www.youtube.com/@Munchies\",\n",
        "#     \"https://www.youtube.com/@dcofficial\",\n",
        "#     \"https://www.youtube.com/@48hours\",\n",
        "#     \"https://www.youtube.com/@therealautoblog\",\n",
        "#     \"https://www.youtube.com/@BusinessInsider\",\n",
        "#     \"https://www.youtube.com/@NickDiGiovanni\",\n",
        "#     \"https://www.youtube.com/@RamTrucks\",\n",
        "#     \"https://www.youtube.com/@stalekrackerofficial4240\",\n",
        "#     \"https://www.youtube.com/@nytimes\",\n",
        "#     \"https://www.youtube.com/@DailyCallerVideo\",\n",
        "#     \"https://www.youtube.com/@babishculinaryuniverse\",\n",
        "#     \"https://www.youtube.com/@marvel\",\n",
        "#     \"https://www.youtube.com/@adidas\",\n",
        "#     \"https://www.youtube.com/@nissanusa\",\n",
        "#     \"https://www.youtube.com/@TED\",\n",
        "#     \"https://www.youtube.com/@CBSNews\",\n",
        "#     \"https://www.youtube.com/@ProHomeCooks\",\n",
        "#     \"https://www.youtube.com/@buzzfeedtasty\",\n",
        "#     \"https://www.youtube.com/@Honda\",\n",
        "#     \"https://www.youtube.com/@TFLEV\",\n",
        "#     \"https://www.youtube.com/@jimgaffigan\",\n",
        "#     \"https://www.youtube.com/@breakingpoints\",\n",
        "#     \"https://www.youtube.com/@Honest_Ads\",\n",
        "#     \"https://www.youtube.com/@Shaun_vids\",\n",
        "#     \"https://www.youtube.com/@JKenjiLopezAlt\",\n",
        "#     \"https://www.youtube.com/@epicurious\",\n",
        "#     \"https://www.youtube.com/@JoshuaWeissman\",\n",
        "#     \"https://www.youtube.com/@TheOnion\",\n",
        "#     \"https://www.youtube.com/@Chevrolet\",\n",
        "#     \"https://www.youtube.com/@HowItShouldHaveEnded\",\n",
        "#     \"https://www.youtube.com/@wsj\",\n",
        "#     \"https://www.youtube.com/@cracked\",\n",
        "#     \"https://www.youtube.com/@TheTRYChannel\",\n",
        "#     \"https://www.youtube.com/@TeamCoco\",\n",
        "#     \"https://www.youtube.com/@LOLNetwork\",\n",
        "#     \"https://www.youtube.com/@KeyAndPeele\",\n",
        "#     \"https://www.youtube.com/@bonappetit\",\n",
        "#     \"https://www.youtube.com/@MentourNow\",\n",
        "#     \"https://www.youtube.com/@HasanAbi\",\n",
        "#     \"https://www.youtube.com/@TheLateLateShow\",\n",
        "#     \"https://www.youtube.com/@ThatChapter\",\n",
        "#     \"https://www.youtube.com/@Coffeezilla\",\n",
        "#     \"https://www.youtube.com/@JimmyKimmelLive\",\n",
        "#     \"https://www.youtube.com/@MentourPilot\",\n",
        "#     \"https://www.youtube.com/@OpenAI\",\n",
        "#     \"https://www.youtube.com/@TheFBIFiles\",\n",
        "#     \"https://www.youtube.com/@CoffeehouseCrime\",\n",
        "#     \"https://www.youtube.com/@TechLead\",\n",
        "#     \"https://www.youtube.com/@gustoonz\",\n",
        "#     \"https://www.youtube.com/@TFLcar\",\n",
        "#     \"https://www.youtube.com/@BreakfastClubPower1051FM\",\n",
        "#     \"https://www.youtube.com/@nike\",\n",
        "#     \"https://www.youtube.com/@MaydayAirDisaster\",\n",
        "#     \"https://www.youtube.com/@GingerBilly\",\n",
        "#     \"https://www.youtube.com/@TheBabylonBee\",\n",
        "#     \"https://www.youtube.com/@Donut\",\n",
        "#     \"https://www.youtube.com/@CSPAN\",\n",
        "#     \"https://www.youtube.com/@PhilosophyTube\",\n",
        "#     \"https://www.youtube.com/@RealTime\",\n",
        "#     \"https://www.youtube.com/@kbb\",\n",
        "#     \"https://www.youtube.com/@tesla\",\n",
        "#     \"https://www.youtube.com/@TheYoungTurks\",\n",
        "#     \"https://www.youtube.com/@bigthink\",\n",
        "#     \"https://www.youtube.com/@LindsayEllisVids\",\n",
        "#     \"https://www.youtube.com/@latimes\",\n",
        "#     \"https://www.youtube.com/@SecularTalk\",\n",
        "#     \"https://www.youtube.com/@hbomberguy\",\n",
        "#     \"https://www.youtube.com/@NewsNation\",\n",
        "#     \"https://www.youtube.com/@aljazeeraenglish\",\n",
        "#     \"https://www.youtube.com/@BenShapiro\",\n",
        "#     \"https://www.youtube.com/@BadFaithPodcast\",\n",
        "#     \"https://www.youtube.com/@fifa\",\n",
        "#     \"https://www.youtube.com/@espn\",\n",
        "#     \"https://www.youtube.com/@ActualJusticeWarrior\",\n",
        "#     \"https://www.youtube.com/@ContraPoints\",\n",
        "#     \"https://www.youtube.com/@fallontonight\",\n",
        "#     \"https://www.youtube.com/@MarkWiens\",\n",
        "#     \"https://www.youtube.com/@BBC\",\n",
        "#     \"https://www.youtube.com/@pbsspacetime\",\n",
        "#     \"https://www.youtube.com/@Dodge\",\n",
        "#     \"https://www.youtube.com/@InsideEdition\",\n",
        "#     \"https://www.youtube.com/@ford\",\n",
        "#     \"https://www.youtube.com/@FoxNews\",\n",
        "#     \"https://www.youtube.com/@Beardmeatsfood\",\n",
        "#     \"https://www.youtube.com/@CodeBlueCam\",\n",
        "#     \"https://www.youtube.com/@SamChui\",\n",
        "#     \"https://www.youtube.com/@toyotausa\",\n",
        "#     \"https://www.youtube.com/@GugaFoods\",\n",
        "#     \"https://www.youtube.com/@BBCNews\",\n",
        "#     \"https://www.youtube.com/@ColbertLateShow\",\n",
        "#     \"https://www.youtube.com/@thehill\",\n",
        "#     \"https://www.youtube.com/@NatGeo\",\n",
        "#     \"https://www.youtube.com/@Cadillac\",\n",
        "#     \"https://www.youtube.com/@TheDodo\",\n",
        "#     \"https://www.youtube.com/@discovery\",\n",
        "#     \"https://www.youtube.com/@SimplilearnOfficial\",\n",
        "#     \"https://www.youtube.com/@NBCNews\"\n",
        "# ]\n",
        "\n",
        "# # Data to be written to JSON file\n",
        "# data = {\"channels\": channels}\n",
        "\n",
        "# # Writing to json file\n",
        "# save_to_json(data, \"channels.json\")"
      ],
      "metadata": {
        "id": "hf3_-dFZdFb3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3GlBdDqdFJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the channel list from the saved jjson file\n",
        "json_data = load_from_json(\"channels.json\")\n",
        "channel_list = json_data['channels']"
      ],
      "metadata": {
        "id": "aB1ExA1XYQzk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvDeptN8fs7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Method 1 - Using the YouTube API\n",
        "\n",
        "# Function to get the channel ID from a URL that has `channel handles`\n",
        "def get_channel_id_from_url_YTAPI(api_key, custom_url):\n",
        "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "    # Removing the 'https://www.youtube.com/' part from the URL\n",
        "    username = custom_url.split('/')[-1]\n",
        "\n",
        "    # Using the 'search' method to find the channel\n",
        "    request = youtube.search().list(\n",
        "        part='snippet',\n",
        "        q=username,\n",
        "        type='channel',\n",
        "        maxResults=1\n",
        "    )\n",
        "\n",
        "    response = request.execute()\n",
        "\n",
        "    if 'items' in response and len(response['items']) > 0:\n",
        "        channel_id = response['items'][0]['snippet']['channelId']\n",
        "        return channel_id\n",
        "    else:\n",
        "        print(f\"ChannelID not found for URL: {custom_url}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "qfPQVjL7f6Ht"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7IWguQ9Wn1Cu"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to get all video IDs from the channel\n",
        "def get_all_video_ids(channel_id):\n",
        "    video_ids = []\n",
        "    next_page_token = None\n",
        "\n",
        "    while True:\n",
        "        request = youtube.search().list(\n",
        "            part='id',\n",
        "            channelId=channel_id,\n",
        "            maxResults=50,\n",
        "            pageToken=next_page_token,\n",
        "            type='video'\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        for item in response['items']:\n",
        "            video_ids.append(item['id']['videoId'])\n",
        "\n",
        "        next_page_token = response.get('nextPageToken')\n",
        "        if not next_page_token:\n",
        "            break\n",
        "\n",
        "    return video_ids\n",
        "\n",
        "# Function to get video statistics (including view count)\n",
        "def get_video_stats(video_ids):\n",
        "    video_stats = []\n",
        "    for i in range(0, len(video_ids), 50):\n",
        "        request = youtube.videos().list(\n",
        "            part='statistics',\n",
        "            id=','.join(video_ids[i:i+50])\n",
        "        )\n",
        "        response = request.execute()\n",
        "        if response.status_code == 200:\n",
        "          # Process the successful response here.\n",
        "          print(\"Request successful!\")\n",
        "        else:\n",
        "          # Handle the error response here.\n",
        "          print(\"Error:\", response.status_code)\n",
        "\n",
        "        for item in response['items']:\n",
        "            view_count = int(item['statistics']['viewCount'])\n",
        "            video_stats.append((item['id'], view_count))\n",
        "\n",
        "    return video_stats"
      ],
      "metadata": {
        "id": "1pPRv9BXD9HQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pEgdoRPVXMBC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Method 2 - Using Request and BeautifulSoup\n",
        "\n",
        "# Function to get the channel ID from a URL that has `channel handles`\n",
        "def get_channel_id_from_url2(url):\n",
        "\n",
        "  # Send a request to fetch the HTML content of the page\n",
        "  response = requests.get(url)\n",
        "\n",
        "  # Parse the HTML content using BeautifulSoup\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "  # Find the channel ID from the HTML content\n",
        "  # The channel ID is usually within a link tag with the attribute containing '/channel/'\n",
        "  channel_id = None\n",
        "  for link in soup.find_all('link'):\n",
        "      href = link.get('href', '')\n",
        "      if '/channel/' in href:\n",
        "          channel_id = href.split('/channel/')[1]\n",
        "          break\n",
        "\n",
        "  return channel_id\n"
      ],
      "metadata": {
        "id": "HLhl60EHgy4s"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We are going to create a dictionary that we will turn into a data frame containing\n",
        "  # 1. Channel Name\n",
        "  # 2. Channel Url (with handle)\n",
        "  # 3. Channel ID\n",
        "  # 4. Chennel UrlwID (with ID)\n",
        "channel_dict = {\n",
        "    \"channel_name\": [],\n",
        "    \"channel_url\": [],\n",
        "    \"channel_id\": [],\n",
        "    \"chennel_UrlwID\": []\n",
        "}\n"
      ],
      "metadata": {
        "id": "I3Mal2CNiJu0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to return th channel `username`\n",
        "def get_channel_username(url):\n",
        "  return url.split('@')[-1]"
      ],
      "metadata": {
        "id": "brLl0Ox4jFLi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's populate our data dictionary using the channel list\n",
        "random.shuffle(channel_list) # randomly shuffle the channel list\n",
        "for channel_url in channel_list:\n",
        "  channel_dict[\"channel_name\"].append(get_channel_username(channel_url))\n",
        "  channel_dict[\"channel_url\"].append(channel_url)\n",
        "  time.sleep(2) #wait for 2 seconds\n",
        "  channel_id = get_channel_id_from_url2(channel_url)\n",
        "  channel_dict[\"channel_id\"].append(channel_id)\n",
        "  channel_dict[\"chennel_UrlwID\"].append(f'https://www.youtube.com/channel/{channel_id}')\n"
      ],
      "metadata": {
        "id": "rdXKEaA1i8zV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JY9TZXjZ-b38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we convert the `channel_dict` to a pandas dataframe\n",
        "df = pd.DataFrame(channel_dict)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "NGKZ2mu-gy2I",
        "outputId": "d6484fa8-fe6e-41dd-9fcc-1acb7d393f6a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      channel_name                               channel_url  \\\n",
              "0       hbomberguy       https://www.youtube.com/@hbomberguy   \n",
              "1          NBCNews          https://www.youtube.com/@NBCNews   \n",
              "2             nike             https://www.youtube.com/@nike   \n",
              "3      Coffeezilla      https://www.youtube.com/@Coffeezilla   \n",
              "4  JordanBPeterson  https://www.youtube.com/@JordanBPeterson   \n",
              "\n",
              "                 channel_id                                     chennel_UrlwID  \n",
              "0  UClt01z1wHHT7c5lKcU8pxRQ  https://www.youtube.com/channel/UClt01z1wHHT7c...  \n",
              "1  UCeY0bbntWzzVIaj2z3QigXg  https://www.youtube.com/channel/UCeY0bbntWzzVI...  \n",
              "2  UCUFgkRb0ZHc4Rpq15VRCICA  https://www.youtube.com/channel/UCUFgkRb0ZHc4R...  \n",
              "3  UCFQMnBA3CS502aghlcr0_aw  https://www.youtube.com/channel/UCFQMnBA3CS502...  \n",
              "4  UCL_f53ZEJxp8TtlOkHwMV9Q  https://www.youtube.com/channel/UCL_f53ZEJxp8T...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e58c693-0dd0-43ce-b79e-b32b1f2bae9b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>channel_name</th>\n",
              "      <th>channel_url</th>\n",
              "      <th>channel_id</th>\n",
              "      <th>chennel_UrlwID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hbomberguy</td>\n",
              "      <td>https://www.youtube.com/@hbomberguy</td>\n",
              "      <td>UClt01z1wHHT7c5lKcU8pxRQ</td>\n",
              "      <td>https://www.youtube.com/channel/UClt01z1wHHT7c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NBCNews</td>\n",
              "      <td>https://www.youtube.com/@NBCNews</td>\n",
              "      <td>UCeY0bbntWzzVIaj2z3QigXg</td>\n",
              "      <td>https://www.youtube.com/channel/UCeY0bbntWzzVI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nike</td>\n",
              "      <td>https://www.youtube.com/@nike</td>\n",
              "      <td>UCUFgkRb0ZHc4Rpq15VRCICA</td>\n",
              "      <td>https://www.youtube.com/channel/UCUFgkRb0ZHc4R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Coffeezilla</td>\n",
              "      <td>https://www.youtube.com/@Coffeezilla</td>\n",
              "      <td>UCFQMnBA3CS502aghlcr0_aw</td>\n",
              "      <td>https://www.youtube.com/channel/UCFQMnBA3CS502...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>JordanBPeterson</td>\n",
              "      <td>https://www.youtube.com/@JordanBPeterson</td>\n",
              "      <td>UCL_f53ZEJxp8TtlOkHwMV9Q</td>\n",
              "      <td>https://www.youtube.com/channel/UCL_f53ZEJxp8T...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e58c693-0dd0-43ce-b79e-b32b1f2bae9b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e58c693-0dd0-43ce-b79e-b32b1f2bae9b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e58c693-0dd0-43ce-b79e-b32b1f2bae9b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3c8c4548-4326-444a-becb-b6178c4aa788\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c8c4548-4326-444a-becb-b6178c4aa788')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3c8c4548-4326-444a-becb-b6178c4aa788 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 168,\n  \"fields\": [\n    {\n      \"column\": \"channel_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 167,\n        \"samples\": [\n          \"BBC\",\n          \"toyotausa\",\n          \"sciencechannel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"channel_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 167,\n        \"samples\": [\n          \"https://www.youtube.com/@BBC\",\n          \"https://www.youtube.com/@toyotausa\",\n          \"https://www.youtube.com/@sciencechannel\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"channel_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 167,\n        \"samples\": [\n          \"UCCj956IF62FbT7Gouszaj9w\",\n          \"UC1pOTJteEef10zJM0cHs4iQ\",\n          \"UCvJiYiBUbw4tmpRSZT2r1Hw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chennel_UrlwID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 167,\n        \"samples\": [\n          \"https://www.youtube.com/channel/UCCj956IF62FbT7Gouszaj9w\",\n          \"https://www.youtube.com/channel/UC1pOTJteEef10zJM0cHs4iQ\",\n          \"https://www.youtube.com/channel/UCvJiYiBUbw4tmpRSZT2r1Hw\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bfV4BybZZAiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"channels.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "MA25cRA8XV_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eOZan7p25usK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_videos(channel_id):\n",
        "    api_key = \"AIzaSyC4FBfnBOGDmHLfnX_a80TtlWusLj6bDcs\"\n",
        "    url = f\"https://www.googleapis.com/youtube/v3/search?key={api_key}&channelId={channel_id}&part=snippet,id&order=viewCount&maxResults=10\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "\n",
        "    top_videos_IDs = []\n",
        "    for item in data['items']:\n",
        "      try:\n",
        "        top_videos_IDs.append(item['id']['videoId'])\n",
        "      except:\n",
        "        continue\n",
        "    return top_videos_IDs"
      ],
      "metadata": {
        "id": "pGmmSpNMsyEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nddQIi4w-X36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we are going to loop through the `channel_id` column of df\n",
        "  # for each `channel_id` get the top ten viewed videos `videoIds` and add them to `video_Id_list`\n",
        "\n",
        "video_Id_list = []\n",
        "i = 0\n",
        "while i < 168:\n",
        "  print(df['channel_name'][i])\n",
        "  print(i)\n",
        "\n",
        "  time.sleep(2) #wait for 2 seconds\n",
        "\n",
        "  video_Id_list += get_top_videos(df['channel_id'][i])\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "fy9Jo4F_tSwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dfAm9K8WCpGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n"
      ],
      "metadata": {
        "id": "FoU5XH3nKzSi",
        "outputId": "5e9042c6-d516-4b98-e8cf-c3909b2e5705",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 168 entries, 0 to 167\n",
            "Data columns (total 4 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   channel_name    168 non-null    object\n",
            " 1   channel_url     168 non-null    object\n",
            " 2   channel_id      168 non-null    object\n",
            " 3   chennel_UrlwID  168 non-null    object\n",
            "dtypes: object(4)\n",
            "memory usage: 5.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the video_Id_list to a JSON file\n",
        "save_to_json(video_Id_list, \"video_Id_list.json\")\n"
      ],
      "metadata": {
        "id": "N9uR9cLKxz2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_Id_list_from_file = load_from_json(\"video_Id_list.json\")\n",
        "video_Id_list_from_file\n"
      ],
      "metadata": {
        "id": "KB15OyTWxzls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "99NgL-kGtYpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we start the real data collection"
      ],
      "metadata": {
        "id": "TlKdUizoYgLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_comments_count(video_id, youtube):\n",
        "    response = youtube.videos().list(\n",
        "        part='statistics',\n",
        "        id=video_id\n",
        "    ).execute()\n",
        "\n",
        "    return int(response['items'][0]['statistics'].get('commentCount', 0))"
      ],
      "metadata": {
        "id": "xeeArd_JYgH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tUsrsmnAycL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_comments_html(video_url):\n",
        "  driver = webdriver.Chrome(options=chrome_options)\n",
        "  try:\n",
        "      wait = WebDriverWait(driver, 5)\n",
        "\n",
        "      # Open the YouTube video\n",
        "      driver.get(video_url)\n",
        "\n",
        "      wait.until(EC.visibility_of_element_located((By.TAG_NAME, 'body')))\n",
        "\n",
        "      # Scroll down to load comments\n",
        "      last_height = 0\n",
        "      while True:\n",
        "          # Scroll to the end of the page\n",
        "          #driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.END)\n",
        "          # Scroll using page-manager element's scroll height\n",
        "          driver.execute_script(\"window.scrollTo(0, document.getElementById('page-manager').scrollHeight);\")\n",
        "          time.sleep(5)  # Adjust sleep time as needed\n",
        "\n",
        "          # Get the current page height\n",
        "          new_height = driver.execute_script(\"return document.getElementById('page-manager').scrollHeight\")\n",
        "\n",
        "          # Break the loop if no more content is loaded\n",
        "          if new_height == last_height:\n",
        "              break\n",
        "\n",
        "          last_height = new_height\n",
        "\n",
        "      # Wait for the comments section to be visible\n",
        "      comments_section = wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"ytd-comments#comments.style-scope.ytd-watch-flexy\")))\n",
        "\n",
        "      # Get the HTML content of the comments section\n",
        "      comments_html = comments_section.get_attribute('outerHTML')\n",
        "\n",
        "  finally:\n",
        "      # Close the WebDriver session\n",
        "      driver.quit()\n",
        "\n",
        "  return comments_html\n"
      ],
      "metadata": {
        "id": "TnV4Wp43r00p"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lV5cWzgDr0xg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_comment_thread_renderers(comments_html):\n",
        "\n",
        "  soup = BeautifulSoup(comments_html, 'html.parser')\n",
        "\n",
        "  # Find the span element with the specified class\n",
        "  comment_count_span = soup.find('span', class_='style-scope yt-formatted-string')\n",
        "\n",
        "  # Extract the text content of the span element\n",
        "  comment_count = comment_count_span.text.strip()\n",
        "\n",
        "  # Print or use the comment count\n",
        "  print(\"Comment Count:\", comment_count)\n",
        "\n",
        "  # Find all occurrences of the ytd-comment-thread-renderer element\n",
        "  comment_thread_renderers = soup.find_all('ytd-comment-thread-renderer', class_='style-scope ytd-item-section-renderer')\n",
        "\n",
        "  # Count the number of occurrences\n",
        "  comment_thread_count = len(comment_thread_renderers)\n",
        "\n",
        "  # Print or use the comment thread count\n",
        "  print(\"Number of ytd-comment-thread-renderer elements:\", comment_thread_count)\n",
        "\n",
        "  return comment_thread_renderers"
      ],
      "metadata": {
        "id": "fIRwH7nHtGZ_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pODm38fYW-oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to save comments data to a JSON file\n",
        "def save_comments_to_json(comments, filename = 'youtube_comments.json'):\n",
        "    with open(filename, 'w') as json_file:\n",
        "        json.dump(comments, json_file, indent=4)\n",
        "\n",
        "def load_comments_from_json(filename = 'youtube_comments.json'):\n",
        "    with open(filename, 'r') as json_file:\n",
        "        comments = json.load(json_file)\n",
        "    return comments"
      ],
      "metadata": {
        "id": "c01OJ8kGXAEo"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lfcjiy0EXABQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVh7Bi4zs17k"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oxuNM3-v6iyv"
      },
      "outputs": [],
      "source": [
        "def get_comments(comment_thread_renderers):\n",
        "  comments = []\n",
        "  comments_data = load_comments_from_json()\n",
        "  # Iterate through each comment thread renderer\n",
        "  for comment_thread_renderer in comment_thread_renderers:\n",
        "\n",
        "      # Extracting the comment text\n",
        "      comment_text_element = comment_thread_renderer.find('yt-attributed-string', id='content-text')\n",
        "      comment_text = comment_text_element.get_text(strip=True) if comment_text_element else None\n",
        "\n",
        "      # Extracting the number of likes\n",
        "      like_count_element = comment_thread_renderer.find('span', class_='style-scope ytd-comment-engagement-bar')\n",
        "      like_count = like_count_element.get_text(strip=True) if like_count_element else None\n",
        "\n",
        "      # Extracting the number of replies\n",
        "      reply_count_element = comment_thread_renderer.find('ytd-button-renderer', id='more-replies')\n",
        "      reply_count = reply_count_element.get_text(strip=True) if reply_count_element else None\n",
        "\n",
        "      comments.append(comment_text)\n",
        "\n",
        "      print(\"Comment Text:\", comment_text)\n",
        "      print(\"Like Count:\", like_count)\n",
        "      print(\"Reply Count:\", reply_count)\n",
        "\n",
        "      print(\"\\n\\n\\n\")\n",
        "\n",
        "\n",
        "      comments_data.append(\n",
        "          {\n",
        "          \"comment_text\": comment_text,\n",
        "          \"like_count\": like_count,\n",
        "          \"reply_count\": reply_count\n",
        "\n",
        "          }\n",
        "      )\n",
        "\n",
        "\n",
        "  save_comments_to_json(comments = comments_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0xnxn5_VBwR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(load_comments_from_json())"
      ],
      "metadata": {
        "id": "HqxB4_8hWgqK",
        "outputId": "2752b835-caa2-4103-e169-9ceef67853f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16477"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qTTKlLrKWgnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for videos using the YouTube API\n",
        "def search_videos(query, youtube = youtube):\n",
        "  # Request video search\n",
        "  response = youtube.search().list(\n",
        "      q=query,\n",
        "      type=\"video\",\n",
        "      part=\"id,snippet\",\n",
        "      maxResults=10\n",
        "  ).execute()\n",
        "\n",
        "  # Extract video IDs from search results\n",
        "  video_ids = []\n",
        "  for item in response[\"items\"]:\n",
        "    video_ids.append(item[\"id\"][\"videoId\"])\n",
        "\n",
        "  return video_ids"
      ],
      "metadata": {
        "id": "yELZ0SdqswL8"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fpCKbrnPOvN1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_info(video_id):\n",
        "  # Request video details\n",
        "  response = youtube.videos().list(\n",
        "      part=\"snippet,statistics\",\n",
        "      id=video_id\n",
        "  ).execute()\n",
        "\n",
        "  # Extract required information\n",
        "  video = response[\"items\"][0]\n",
        "  title = video[\"snippet\"][\"title\"]\n",
        "  view_count = video[\"statistics\"][\"viewCount\"]\n",
        "  like_count = video[\"statistics\"][\"likeCount\"]\n",
        "  commentCount = video[\"statistics\"][\"commentCount\"]\n",
        "  date_posted = video[\"snippet\"][\"publishedAt\"]\n",
        "  description = video[\"snippet\"][\"description\"]\n",
        "\n",
        "\n",
        "  date_str = date_posted\n",
        "  date_object = datetime.datetime.strptime(date_str, \"%Y-%m-%dT%H:%M:%SZ\")\n",
        "\n",
        "  # Format the date object\n",
        "  date_posted = date_object.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "\n",
        "  # Split the description by newlines\n",
        "  paragraphs = description.split(\"\\n\")\n",
        "\n",
        "  # Get the first paragraph\n",
        "  first_paragraph = paragraphs[0]\n",
        "\n",
        "  extracted_video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "\n",
        "\n",
        "  # Print the information\n",
        "  print(\"Title:\", title)\n",
        "  print(\"Video URL:\", extracted_video_url)\n",
        "  print(\"View count:\", view_count)\n",
        "  print(\"Like count:\", like_count)\n",
        "  print(\"Number of Comments:\", commentCount)\n",
        "  print(\"Date posted:\", date_posted)\n",
        "  print(\"Description:\", first_paragraph)\n",
        "  print(\"\\n\\n\\n\")\n"
      ],
      "metadata": {
        "id": "ZYi3Cag9OvE_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Zswn5xbOrKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example usage of the `get video info/details` function\n",
        "get_video_info(video_Id_list_from_file[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbWDPaalwZP_",
        "outputId": "58c76857-f552-452e-d62f-7bd48f2c8560"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: What if He Falls? The Terrifying Reality Behind Filming “Free Solo” | Op-Docs\n",
            "Video URL: https://www.youtube.com/watch?v=3-wjmIFlnNo\n",
            "View count: 17964599\n",
            "Like count: 233891\n",
            "Number of Comments: 19775\n",
            "Date posted: 2018-11-02 23:00:00\n",
            "Description: In 2017, when Alex Honnold made his stunning free-solo ascent of Yosemite’s El Capitan, he was taking an unimaginable risk: nearly three thousand feet of climbing without any ropes or safety equipment. But was the climb made even riskier by the filmmakers who accompanied him?\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k8iJRGnYwZL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_query = \"Electric Vehicles\"\n",
        "video_ids = search_videos(search_query)\n",
        "\n",
        "\n",
        "for video_id in video_ids:\n",
        "  get_video_info(video_id)"
      ],
      "metadata": {
        "id": "Pw36E4SFswGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJT4gLq0PU1z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7RSC_pdtQ99W"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
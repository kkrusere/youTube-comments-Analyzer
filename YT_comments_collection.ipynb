{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eU0xXXoBQzor"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "sudo apt -y update\n",
        "sudo apt install -y wget curl unzip\n",
        "wget http://archive.ubuntu.com/ubuntu/pool/main/libu/libu2f-host/libu2f-udev_1.1.4-1_all.deb\n",
        "dpkg -i libu2f-udev_1.1.4-1_all.deb\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "dpkg -i google-chrome-stable_current_amd64.deb\n",
        "\n",
        "wget -N https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/118.0.5993.70/linux64/chromedriver-linux64.zip -P /tmp/\n",
        "unzip -o /tmp/chromedriver-linux64.zip -d /tmp/\n",
        "chmod +x /tmp/chromedriver-linux64/chromedriver\n",
        "mv /tmp/chromedriver-linux64/chromedriver /usr/local/bin/chromedriver\n",
        "pip install selenium chromedriver_autoinstaller"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft\n",
        "!pip install datasets\n",
        "!pip install rouge-score"
      ],
      "metadata": {
        "id": "2iAPTc9BExMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EXC_Unt0ExGz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lo_Rt1YYX9U5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqMUbwZnX_vZ",
        "outputId": "c6c26a6d-3548-4dcd-863a-f1d0fe481dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/NLP_Data\n"
          ]
        }
      ],
      "source": [
        "#mounting google drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "########################################\n",
        "\n",
        "#changing the working directory\n",
        "os.chdir(\"/content/drive/MyDrive/NLP_Data\")\n",
        "\n",
        "!pwd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ql3oOw_zRdDb"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "\n",
        "\n",
        "from selenium import webdriver\n",
        "import chromedriver_autoinstaller\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.common.exceptions import TimeoutException, ElementNotInteractableException\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "\n",
        "import random\n",
        "import time\n",
        "\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chromedriver_autoinstaller.install()\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import operator\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('YouTubeAPI_key')\n",
        "\n",
        "import googleapiclient.discovery\n",
        "from googleapiclient.discovery import build\n",
        "import datetime\n",
        "\n",
        "from datasets import Dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset, load_metric\n",
        "from transformers import BartTokenizer, BartForConditionalGeneration, TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "import torch\n",
        "import re\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ps6xt7G1EfGL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMLm81KQ27EV"
      },
      "source": [
        "This Jupyter Notebook is designed to collect YouTube video comments from various videos. These comments will be used for creating, training, and validating a Sentiment Analysis model. The videos from which the comments were collected were chosen with no particular criteria other than being from my favorite channels and videos.\n",
        "\n",
        "The process of collecting comments makes use of the YouTube API, Selenium, BeautifulSoup, and other custom functions.\n",
        "\n",
        "The process:\n",
        "\n",
        "1. Create a list of favorite channels.\n",
        "2. Use the YouTube API to select the top 10 most-watched videos from each channel and store them in a master list of videos from which we will collect comments.\n",
        "3. For each video in the master video list, use Selenium and BeautifulSoup to collect the comments and store them in a pandas DataFrame.\n",
        "4. Clean and sanitize the comments in the DataFrame and prepare the data for Sentiment Analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nNpaCEhz2vCm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sQISFC8_errB"
      },
      "outputs": [],
      "source": [
        "# Below are functions for reading a writting json file for the current working directory\n",
        "\n",
        "def save_to_json(data, filename):\n",
        "    with open(filename, 'w') as json_file:\n",
        "        json.dump(data, json_file, indent=4)\n",
        "\n",
        "def load_from_json(filename):\n",
        "    with open(filename, 'r') as json_file:\n",
        "        comments = json.load(json_file)\n",
        "    return comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XE90kVwSerj-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hf3_-dFZdFb3"
      },
      "outputs": [],
      "source": [
        "# Function to convert string values containing suffixes 'K', 'M', or 'B' to integers and extract numeric values.\n",
        "def convert_to_int(value):\n",
        "  \"\"\"\n",
        "    - If the value is NaN or an empty string, return 0.\n",
        "    - If the value is a string:\n",
        "      - Extract numeric digits from the string.\n",
        "      - Convert the extracted digits to an integer.\n",
        "      - If the string contains 'K', multiply the number by 1,000.\n",
        "      - If the string contains 'M', multiply the number by 1,000,000.\n",
        "      - If the string contains 'B', multiply the number by 1,000,000,000.\n",
        "    - Return the converted integer value.\n",
        "\n",
        "  \"\"\"\n",
        "  if pd.isna(value) or value == '':\n",
        "      return 0\n",
        "  if isinstance(value, str):\n",
        "      # Extract numbers and convert them\n",
        "      num = re.findall(r'\\d+', value)\n",
        "      if not num:\n",
        "          return 0\n",
        "      num = ''.join(num)\n",
        "      if 'K' in value:\n",
        "          return int(float(num) * 1000)\n",
        "      if 'M' in value:\n",
        "          return int(float(num) * 1000000)\n",
        "      if 'B' in value:\n",
        "          return int(float(num) * 1000000000)\n",
        "      return int(num)\n",
        "  return int(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "p3GlBdDqdFJJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "aB1ExA1XYQzk"
      },
      "outputs": [],
      "source": [
        "# # Reading the channel list from the saved json file\n",
        "# json_data = load_from_json(\"channels.json\")\n",
        "# channel_list = json_data['channels']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qvDeptN8fs7E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize YouTube API client\n",
        "def initialize_youtube_api(api_key):\n",
        "    return build(\"youtube\", \"v3\", developerKey=api_key)\n",
        "\n",
        "def init_webdriver():\n",
        "    \"\"\"Initializes and returns a Chrome WebDriver instance with options.\"\"\"\n",
        "    try:\n",
        "        chrome_options = webdriver.ChromeOptions()\n",
        "        chrome_options.add_argument('--headless')\n",
        "        chrome_options.add_argument('--no-sandbox')\n",
        "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "        chromedriver_autoinstaller.install()\n",
        "        driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "        print(\"WebDriver initialized successfully\")  # Confirm initialization\n",
        "        return driver\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to initialize WebDriver: {e}\")\n",
        "        raise\n",
        "\n",
        "def close_webdriver(driver):\n",
        "    \"\"\"Closes the provided WebDriver instance.\"\"\"\n",
        "    print(\"WebDriver successfully closed\")\n",
        "    driver.quit()\n"
      ],
      "metadata": {
        "id": "VFze5_JN7rTy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aX9K9LUs9vuX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The function will accept a single parameter, the video_id.\n",
        "# It will construct the YouTube URL using the standard base URL and the provided video_id.\n",
        "# The completed URL will be returned.\n",
        "\n",
        "def get_youtube_url(video_id):\n",
        "  \"\"\"\n",
        "  Constructs a YouTube URL from a given video ID.\n",
        "\n",
        "  Args:\n",
        "      video_id: The unique identifier for a YouTube video.\n",
        "\n",
        "  Returns:\n",
        "      The full URL of the YouTube video.\n",
        "  \"\"\"\n",
        "\n",
        "  video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "\n",
        "  return video_url\n"
      ],
      "metadata": {
        "id": "2cgZlIy-9vrA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ULTKqAEy7rO1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "7IWguQ9Wn1Cu"
      },
      "outputs": [],
      "source": [
        "def get_comments_html(video_url, driver):\n",
        "    \"\"\"\n",
        "    Fetches the HTML content of the comments section from a YouTube video.\n",
        "\n",
        "    This function initializes a WebDriver instance to open the provided YouTube video URL,\n",
        "    scrolls down to load the comments section, and retrieves the HTML content of the loaded\n",
        "    comments section.\n",
        "\n",
        "    Args:\n",
        "        video_url (str): The URL of the YouTube video from which to fetch comments.\n",
        "        driver: An initialized WebDriver instance (from Selenium).\n",
        "\n",
        "    Returns:\n",
        "        str: The HTML content of the comments section.\n",
        "\n",
        "    Raises:\n",
        "        TimeoutException: If the comments section does not load within the specified time.\n",
        "    \"\"\"\n",
        "\n",
        "    # Wait until the comments section is loaded\n",
        "    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'ytd-comments')))\n",
        "\n",
        "    # Scroll to the comments section to load initial comments\n",
        "    driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
        "\n",
        "    # Set initial values for dynamic loading\n",
        "    last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
        "    scroll_pause_time = 2  # Time to wait between scrolls\n",
        "    max_scrolls = 100  # Increase the max number of scrolls to ensure all comments are loaded\n",
        "    scroll_count = 0\n",
        "\n",
        "    while scroll_count < max_scrolls:\n",
        "        # Scroll down to the bottom\n",
        "        driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\n",
        "\n",
        "        # Wait for new comments to load dynamically\n",
        "        time.sleep(scroll_pause_time)  # Simple wait to allow comments to load\n",
        "\n",
        "        # Check the new scroll height and compare it with the last height\n",
        "        new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
        "        if new_height == last_height:\n",
        "            # If the height hasn't changed, try one more scroll to ensure all comments are loaded\n",
        "            time.sleep(scroll_pause_time)\n",
        "            new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\n",
        "            if new_height == last_height:\n",
        "                # If the height still hasn't changed, we've reached the end\n",
        "                print(\"All comments have been loaded.\")\n",
        "                break\n",
        "\n",
        "        last_height = new_height\n",
        "        scroll_count += 1\n",
        "\n",
        "    # Get the HTML of the comments section\n",
        "    comments_html = driver.page_source\n",
        "\n",
        "    # Close the driver\n",
        "    driver.quit()\n",
        "\n",
        "    return comments_html"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DaAB_9fT-Ivv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_comment_thread_renderers(comments_html):\n",
        "    \"\"\"\n",
        "    Parses the provided HTML content to extract YouTube comment threads and their counts.\n",
        "\n",
        "    This function uses BeautifulSoup to parse the HTML content of a YouTube video's comments section.\n",
        "    It finds and prints the number of comments and the number of comment thread renderers (`ytd-comment-thread-renderer`).\n",
        "    It then returns a list of all the `ytd-comment-thread-renderer` elements found in the HTML.\n",
        "\n",
        "    Args:\n",
        "        comments_html (str): The HTML content of the comments section of a YouTube video.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of `ytd-comment-thread-renderer` elements found in the HTML.\n",
        "    \"\"\"\n",
        "\n",
        "    soup = BeautifulSoup(comments_html, 'html.parser')\n",
        "\n",
        "    # Find the span element with the specified class\n",
        "    comment_count_span = soup.find('span', class_='style-scope yt-formatted-string')\n",
        "\n",
        "    # Extract the text content of the span element\n",
        "    comment_count = comment_count_span.text.strip()\n",
        "\n",
        "    # # Print or use the comment count\n",
        "    # print(\"Comment Count:\", comment_count)\n",
        "\n",
        "    # Find all occurrences of the ytd-comment-thread-renderer element\n",
        "    comment_thread_renderers = soup.find_all('ytd-comment-thread-renderer', class_='style-scope ytd-item-section-renderer')\n",
        "\n",
        "    # Count the number of occurrences\n",
        "    comment_thread_count = len(comment_thread_renderers)\n",
        "\n",
        "    # # Print or use the comment thread count\n",
        "    # print(\"Number of ytd-comment-thread-renderer elements:\", comment_thread_count)\n",
        "\n",
        "    return comment_thread_renderers"
      ],
      "metadata": {
        "id": "nQce9ZdW-Iso"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BX2dDo1f-QA9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_comments(comment_thread_renderers):\n",
        "    comments = list()\n",
        "    comments_data = list()\n",
        "    # Iterate through each comment thread renderer\n",
        "    for comment_thread_renderer in comment_thread_renderers:\n",
        "\n",
        "        # Extracting the comment text\n",
        "        comment_text_element = comment_thread_renderer.find('yt-attributed-string', id='content-text')\n",
        "        comment_text = comment_text_element.get_text(strip=True) if comment_text_element else None\n",
        "\n",
        "        # Extracting the number of likes\n",
        "        like_count_element = comment_thread_renderer.find('span', class_='style-scope ytd-comment-engagement-bar')\n",
        "        like_count = like_count_element.get_text(strip=True) if like_count_element else None\n",
        "\n",
        "        # Extracting the number of replies\n",
        "        reply_count_element = comment_thread_renderer.find('ytd-button-renderer', id='more-replies')\n",
        "        reply_count = reply_count_element.get_text(strip=True) if reply_count_element else None\n",
        "\n",
        "        comments.append(comment_text)\n",
        "\n",
        "        comments_data.append(\n",
        "            {\n",
        "            \"comment_text\": comment_text,\n",
        "            \"like_count\": like_count,\n",
        "            \"reply_count\": reply_count\n",
        "\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return comments, comments_data\n"
      ],
      "metadata": {
        "id": "1qdrNHsP-RHy"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eAoOeocICNqN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_description(description_data, model_path=\"./fine-tuned-lora-model\"):\n",
        "    \"\"\"\n",
        "    Cleans and summarizes YouTube video descriptions using a fine-tuned LoRA model.\n",
        "\n",
        "    Args:\n",
        "        description_data: A list of dictionaries containing video details (channel_name, video_title, video_description).\n",
        "        model_path: The path to the fine-tuned LoRA model.\n",
        "\n",
        "    Returns:\n",
        "        A list of cleaned and summarized video descriptions.\n",
        "    \"\"\"\n",
        "    # Configure LoRA\n",
        "    lora_config = LoraConfig(\n",
        "        r=16,  # Rank of the LoRA matrix\n",
        "        lora_alpha=32,  # Scaling factor for LoRA\n",
        "        target_modules=[\"q_proj\", \"v_proj\"],  # Target attention layers to apply LoRA\n",
        "        lora_dropout=0.05,  # Dropout rate for LoRA\n",
        "        bias=\"none\",  # No bias\n",
        "    )\n",
        "\n",
        "    # Preparing input for inference\n",
        "    formatted_inputs = [\n",
        "        f\"Channel: {item['channel_name']}, Title: {item['video_title']}, Description: {item['video_description']}\"\n",
        "        for item in description_data\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Loading the fine-tuned LoRA model and tokenizer\n",
        "    model = BartForConditionalGeneration.from_pretrained(model_path)\n",
        "\n",
        "    # # Tokenize input\n",
        "    tokenizer = BartTokenizer.from_pretrained(model_path)\n",
        "    inputs = tokenizer(formatted_inputs, max_length=512, return_tensors=\"pt\", truncation=True, padding=\"max_length\")\n",
        "\n",
        "    # Move inputs to the same device as the model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "\n",
        "    # LoRA configuration applied to the model\n",
        "    lora_model = get_peft_model(model, lora_config)\n",
        "    lora_model.to(device)\n",
        "\n",
        "    # Generate Cleaned Descriptions\n",
        "    with torch.no_grad():\n",
        "        outputs = lora_model.generate(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            max_length=128,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "    # Decode and print summaries\n",
        "    cleaned_descriptions = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "\n",
        "    return cleaned_descriptions[0]"
      ],
      "metadata": {
        "id": "QjP0LbMbEF1U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ofSGBkwcEFxa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NTIRmf_jEFtg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and display video comments\n",
        "def get_video_comments(video_url, driver):\n",
        "    \"\"\"\n",
        "    Retrieves comments from the provided YouTube video URL.\n",
        "\n",
        "    Args:\n",
        "        video_url (str): The URL of the YouTube video.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of comments and their data.\n",
        "    \"\"\"\n",
        "    #print(\"\\nwe are now in the get_video_comments function\\n\")\n",
        "    comments_html = get_comments_html(video_url, driver)  # Get HTML of comments section\n",
        "    comment_thread_renderers = get_comment_thread_renderers(comments_html)  # Extract comment renderers\n",
        "    _, comments_data = get_comments(comment_thread_renderers)  # Extract comment data\n",
        "\n",
        "    return comments_data"
      ],
      "metadata": {
        "id": "mNP_Z8zdCMWn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UimTMwbz-REa"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_data(video_id):\n",
        "    \"\"\"Fetches video data from YouTube given a video ID.\n",
        "\n",
        "    Args:\n",
        "        video_id (str): The ID of the YouTube video to fetch data for.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing the video data with the following keys:\n",
        "            - 'channel_name': The name of the channel that uploaded the video.\n",
        "            - 'video_title': The title of the video.\n",
        "            - 'video_description': The description of the video.\n",
        "\n",
        "    Raises:\n",
        "        Exception: If there is an error accessing or processing the video data.\n",
        "    \"\"\"\n",
        "    driver = init_webdriver()\n",
        "    video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
        "    video_data = {}\n",
        "\n",
        "    try:\n",
        "        driver.get(video_url)\n",
        "\n",
        "        try:\n",
        "            # Wait for the bottom-row element to be present\n",
        "            bottom_row = WebDriverWait(driver, 20).until(\n",
        "                EC.presence_of_element_located((By.XPATH, '//*[@id=\"bottom-row\"]'))\n",
        "            )\n",
        "\n",
        "            # Locate and click the expand button if it exists\n",
        "            try:\n",
        "                expand_button = WebDriverWait(driver, 10).until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, '/html/body/ytd-app/div[1]/ytd-page-manager/ytd-watch-flexy/div[5]/div[1]/div/div[2]/ytd-watch-metadata/div/div[4]/div[1]/div/ytd-text-inline-expander/tp-yt-paper-button[1]'))\n",
        "                )\n",
        "                expand_button.click()\n",
        "            except TimeoutException:\n",
        "                pass  # Ignore if the expand button is not found\n",
        "\n",
        "            # Wait for elements to be visible and extract data\n",
        "            expanded_description = WebDriverWait(driver, 10).until(\n",
        "                EC.visibility_of_element_located((By.ID, 'description-inline-expander'))\n",
        "            )\n",
        "            title_element = WebDriverWait(driver, 10).until(\n",
        "                EC.presence_of_element_located((By.XPATH, '//h1[@class=\"style-scope ytd-watch-metadata\"]//yt-formatted-string'))\n",
        "            )\n",
        "            channel_name_element = WebDriverWait(driver, 10).until(\n",
        "                EC.presence_of_element_located((By.XPATH, '//ytd-channel-name[@id=\"channel-name\"]//yt-formatted-string//a'))\n",
        "            )\n",
        "\n",
        "            video_data = {\n",
        "                'channel_name': channel_name_element.text,\n",
        "                'video_title': title_element.text,\n",
        "                'video_description': expanded_description.text\n",
        "            }\n",
        "            # print(\"\\nwe got the raw video_data\")\n",
        "            temp_list = list()\n",
        "            temp_list.append(video_data)\n",
        "            cleaned_description = clean_description(temp_list)\n",
        "            video_data['video_description'] = cleaned_description\n",
        "\n",
        "            comments_data = get_video_comments(video_url, driver)\n",
        "            video_data['comments'] = comments_data\n",
        "\n",
        "        except TimeoutException:\n",
        "            print(f\"Error processing {video_url}: Elements not found within timeout.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {video_url}: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "    finally:\n",
        "        # Close the browser when done\n",
        "        close_webdriver(driver)\n",
        "\n",
        "    return video_data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gwxMow8r_K5K"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HFYHQuwP_K0w"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_and_shuffle_video_ids(filename):\n",
        "  \"\"\"Reads video IDs from a JSON file and returns a shuffled list.\"\"\"\n",
        "  video_id_list = load_from_json(filename)\n",
        "  random.shuffle(video_id_list)\n",
        "  return video_id_list\n",
        "\n",
        "\n",
        "video_id_list = read_and_shuffle_video_ids(\"video_Id_list.json\")\n"
      ],
      "metadata": {
        "id": "IErfKmtR_KrW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(video_id_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WSG6ZCQ_Kn_",
        "outputId": "b5ba9c35-f5ed-4bf5-f872-b9bfa2fa9b69"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1674"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_id = video_id_list[5]\n",
        "video_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "06lVL0OsAYp-",
        "outputId": "683ee52e-d4b8-47ce-9d92-d07ecd823f0c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gqS1ov4lSI0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test\n",
        "video_data = get_video_data(video_id)\n",
        "print(video_data)\n"
      ],
      "metadata": {
        "id": "VrR686pIAiTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ppg9pC6dAiQE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_data.keys()"
      ],
      "metadata": {
        "id": "bnz1CgpqAiM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "924764b0-b36f-47ca-dc7e-ab98698d0c8c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['channel_name', 'video_title', 'video_description', 'comments'])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "video_data['video_description']"
      ],
      "metadata": {
        "id": "Humh0LEOTVff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b5RnrIxhAh1_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we collect video data that we are going to use to fine-tune a LLM Sentiment Analysis Model\n",
        "video_data_list = []\n",
        "for video_id in video_id_list[:125]:\n",
        "  try:\n",
        "    video_data = get_video_data(video_id)\n",
        "    video_data_list.append(video_data)\n",
        "  except Exception as e:\n",
        "    print(f\"Error processing video ID {video_id}: {e}\")\n",
        "    print(f\"https://www.youtube.com/watch?v={video_id}\")\n",
        "    continue  # Continue to the next video ID if an error occurs\n",
        "\n",
        "save_to_json(video_data_list, \"video_data_list.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUaDuVpKadPI",
        "outputId": "42ec2079-dadc-4863-ba0a-90c702ec4c7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WebDriver initialized successfully\n",
            "All comments have been loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x795e93cf2bf0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/d83133f1c59047033820b461083ae8ec\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x795e93cf2ec0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/d83133f1c59047033820b461083ae8ec\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x795e93cf3010>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/d83133f1c59047033820b461083ae8ec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WebDriver successfully closed\n",
            "WebDriver initialized successfully\n",
            "All comments have been loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x795e91d728c0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/f180500df87b4056d4785eb7b4542c1a\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x795e91d72a10>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/f180500df87b4056d4785eb7b4542c1a\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x795e91d725c0>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/f180500df87b4056d4785eb7b4542c1a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WebDriver successfully closed\n",
            "WebDriver initialized successfully\n",
            "All comments have been loaded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x795f34bb1840>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/e6a634e15dbca332a7a4c8600f1d5b8c\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x795f34bb1b70>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/e6a634e15dbca332a7a4c8600f1d5b8c\n",
            "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x795f34bb1a80>: Failed to establish a new connection: [Errno 111] Connection refused')': /session/e6a634e15dbca332a7a4c8600f1d5b8c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WebDriver successfully closed\n",
            "WebDriver initialized successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "T-ucVwnjbIk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# # Initialize YouTube API client\n",
        "# api_key = userdata.get('YouTubeAPI_key')\n",
        "# youtube = initialize_youtube_api(api_key)\n",
        "\n",
        "# # # Display video info\n",
        "# # print(\"\\nVideo Information:\\n\")\n",
        "# # title, extracted_video_url, view_count, like_count, commentCount, date_posted, first_paragraph, thumbnail_url = get_video_info(video_id)\n",
        "# # print(f\"Title: {title}\")\n",
        "# # print(f\"Video URL: {extracted_video_url}\")\n",
        "# # print(f\"View count: {view_count}\")\n",
        "# # print(f\"Like count: {like_count}\")\n",
        "# # print(f\"Number of Comments: {commentCount}\")\n",
        "# # print(f\"Date posted: {date_posted}\")\n",
        "# # print(f\"Description: {first_paragraph}\")\n",
        "# # print(f\"Thumbnail URL: {thumbnail_url}\")\n",
        "# # print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "WJqrk0bl_HUh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}